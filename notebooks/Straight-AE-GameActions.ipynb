{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyper_params import *\n",
    "import text_encoder as te\n",
    "import text_decoder as td\n",
    "from data_set import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bowizer\n",
    "import tfidf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_policy_random.pkl', 'rb') as f:\n",
    "    gd = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n                    ________  ________  __    __  ________        \\n                   |        \\\\|        \\\\|  \\\\  |  \\\\|        \\\\       \\n                    \\\\$$$$$$$$| $$$$$$$$| $$  | $$ \\\\$$$$$$$$       \\n                      | $$   | $$__     \\\\$$\\\\/  $$   | $$          \\n                      | $$   | $$  \\\\     >$$  $$    | $$          \\n                      | $$   | $$$$$    /  $$$$\\\\    | $$          \\n                      | $$   | $$_____ |  $$ \\\\$$\\\\   | $$          \\n                      | $$   | $$     \\\\| $$  | $$   | $$          \\n                       \\\\$$    \\\\$$$$$$$$ \\\\$$   \\\\$$    \\\\$$          \\n              __       __   ______   _______   __        _______  \\n             |  \\\\  _  |  \\\\ /      \\\\ |       \\\\ |  \\\\      |       \\\\ \\n             | $$ / \\\\ | $$|  $$$$$$\\\\| $$$$$$$\\\\| $$      | $$$$$$$\\\\\\n             | $$/  $\\\\| $$| $$  | $$| $$__| $$| $$      | $$  | $$\\n             | $$  $$$\\\\ $$| $$  | $$| $$    $$| $$      | $$  | $$\\n             | $$ $$\\\\$$\\\\$$| $$  | $$| $$$$$$$\\\\| $$      | $$  | $$\\n             | $$$$  \\\\$$$$| $$__/ $$| $$  | $$| $$_____ | $$__/ $$\\n             | $$$    \\\\$$$ \\\\$$    $$| $$  | $$| $$     \\\\| $$    $$\\n              \\\\$$      \\\\$$  \\\\$$$$$$  \\\\$$   \\\\$$ \\\\$$$$$$$$ \\\\$$$$$$$ \\n\\nIt\\'s time to explore the amazing world of TextWorld! Make it so the safe inside the cellar is locked.\\n\\n-= Cellar =-\\nYou find yourself in a cellar. A typical one. You try to gain information on your surroundings by using a technique you call \"looking.\"\\n\\nA closed safe, which looks typical, is in the corner.\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob ='\\n\\n\\n                    ________  ________  __    __  ________        \\n                   |        \\\\|        \\\\|  \\\\  |  \\\\|        \\\\       \\n                    \\\\$$$$$$$$| $$$$$$$$| $$  | $$ \\\\$$$$$$$$       \\n                      | $$   | $$__     \\\\$$\\\\/  $$   | $$          \\n                      | $$   | $$  \\\\     >$$  $$    | $$          \\n                      | $$   | $$$$$    /  $$$$\\\\    | $$          \\n                      | $$   | $$_____ |  $$ \\\\$$\\\\   | $$          \\n                      | $$   | $$     \\\\| $$  | $$   | $$          \\n                       \\\\$$    \\\\$$$$$$$$ \\\\$$   \\\\$$    \\\\$$          \\n              __       __   ______   _______   __        _______  \\n             |  \\\\  _  |  \\\\ /      \\\\ |       \\\\ |  \\\\      |       \\\\ \\n             | $$ / \\\\ | $$|  $$$$$$\\\\| $$$$$$$\\\\| $$      | $$$$$$$\\\\\\n             | $$/  $\\\\| $$| $$  | $$| $$__| $$| $$      | $$  | $$\\n             | $$  $$$\\\\ $$| $$  | $$| $$    $$| $$      | $$  | $$\\n             | $$ $$\\\\$$\\\\$$| $$  | $$| $$$$$$$\\\\| $$      | $$  | $$\\n             | $$$$  \\\\$$$$| $$__/ $$| $$  | $$| $$_____ | $$__/ $$\\n             | $$$    \\\\$$$ \\\\$$    $$| $$  | $$| $$     \\\\| $$    $$\\n              \\\\$$      \\\\$$  \\\\$$$$$$  \\\\$$   \\\\$$ \\\\$$$$$$$$ \\\\$$$$$$$ \\n\\n'\n",
    "bloblen = len(blob)\n",
    "\n",
    "gd[0] = [x.replace(blob, \"\") for x in gd[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_data = len(gd[1])\n",
    "\n",
    "vocab_size = 300\n",
    "training_split = 0.7\n",
    "\n",
    "traininglen = int(len_data * training_split)\n",
    "\n",
    "# - use gd[1] for actions data\n",
    "training_set = gd[1][:traininglen]\n",
    "test_set = gd[1][traininglen:]\n",
    "test_set[0]\n",
    "\n",
    "#use the game states for tokens\n",
    "tm = bowizer.TokenMaker(corpus=gd[1], vocab_size= vocab_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont use big.txt for tokens\n",
    "#with open('../../../data/norvig_tm_3000.pkl', 'rb') as f:\n",
    "    #tm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_h = EmbeddingHyper(tm.vocab_size + 1, 64)\n",
    "conv_h = ConvHyper(64, 6, 4)\n",
    "rnn_h = RnnHyper(512, is_lstm=False, is_bidirectional=True, return_sequences=False)\n",
    "encoder_h = te.Hyper(embed_h, [conv_h, rnn_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dernn_h = RnnHyper(512, is_lstm=False, is_bidirectional=False, return_sequences=True, unroll=True)\n",
    "dec_h = DeconvHyper(64, 6, 4)\n",
    "decoder_h = td.Hyper(tm.vocab_size + 1, [dernn_h, dec_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder_h.make_layer()\n",
    "decoder = decoder_h.make_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(training_set).shape\n",
    "\n",
    "ml = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(max_len):\n",
    "    x = Input(shape=(max_len,), name='text_input')\n",
    "    h = encoder(x)\n",
    "    h = decoder(h, max_len)\n",
    "    model = Model(x, h)\n",
    "    model.compile(optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['categorical_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel = make_model(ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testmodel.load_weights('../models/wl_model64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_round(history=None):\n",
    "    if history is None:\n",
    "        initial_epoch = 0\n",
    "    else:\n",
    "        initial_epoch = len(history['loss'])\n",
    "    train = bowizer.SlicedWordData(lines=r.choice(training_set, size=2000, replace=False), maxlen=ml,tokenmaker=tm)\n",
    "    test = bowizer.SlicedWordData(lines=r.choice(test_set, size=400, replace=False), maxlen=ml,tokenmaker=tm)\n",
    "    newhistory = testmodel.fit(x=train.x, y=train.y,\n",
    "                            epochs=initial_epoch+5, batch_size=32,\n",
    "                            validation_data=(test.x, test.y),\n",
    "                            initial_epoch=initial_epoch)\n",
    "    if history is None:\n",
    "        history = newhistory.history\n",
    "    else:\n",
    "        history = {key:history[key] + newhistory.history[key] for key in history.keys()}\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 35s - loss: 1.0639 - categorical_accuracy: 0.9397 - val_loss: 0.7411 - val_categorical_accuracy: 0.9540\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 103s - loss: 0.7244 - categorical_accuracy: 0.9551 - val_loss: 0.7411 - val_categorical_accuracy: 0.9540\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 110s - loss: 0.7244 - categorical_accuracy: 0.9551 - val_loss: 0.7411 - val_categorical_accuracy: 0.9540\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 61s - loss: 0.7244 - categorical_accuracy: 0.9551 - val_loss: 0.7411 - val_categorical_accuracy: 0.9540\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 77s - loss: 0.7244 - categorical_accuracy: 0.9551 - val_loss: 0.7411 - val_categorical_accuracy: 0.9540\n",
      "1\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 110s - loss: 0.7397 - categorical_accuracy: 0.9541 - val_loss: 0.7241 - val_categorical_accuracy: 0.9551\n",
      "Epoch 7/10\n",
      "  32/2000 [..............................] - ETA: 103s - loss: 0.7162 - categorical_accuracy: 0.9556"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(i)\n",
    "    history = training_round(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.save('../models/gameaction_ae64.hp5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
