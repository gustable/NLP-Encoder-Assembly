{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bytelevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Conv1D, Input, GRU, LSTM, Bidirectional, Dense, UpSampling1D, Dropout, TimeDistributed, RepeatVector\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.RandomState(42)\n",
    "\n",
    "def random_chop(s, r, m):\n",
    "    n = len(s)\n",
    "    if n <= m:\n",
    "        return s\n",
    "    k = r.randint(n - m)\n",
    "    s = s[k:]\n",
    "    return s[:m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_20newsgroups(subset='train')\n",
    "test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 64\n",
    "\n",
    "def dataset(x):\n",
    "    x = [random_chop(s, r, max_len + 1) for s in x]\n",
    "    x = bytelevel.encode(x)\n",
    "    x = pad_sequences(x, max_len + 1)\n",
    "    return x\n",
    "\n",
    "x_train = dataset(train['data'])\n",
    "x_test = dataset(test['data'])\n",
    "x_test = x_test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingHyper(object):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "    @staticmethod\n",
    "    def Random(r):\n",
    "        embedding_dim = r.choice([2 ** i for i in range(6, 10)])\n",
    "        return EmbeddingHyper(256, embedding_dim)\n",
    "        \n",
    "    def display(self):\n",
    "        print(\"embedding\")\n",
    "        print(\"vocab size=%d\" % self.vocab_size)\n",
    "        print(\"embedding dimension=%d\" % self.embedding_dim)\n",
    "        \n",
    "    def make_layer(self, name='embedder'):\n",
    "        return Embedding(self.vocab_size, \n",
    "            self.embedding_dim , name=name)\n",
    "    \n",
    "class ConvHyper(object):\n",
    "    def __init__(self, filters, kernel_size=3, stride=2):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        \n",
    "    @staticmethod\n",
    "    def Random(r):\n",
    "        filters = r.choice([2 ** i for i in range(6, 10)])\n",
    "        kernel_size = r.randint(8) + 2\n",
    "        stride = r.randint(4) + 1\n",
    "        return ConvHyper(filters, kernel_size, stride)\n",
    "        \n",
    "    def display(self):\n",
    "        print(\"conv 1d\")\n",
    "        print(\"filters=%d\" % self.filters)\n",
    "        print(\"kernel size=%d\" % self.kernel_size)\n",
    "        print(\"stride = %d\" % self.stride)\n",
    "        \n",
    "    def make_layer(self, name):\n",
    "        return Conv1D(self.filters, self.kernel_size, strides=self.stride, padding='causal', activation='relu', name=name)\n",
    "    \n",
    "class RnnHyper(object):\n",
    "    def __init__(self, hidden_dim, is_lstm, is_bidirectional):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.is_lstm = is_lstm\n",
    "        self.is_bidirectional = is_bidirectional\n",
    "        \n",
    "    @staticmethod\n",
    "    def Random(r):\n",
    "        hidden_dim = r.choice([2 ** i for i in range(6, 10)])\n",
    "        is_lstm = bool(r.randint(2))\n",
    "        is_bidirectional = bool(r.randint(2))\n",
    "        return RnnHyper(hidden_dim, is_lstm, is_bidirectional)\n",
    "\n",
    "    def display(self):\n",
    "        print(\"RNN\")\n",
    "        print(\"hidden dimension=%d\" % self.hidden_dim)\n",
    "        if self.is_bidirectional:\n",
    "            print(\"bidirectional\")\n",
    "        if self.is_lstm:\n",
    "            print(\"lstm\")\n",
    "        else:\n",
    "            print(\"gru\")            \n",
    "        \n",
    "    def make_layer(self, name, return_sequences):\n",
    "        if self.is_lstm:\n",
    "            make_rnn = LSTM\n",
    "        else:\n",
    "            make_rnn = GRU\n",
    "        if self.is_bidirectional:\n",
    "            return Bidirectional(make_rnn(self.hidden_dim, return_sequences=return_sequences), name=name)\n",
    "        return make_rnn(self.hidden_dim, return_sequences=return_sequences, name=name)\n",
    "    \n",
    "class RnnCnnHyper(object):\n",
    "    def __init__(self, embedder, conv, rnn):\n",
    "        self.embedder = embedder\n",
    "        self.conv = conv\n",
    "        self.rnn = rnn\n",
    "        \n",
    "    @staticmethod\n",
    "    def Random(r):\n",
    "        embedder = EmbeddingHyper.Random(r)\n",
    "        conv = ConvHyper.Random(r)\n",
    "        rnn = RnnHyper.Random(r)\n",
    "        \n",
    "        return RnnCnnHyper(embedder, conv, rnn)\n",
    "\n",
    "    def display(self):\n",
    "        self.embedder.display()\n",
    "        print()\n",
    "        self.conv.display()\n",
    "        print()\n",
    "        self.rnn.display()\n",
    "        print()\n",
    "        \n",
    "    def make_layers(self, name, return_sequences):\n",
    "        if name is not None and len(name):\n",
    "            prefix = '%s_' % name\n",
    "        else:\n",
    "            prefix = ''\n",
    "        embedder = self.embedder.make_layer(name='%sembedder' % prefix)\n",
    "        conv = self.conv.make_layer(name='%sconv' % prefix)\n",
    "        rnn = self.rnn.make_layer(name='%srnn' % prefix, return_sequences=return_sequences)\n",
    "        dense = Dense(self.embedder.vocab_size, activation='softmax', name='%sprobs' % prefix)\n",
    "        return embedder, conv, rnn, dense\n",
    "    \n",
    "class DeconvHyper(object):\n",
    "    def __init__(self, filters, kernel_size=3, upsample=2):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.upsample = upsample\n",
    "        \n",
    "    @staticmethod\n",
    "    def Random(r, upsample=None):\n",
    "        filters = r.choice([2 ** i for i in range(6, 10)])\n",
    "        kernel_size = r.randint(8) + 2\n",
    "        if upsample is None:\n",
    "            upsample = r.randint(4) + 1\n",
    "        return DeconvHyper(filters, kernel_size, upsample)\n",
    "        \n",
    "    def display(self):\n",
    "        print(\"deconv 1d\")\n",
    "        print(\"filters=%d\" % self.filters)\n",
    "        print(\"kernel size=%d\" % self.kernel_size)\n",
    "        print(\"upsample = %d\" % self.upsample)\n",
    "        \n",
    "    def make_layer(self, name):\n",
    "        conv = Conv1D(self.filters, self.kernel_size, strides=1, padding='causal', activation='relu', name=name)\n",
    "        return conv, UpSampling1D(self.upsample)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def explore(seed, count, max_len):\n",
    "    r = np.random.RandomState(seed)\n",
    "    histories = []\n",
    "    \n",
    "    def dataset(x):\n",
    "        x = [random_chop(s, r, max_len + 1) for s in x]\n",
    "        x = bytelevel.encode(x)\n",
    "        x = pad_sequences(x, max_len + 1)\n",
    "        return x\n",
    "\n",
    "    x_train = dataset(train['data'])\n",
    "    x_test = dataset(test['data'])\n",
    "    x_test = x_test[:2000]\n",
    "\n",
    "    for i in range(count):\n",
    "        seed = r.randint(200000)\n",
    "        name = \"RnnCnn%d\" % seed\n",
    "        r_i = np.random.RandomState(seed)\n",
    "        hyper = RnnCnnHyper.Random(r_i)\n",
    "        hyper.display()\n",
    "\n",
    "        embed, conv, rnn, pred = hyper.make_layers('', False)\n",
    "\n",
    "        x = Input(shape=(max_len,), name='text_input')\n",
    "        h = embed(x)\n",
    "        print(h.shape)\n",
    "        h = conv(h)\n",
    "        print(h.shape)\n",
    "        h = rnn(h)\n",
    "        print(h.shape)\n",
    "        h = pred(h)\n",
    "        print(h.shape)\n",
    "\n",
    "        model = Model(x, h)\n",
    "        model.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "        history = model.fit(x=x_train[:, :max_len], \n",
    "                     y=x_train[:, max_len],\n",
    "                    epochs=3, batch_size=10,\n",
    "                    validation_data=(x_test[:, :max_len], x_test[:, max_len]))\n",
    "\n",
    "        histories.append([seed, history])\n",
    "        \n",
    "        with open(\"../models/%s.pkl\" % name, 'wb') as f:\n",
    "            pickle.dump([seed, hyper, history.history], f)\n",
    "            \n",
    "        model.save(\"../models/%s.h5\" % name)\n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "    \n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=3\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "lstm\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 12, 256)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 23s - loss: 3.4506 - sparse_categorical_accuracy: 0.1695 - val_loss: 3.3535 - val_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 22s - loss: 3.2965 - sparse_categorical_accuracy: 0.1797 - val_loss: 3.2803 - val_sparse_categorical_accuracy: 0.1915\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 23s - loss: 3.1969 - sparse_categorical_accuracy: 0.1990 - val_loss: 3.2470 - val_sparse_categorical_accuracy: 0.1950\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=4\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=512\n",
      "lstm\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 12, 512)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 72s - loss: 3.4070 - sparse_categorical_accuracy: 0.1709 - val_loss: 3.2711 - val_sparse_categorical_accuracy: 0.1945\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 72s - loss: 3.1829 - sparse_categorical_accuracy: 0.2007 - val_loss: 3.1853 - val_sparse_categorical_accuracy: 0.2195\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 71s - loss: 3.0020 - sparse_categorical_accuracy: 0.2310 - val_loss: 3.1724 - val_sparse_categorical_accuracy: 0.2275\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=64\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=3\n",
      "stride = 3\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 64)\n",
      "(?, 16, 256)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 26s - loss: 3.4575 - sparse_categorical_accuracy: 0.1694 - val_loss: 3.3319 - val_sparse_categorical_accuracy: 0.1770\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 26s - loss: 3.2881 - sparse_categorical_accuracy: 0.1808 - val_loss: 3.2638 - val_sparse_categorical_accuracy: 0.1775\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 26s - loss: 3.1833 - sparse_categorical_accuracy: 0.1990 - val_loss: 3.2287 - val_sparse_categorical_accuracy: 0.1875\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=6\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "bidirectional\n",
      "lstm\n",
      "\n",
      "(?, 50, 128)\n",
      "(?, 23, 256)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 45s - loss: 3.2296 - sparse_categorical_accuracy: 0.2094 - val_loss: 2.9224 - val_sparse_categorical_accuracy: 0.2465\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 45s - loss: 2.7654 - sparse_categorical_accuracy: 0.2790 - val_loss: 2.7227 - val_sparse_categorical_accuracy: 0.2910\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 45s - loss: 2.5653 - sparse_categorical_accuracy: 0.3238 - val_loss: 2.6278 - val_sparse_categorical_accuracy: 0.3135\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=2\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=512\n",
      "lstm\n",
      "\n",
      "(?, 50, 128)\n",
      "(?, 13, 512)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 62s - loss: 3.1042 - sparse_categorical_accuracy: 0.2282 - val_loss: 2.7933 - val_sparse_categorical_accuracy: 0.2810\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 61s - loss: 2.6900 - sparse_categorical_accuracy: 0.2926 - val_loss: 2.6542 - val_sparse_categorical_accuracy: 0.3010\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 62s - loss: 2.4998 - sparse_categorical_accuracy: 0.3269 - val_loss: 2.6038 - val_sparse_categorical_accuracy: 0.3165\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=2\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 25, 128)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 39s - loss: 3.1447 - sparse_categorical_accuracy: 0.2264 - val_loss: 2.7984 - val_sparse_categorical_accuracy: 0.2785\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 38s - loss: 2.6712 - sparse_categorical_accuracy: 0.2979 - val_loss: 2.6454 - val_sparse_categorical_accuracy: 0.3155\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 38s - loss: 2.4768 - sparse_categorical_accuracy: 0.3382 - val_loss: 2.5581 - val_sparse_categorical_accuracy: 0.3320\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=7\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "gru\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 11, 256)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 22s - loss: 3.4349 - sparse_categorical_accuracy: 0.1711 - val_loss: 3.2981 - val_sparse_categorical_accuracy: 0.1950\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 22s - loss: 3.2083 - sparse_categorical_accuracy: 0.1991 - val_loss: 3.2528 - val_sparse_categorical_accuracy: 0.2025\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 22s - loss: 2.9883 - sparse_categorical_accuracy: 0.2359 - val_loss: 3.2791 - val_sparse_categorical_accuracy: 0.2030\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=64\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=6\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "gru\n",
      "\n",
      "(?, 50, 64)\n",
      "(?, 12, 128)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 16s - loss: 3.1982 - sparse_categorical_accuracy: 0.2105 - val_loss: 2.8397 - val_sparse_categorical_accuracy: 0.2615\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 15s - loss: 2.6995 - sparse_categorical_accuracy: 0.2921 - val_loss: 2.6473 - val_sparse_categorical_accuracy: 0.3120\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 15s - loss: 2.4735 - sparse_categorical_accuracy: 0.3396 - val_loss: 2.6088 - val_sparse_categorical_accuracy: 0.3230\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=6\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 128)\n",
      "(?, 12, 512)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 40s - loss: 3.0617 - sparse_categorical_accuracy: 0.2439 - val_loss: 2.7135 - val_sparse_categorical_accuracy: 0.3075\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 40s - loss: 2.5203 - sparse_categorical_accuracy: 0.3412 - val_loss: 2.6116 - val_sparse_categorical_accuracy: 0.3235\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 40s - loss: 2.1392 - sparse_categorical_accuracy: 0.4109 - val_loss: 2.6251 - val_sparse_categorical_accuracy: 0.3285\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=5\n",
      "stride = 1\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 128)\n",
      "(?, 46, 128)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 72s - loss: 3.1482 - sparse_categorical_accuracy: 0.2246 - val_loss: 2.7579 - val_sparse_categorical_accuracy: 0.2905\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 71s - loss: 2.6420 - sparse_categorical_accuracy: 0.3107 - val_loss: 2.6181 - val_sparse_categorical_accuracy: 0.3145\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 71s - loss: 2.3934 - sparse_categorical_accuracy: 0.3557 - val_loss: 2.5522 - val_sparse_categorical_accuracy: 0.3425\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=64\n",
      "\n",
      "conv 1d\n",
      "filters=64\n",
      "kernel size=9\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=512\n",
      "lstm\n",
      "\n",
      "(?, 50, 64)\n",
      "(?, 21, 64)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 66s - loss: 3.5155 - sparse_categorical_accuracy: 0.1655 - val_loss: 3.4432 - val_sparse_categorical_accuracy: 0.1710\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 65s - loss: 3.5415 - sparse_categorical_accuracy: 0.1602 - val_loss: 3.4567 - val_sparse_categorical_accuracy: 0.1730\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 63s - loss: 3.4226 - sparse_categorical_accuracy: 0.1712 - val_loss: 3.3740 - val_sparse_categorical_accuracy: 0.1825\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=9\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 11, 128)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 23s - loss: 3.3853 - sparse_categorical_accuracy: 0.1784 - val_loss: 3.2120 - val_sparse_categorical_accuracy: 0.1935\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 22s - loss: 3.0632 - sparse_categorical_accuracy: 0.2203 - val_loss: 3.0886 - val_sparse_categorical_accuracy: 0.2315\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 22s - loss: 2.7904 - sparse_categorical_accuracy: 0.2827 - val_loss: 3.0943 - val_sparse_categorical_accuracy: 0.2315\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=64\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=4\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "lstm\n",
      "\n",
      "(?, 50, 64)\n",
      "(?, 24, 512)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 29s - loss: 3.1747 - sparse_categorical_accuracy: 0.2180 - val_loss: 2.8388 - val_sparse_categorical_accuracy: 0.2600\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 28s - loss: 2.7262 - sparse_categorical_accuracy: 0.2878 - val_loss: 2.6872 - val_sparse_categorical_accuracy: 0.2955\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 28s - loss: 2.5534 - sparse_categorical_accuracy: 0.3216 - val_loss: 2.6025 - val_sparse_categorical_accuracy: 0.3025\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=8\n",
      "stride = 3\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 128)\n",
      "(?, 15, 512)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 47s - loss: 3.0639 - sparse_categorical_accuracy: 0.2415 - val_loss: 2.7453 - val_sparse_categorical_accuracy: 0.2830\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 47s - loss: 2.5026 - sparse_categorical_accuracy: 0.3364 - val_loss: 2.6352 - val_sparse_categorical_accuracy: 0.3255\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 47s - loss: 2.0625 - sparse_categorical_accuracy: 0.4258 - val_loss: 2.6898 - val_sparse_categorical_accuracy: 0.3250\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=4\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "lstm\n",
      "\n",
      "(?, 50, 128)\n",
      "(?, 24, 256)\n",
      "(?, 64)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 26s - loss: 3.2859 - sparse_categorical_accuracy: 0.2030 - val_loss: 2.9442 - val_sparse_categorical_accuracy: 0.2485\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 25s - loss: 2.8213 - sparse_categorical_accuracy: 0.2757 - val_loss: 2.7740 - val_sparse_categorical_accuracy: 0.2855\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 25s - loss: 2.6646 - sparse_categorical_accuracy: 0.3025 - val_loss: 2.7018 - val_sparse_categorical_accuracy: 0.2980\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=64\n",
      "kernel size=5\n",
      "stride = 3\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "lstm\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 16, 64)\n",
      "(?, 64)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 20s - loss: 3.2880 - sparse_categorical_accuracy: 0.2031 - val_loss: 2.9351 - val_sparse_categorical_accuracy: 0.2475\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 19s - loss: 2.8284 - sparse_categorical_accuracy: 0.2717 - val_loss: 2.7813 - val_sparse_categorical_accuracy: 0.2840\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 19s - loss: 2.6715 - sparse_categorical_accuracy: 0.3037 - val_loss: 2.6992 - val_sparse_categorical_accuracy: 0.3050\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=64\n",
      "kernel size=8\n",
      "stride = 3\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "gru\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 15, 64)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 19s - loss: 3.1513 - sparse_categorical_accuracy: 0.2212 - val_loss: 2.8285 - val_sparse_categorical_accuracy: 0.2675\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 18s - loss: 2.6547 - sparse_categorical_accuracy: 0.3019 - val_loss: 2.6795 - val_sparse_categorical_accuracy: 0.2975\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 18s - loss: 2.3960 - sparse_categorical_accuracy: 0.3533 - val_loss: 2.6489 - val_sparse_categorical_accuracy: 0.3175\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=9\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 21, 512)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 74s - loss: 3.3196 - sparse_categorical_accuracy: 0.1901 - val_loss: 3.1312 - val_sparse_categorical_accuracy: 0.2320\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 73s - loss: 2.8826 - sparse_categorical_accuracy: 0.2596 - val_loss: 3.0977 - val_sparse_categorical_accuracy: 0.2215\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 73s - loss: 2.3140 - sparse_categorical_accuracy: 0.3850 - val_loss: 3.2575 - val_sparse_categorical_accuracy: 0.2245\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=6\n",
      "stride = 3\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "gru\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 15, 512)\n",
      "(?, 64)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 26s - loss: 3.4535 - sparse_categorical_accuracy: 0.1736 - val_loss: 3.3272 - val_sparse_categorical_accuracy: 0.1840\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 25s - loss: 3.2530 - sparse_categorical_accuracy: 0.1893 - val_loss: 3.2714 - val_sparse_categorical_accuracy: 0.2010\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 25s - loss: 3.1116 - sparse_categorical_accuracy: 0.2191 - val_loss: 3.2430 - val_sparse_categorical_accuracy: 0.1900\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=2\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "bidirectional\n",
      "lstm\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 25, 128)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 49s - loss: 3.1899 - sparse_categorical_accuracy: 0.2213 - val_loss: 2.8767 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 48s - loss: 2.7585 - sparse_categorical_accuracy: 0.2813 - val_loss: 2.7047 - val_sparse_categorical_accuracy: 0.2970\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 48s - loss: 2.5993 - sparse_categorical_accuracy: 0.3030 - val_loss: 2.6454 - val_sparse_categorical_accuracy: 0.3075\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=64\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=8\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 64)\n",
      "(?, 11, 256)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 31s - loss: 3.4472 - sparse_categorical_accuracy: 0.1707 - val_loss: 3.3224 - val_sparse_categorical_accuracy: 0.1780\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 30s - loss: 3.2436 - sparse_categorical_accuracy: 0.1906 - val_loss: 3.2214 - val_sparse_categorical_accuracy: 0.2080\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 30s - loss: 3.0352 - sparse_categorical_accuracy: 0.2266 - val_loss: 3.2305 - val_sparse_categorical_accuracy: 0.2040\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=64\n",
      "kernel size=2\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "lstm\n",
      "\n",
      "(?, 50, 128)\n",
      "(?, 25, 64)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 32s - loss: 3.1856 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.8437 - val_sparse_categorical_accuracy: 0.2515\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314/11314 [==============================] - 31s - loss: 2.7582 - sparse_categorical_accuracy: 0.2743 - val_loss: 2.6972 - val_sparse_categorical_accuracy: 0.2840\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 31s - loss: 2.5826 - sparse_categorical_accuracy: 0.3100 - val_loss: 2.6260 - val_sparse_categorical_accuracy: 0.3080\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=6\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=512\n",
      "bidirectional\n",
      "lstm\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 23, 512)\n",
      "(?, 1024)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 174s - loss: 3.1024 - sparse_categorical_accuracy: 0.2329 - val_loss: 2.7032 - val_sparse_categorical_accuracy: 0.3050\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 176s - loss: 2.5453 - sparse_categorical_accuracy: 0.3268 - val_loss: 2.5547 - val_sparse_categorical_accuracy: 0.3275\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 179s - loss: 2.1805 - sparse_categorical_accuracy: 0.3982 - val_loss: 2.5225 - val_sparse_categorical_accuracy: 0.3435\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=5\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 12, 512)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 58s - loss: 3.3107 - sparse_categorical_accuracy: 0.1906 - val_loss: 3.1219 - val_sparse_categorical_accuracy: 0.2295\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 57s - loss: 2.9259 - sparse_categorical_accuracy: 0.2556 - val_loss: 3.0979 - val_sparse_categorical_accuracy: 0.2375\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 56s - loss: 2.5142 - sparse_categorical_accuracy: 0.3285 - val_loss: 3.1593 - val_sparse_categorical_accuracy: 0.2505\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=64\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=2\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "lstm\n",
      "\n",
      "(?, 50, 64)\n",
      "(?, 25, 256)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 36s - loss: 3.1611 - sparse_categorical_accuracy: 0.2198 - val_loss: 2.8304 - val_sparse_categorical_accuracy: 0.2590\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 34s - loss: 2.7236 - sparse_categorical_accuracy: 0.2752 - val_loss: 2.6697 - val_sparse_categorical_accuracy: 0.2975\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 35s - loss: 2.5397 - sparse_categorical_accuracy: 0.3159 - val_loss: 2.5908 - val_sparse_categorical_accuracy: 0.3230\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=2\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "lstm\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 13, 256)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 19s - loss: 3.1324 - sparse_categorical_accuracy: 0.2312 - val_loss: 2.8123 - val_sparse_categorical_accuracy: 0.2600\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 18s - loss: 2.7341 - sparse_categorical_accuracy: 0.2852 - val_loss: 2.6927 - val_sparse_categorical_accuracy: 0.2835\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 18s - loss: 2.6027 - sparse_categorical_accuracy: 0.3084 - val_loss: 2.6158 - val_sparse_categorical_accuracy: 0.3080\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=2\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "gru\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 13, 128)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 17s - loss: 3.0536 - sparse_categorical_accuracy: 0.2393 - val_loss: 2.7512 - val_sparse_categorical_accuracy: 0.2840\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 16s - loss: 2.6327 - sparse_categorical_accuracy: 0.3051 - val_loss: 2.6215 - val_sparse_categorical_accuracy: 0.3125\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 16s - loss: 2.4455 - sparse_categorical_accuracy: 0.3398 - val_loss: 2.5750 - val_sparse_categorical_accuracy: 0.3230\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=4\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=512\n",
      "lstm\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 12, 512)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 75s - loss: 3.4124 - sparse_categorical_accuracy: 0.1704 - val_loss: 3.2796 - val_sparse_categorical_accuracy: 0.1915\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 73s - loss: 3.1889 - sparse_categorical_accuracy: 0.2004 - val_loss: 3.2351 - val_sparse_categorical_accuracy: 0.1970\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 73s - loss: 3.0106 - sparse_categorical_accuracy: 0.2298 - val_loss: 3.1894 - val_sparse_categorical_accuracy: 0.2160\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=64\n",
      "kernel size=5\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "bidirectional\n",
      "lstm\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 23, 64)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 50s - loss: 3.3953 - sparse_categorical_accuracy: 0.1736 - val_loss: 3.2442 - val_sparse_categorical_accuracy: 0.1865\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 48s - loss: 3.1406 - sparse_categorical_accuracy: 0.2009 - val_loss: 3.1413 - val_sparse_categorical_accuracy: 0.2055\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 48s - loss: 2.9912 - sparse_categorical_accuracy: 0.2337 - val_loss: 3.0905 - val_sparse_categorical_accuracy: 0.2275\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=64\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=9\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "bidirectional\n",
      "lstm\n",
      "\n",
      "(?, 50, 64)\n",
      "(?, 21, 256)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4273 - sparse_categorical_accuracy: 0.1724 - val_loss: 3.2626 - val_sparse_categorical_accuracy: 0.1955\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 43s - loss: 3.1867 - sparse_categorical_accuracy: 0.1971 - val_loss: 3.1783 - val_sparse_categorical_accuracy: 0.2005\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 43s - loss: 3.0514 - sparse_categorical_accuracy: 0.2209 - val_loss: 3.1242 - val_sparse_categorical_accuracy: 0.2230\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "histories = explore(42, 30, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [3.3535089254379273, 3.280325162410736, 3.2470242130756377],\n",
       " 'val_sparse_categorical_accuracy': [0.15000000320374965,\n",
       "  0.19150000415742396,\n",
       "  0.19500000398606063],\n",
       " 'loss': [3.4505941521179473, 3.296464189531442, 3.1968547680446657],\n",
       " 'sparse_categorical_accuracy': [0.1695244864817325,\n",
       "  0.17968888495453933,\n",
       "  0.19895704868447978]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histories[0][1].history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = lambda x: x[1].history['val_sparse_categorical_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories.sort(key=val_acc, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3435000073164701,\n",
       " 0.3425000065565109,\n",
       " 0.33200000803917645,\n",
       " 0.3285000066459179,\n",
       " 0.3250000074505806,\n",
       " 0.3230000077188015,\n",
       " 0.3230000064894557,\n",
       " 0.323000006377697,\n",
       " 0.3175000072270632,\n",
       " 0.3165000065788627,\n",
       " 0.31350000761449337,\n",
       " 0.3080000070855021,\n",
       " 0.3080000065267086,\n",
       " 0.307500006891787,\n",
       " 0.305000006519258,\n",
       " 0.30250000681728123,\n",
       " 0.2980000066012144,\n",
       " 0.2505000047758222,\n",
       " 0.23150000479072333,\n",
       " 0.22750000536441803,\n",
       " 0.2275000049546361,\n",
       " 0.22450000502169132,\n",
       " 0.2230000051110983,\n",
       " 0.21600000452250243,\n",
       " 0.204000004529953,\n",
       " 0.20300000436604024,\n",
       " 0.19500000398606063,\n",
       " 0.19000000402331352,\n",
       " 0.18750000394880773,\n",
       " 0.18250000409781933]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[val_acc(x) for x in histories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReHyper(seed):\n",
    "    r = np.random.RandomState(seed)\n",
    "    hyper = RnnCnnHyper.Random(r)\n",
    "    return hyper, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper, _ =ReHyper(histories[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154351\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=6\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=512\n",
      "bidirectional\n",
      "lstm\n",
      "\n",
      "150338\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=5\n",
      "stride = 1\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "17970\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=2\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "154443\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=6\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "27315\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=8\n",
      "stride = 3\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "62245\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=2\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "gru\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seed, _ in histories[:6]:\n",
    "    hyper, _ = ReHyper(seed)\n",
    "    print(seed)\n",
    "    hyper.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(int(max_len / 4), 16), name='seq_input')\n",
    "up = UpSampling1D(size=4)\n",
    "h = up(x)\n",
    "deconv = Conv1D(16, 4, strides=2, name='deconv', padding='causal')\n",
    "h = deconv(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(128), Dimension(16)])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = r.rand(2, 64, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(x, up(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = model.predict(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 256, 16)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_h = EmbeddingHyper(256, 256)\n",
    "conv_h = ConvHyper(512, 6, 2)\n",
    "rnn_h = RnnHyper(512, is_lstm=True, is_bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = RnnCnnHyper(embed_h, conv_h, rnn_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 256)\n",
      "(?, ?, 512)\n",
      "(?, 1024)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "11314/11314 [==============================] - 33s - loss: 3.5957 - sparse_categorical_accuracy: 0.1556 - val_loss: 3.3676 - val_sparse_categorical_accuracy: 0.1830\n",
      "Epoch 2/5\n",
      "11314/11314 [==============================] - 30s - loss: 3.3459 - sparse_categorical_accuracy: 0.1709 - val_loss: 3.2271 - val_sparse_categorical_accuracy: 0.1905\n",
      "Epoch 3/5\n",
      "11314/11314 [==============================] - 30s - loss: 3.1607 - sparse_categorical_accuracy: 0.1999 - val_loss: 3.0716 - val_sparse_categorical_accuracy: 0.2190\n",
      "Epoch 4/5\n",
      "11314/11314 [==============================] - 31s - loss: 2.9595 - sparse_categorical_accuracy: 0.2420 - val_loss: 2.9864 - val_sparse_categorical_accuracy: 0.2440\n",
      "Epoch 5/5\n",
      "11314/11314 [==============================] - 30s - loss: 2.7673 - sparse_categorical_accuracy: 0.2820 - val_loss: 2.9424 - val_sparse_categorical_accuracy: 0.2615\n"
     ]
    }
   ],
   "source": [
    "max_len = 32\n",
    "\n",
    "def dataset(x):\n",
    "    x = [random_chop(s, r, max_len + 1) for s in x]\n",
    "    x = bytelevel.encode(x)\n",
    "    x = pad_sequences(x, max_len + 1)\n",
    "    return x\n",
    "\n",
    "x_train = dataset(train['data'])\n",
    "x_test = dataset(test['data'])\n",
    "x_test = x_test[:2000]\n",
    "\n",
    "# first with no dropout\n",
    "embed, conv0, rnn, pred = hyper.make_layers('', False)\n",
    "\n",
    "\n",
    "x = Input(shape=(None,), name='text_input')\n",
    "h = embed(x)\n",
    "print(h.shape)\n",
    "h = conv0(h)\n",
    "print(h.shape)\n",
    "h = rnn(h)\n",
    "print(h.shape)\n",
    "h = pred(h)\n",
    "print(h.shape)\n",
    "\n",
    "model = Model(x, h)\n",
    "model.compile(optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(x=x_train[:, :max_len], \n",
    "            y=x_train[:, max_len],\n",
    "            epochs=5, batch_size=100,\n",
    "            validation_data=(x_test[:, :max_len], x_test[:, max_len]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 256)\n",
      "(?, ?, 512)\n",
      "(?, ?, 512)\n",
      "(?, 1024)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "11314/11314 [==============================] - 34s - loss: 2.9412 - sparse_categorical_accuracy: 0.2520 - val_loss: 2.9655 - val_sparse_categorical_accuracy: 0.2530\n",
      "Epoch 2/5\n",
      "11314/11314 [==============================] - 31s - loss: 2.7193 - sparse_categorical_accuracy: 0.2925 - val_loss: 2.9340 - val_sparse_categorical_accuracy: 0.2510\n",
      "Epoch 3/5\n",
      "11314/11314 [==============================] - 31s - loss: 2.5371 - sparse_categorical_accuracy: 0.3248 - val_loss: 2.9871 - val_sparse_categorical_accuracy: 0.2585\n",
      "Epoch 4/5\n",
      "11314/11314 [==============================] - 31s - loss: 2.3119 - sparse_categorical_accuracy: 0.3776 - val_loss: 3.0257 - val_sparse_categorical_accuracy: 0.2485\n",
      "Epoch 5/5\n",
      "11314/11314 [==============================] - 31s - loss: 2.0282 - sparse_categorical_accuracy: 0.4462 - val_loss: 3.1230 - val_sparse_categorical_accuracy: 0.2435\n"
     ]
    }
   ],
   "source": [
    "# refresh data\n",
    "max_len = 32\n",
    "\n",
    "x_train = dataset(train['data'])\n",
    "x_test = dataset(test['data'])\n",
    "x_test = x_test[:2000]\n",
    "\n",
    "# add a bit of dropout\n",
    "drop = Dropout(0.2)\n",
    "\n",
    "h = embed(x)\n",
    "print(h.shape)\n",
    "h = conv0(h)\n",
    "print(h.shape)\n",
    "h = drop(h)\n",
    "print(h.shape)\n",
    "h = rnn(h)\n",
    "print(h.shape)\n",
    "h = pred(h)\n",
    "print(h.shape)\n",
    "\n",
    "model = Model(x, h)\n",
    "model.compile(optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(x=x_train[:, :max_len], \n",
    "            y=x_train[:, max_len],\n",
    "            epochs=5, batch_size=100,\n",
    "            validation_data=(x_test[:, :max_len], x_test[:, max_len]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 256)\n",
      "(?, ?, 512)\n",
      "(?, ?, 512)\n",
      "(?, ?, 512)\n",
      "(?, ?, 512)\n",
      "(?, 1024)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 45s - loss: 3.4200 - sparse_categorical_accuracy: 0.1716 - val_loss: 3.3315 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 41s - loss: 3.2149 - sparse_categorical_accuracy: 0.1968 - val_loss: 3.2692 - val_sparse_categorical_accuracy: 0.1905\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 42s - loss: 2.9958 - sparse_categorical_accuracy: 0.2340 - val_loss: 3.3190 - val_sparse_categorical_accuracy: 0.1760\n"
     ]
    }
   ],
   "source": [
    "# get some data from longer strings\n",
    "max_len = 64\n",
    "\n",
    "x_train = dataset(train['data'])\n",
    "x_test = dataset(test['data'])\n",
    "x_test = x_test[:2000]\n",
    "\n",
    "# add another convolutional layer\n",
    "conv1 = conv_h.make_layer('')\n",
    "\n",
    "h = embed(x)\n",
    "print(h.shape)\n",
    "h = conv0(h)\n",
    "print(h.shape)\n",
    "h = drop(h)\n",
    "print(h.shape)\n",
    "h = conv1(h)\n",
    "print(h.shape)\n",
    "h = drop(h)\n",
    "print(h.shape)\n",
    "h = rnn(h)\n",
    "print(h.shape)\n",
    "h = pred(h)\n",
    "print(h.shape)\n",
    "\n",
    "model = Model(x, h)\n",
    "model.compile(optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "history = model.fit(x=x_train[:, :max_len], \n",
    "            y=x_train[:, max_len],\n",
    "            epochs=3, batch_size=100,\n",
    "            validation_data=(x_test[:, :max_len], x_test[:, max_len]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain(max_len):\n",
    "    def dataset(x):\n",
    "        x = [random_chop(s, r, max_len + 1) for s in x]\n",
    "        x = bytelevel.encode(x)\n",
    "        x = pad_sequences(x, max_len + 1)\n",
    "        return x\n",
    "    x_train = dataset(train['data'])\n",
    "    x_test = dataset(test['data'])\n",
    "    x_test = x_test[:2000]\n",
    "\n",
    "    history = model.fit(x=x_train[:, :max_len], \n",
    "                y=x_train[:, max_len],\n",
    "                epochs=3, batch_size=40,\n",
    "                validation_data=(x_test[:, :max_len], x_test[:, max_len]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([115, 102,  48, 102,  97], dtype=int32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:5, max_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[104, 101,  32,  98, 101],\n",
       "       [ 98, 117, 116,  10,  97],\n",
       "       [115,  32, 118,  49,  46],\n",
       "       [ 32, 115, 116, 117, 102],\n",
       "       [ 40,  78, 111, 114, 109]], dtype=int32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:5, max_len-5:max_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32, 32, 32, 32, 32])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[:5, :max_len]).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 256)\n",
      "(?, ?, 512)\n",
      "(?, ?, 512)\n",
      "(?, ?, 512)\n",
      "(?, ?, 512)\n",
      "(?, ?, 512)\n",
      "(?, ?, 512)\n",
      "(?, ?, 512)\n",
      "(?, ?, 512)\n",
      "(?, 1024)\n",
      "(?, 256)\n"
     ]
    }
   ],
   "source": [
    "# convolve a couple more times\n",
    "\n",
    "h = embed(x)\n",
    "print(h.shape)\n",
    "h = conv0(h)\n",
    "print(h.shape)\n",
    "h = drop(h)\n",
    "print(h.shape)\n",
    "h = conv1(h)\n",
    "print(h.shape)\n",
    "h = drop(h)\n",
    "print(h.shape)\n",
    "h = conv1(h)\n",
    "print(h.shape)\n",
    "h = drop(h)\n",
    "print(h.shape)\n",
    "h = conv1(h)\n",
    "print(h.shape)\n",
    "h = drop(h)\n",
    "print(h.shape)\n",
    "h = rnn(h)\n",
    "print(h.shape)\n",
    "h = pred(h)\n",
    "print(h.shape)\n",
    "\n",
    "model = Model(x, h)\n",
    "model.compile(optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4378 - sparse_categorical_accuracy: 0.1687 - val_loss: 3.4643 - val_sparse_categorical_accuracy: 0.1650\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4157 - sparse_categorical_accuracy: 0.1701 - val_loss: 3.4534 - val_sparse_categorical_accuracy: 0.1665\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4109 - sparse_categorical_accuracy: 0.1701 - val_loss: 3.4631 - val_sparse_categorical_accuracy: 0.1650\n",
      "\n",
      "1\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4164 - sparse_categorical_accuracy: 0.1731 - val_loss: 3.4310 - val_sparse_categorical_accuracy: 0.1680\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 45s - loss: 3.4082 - sparse_categorical_accuracy: 0.1734 - val_loss: 3.4598 - val_sparse_categorical_accuracy: 0.1680\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 45s - loss: 3.4103 - sparse_categorical_accuracy: 0.1724 - val_loss: 3.4624 - val_sparse_categorical_accuracy: 0.1675\n",
      "\n",
      "2\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 45s - loss: 3.4246 - sparse_categorical_accuracy: 0.1731 - val_loss: 3.4259 - val_sparse_categorical_accuracy: 0.1755\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 46s - loss: 3.4169 - sparse_categorical_accuracy: 0.1723 - val_loss: 3.4393 - val_sparse_categorical_accuracy: 0.1770\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 45s - loss: 3.4205 - sparse_categorical_accuracy: 0.1734 - val_loss: 3.4358 - val_sparse_categorical_accuracy: 0.1760\n",
      "\n",
      "3\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 45s - loss: 3.4511 - sparse_categorical_accuracy: 0.1641 - val_loss: 3.4497 - val_sparse_categorical_accuracy: 0.1560\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4724 - sparse_categorical_accuracy: 0.1589 - val_loss: 3.4463 - val_sparse_categorical_accuracy: 0.1570\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 45s - loss: 3.4639 - sparse_categorical_accuracy: 0.1587 - val_loss: 3.4262 - val_sparse_categorical_accuracy: 0.1575\n",
      "\n",
      "4\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 45s - loss: 3.4755 - sparse_categorical_accuracy: 0.1688 - val_loss: 3.4664 - val_sparse_categorical_accuracy: 0.1540\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4688 - sparse_categorical_accuracy: 0.1694 - val_loss: 3.4762 - val_sparse_categorical_accuracy: 0.1545\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4622 - sparse_categorical_accuracy: 0.1697 - val_loss: 3.4764 - val_sparse_categorical_accuracy: 0.1595\n",
      "\n",
      "5\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4643 - sparse_categorical_accuracy: 0.1668 - val_loss: 3.5025 - val_sparse_categorical_accuracy: 0.1735\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4715 - sparse_categorical_accuracy: 0.1613 - val_loss: 3.5169 - val_sparse_categorical_accuracy: 0.1725\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4656 - sparse_categorical_accuracy: 0.1646 - val_loss: 3.5363 - val_sparse_categorical_accuracy: 0.1770\n",
      "\n",
      "6\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 45s - loss: 3.4967 - sparse_categorical_accuracy: 0.1630 - val_loss: 3.4748 - val_sparse_categorical_accuracy: 0.1660\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4778 - sparse_categorical_accuracy: 0.1659 - val_loss: 3.4652 - val_sparse_categorical_accuracy: 0.1720\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4725 - sparse_categorical_accuracy: 0.1670 - val_loss: 3.4651 - val_sparse_categorical_accuracy: 0.1710\n",
      "\n",
      "7\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4773 - sparse_categorical_accuracy: 0.1729 - val_loss: 3.4734 - val_sparse_categorical_accuracy: 0.1645\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4605 - sparse_categorical_accuracy: 0.1723 - val_loss: 3.4733 - val_sparse_categorical_accuracy: 0.1650\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4601 - sparse_categorical_accuracy: 0.1722 - val_loss: 3.4755 - val_sparse_categorical_accuracy: 0.1650\n",
      "\n",
      "8\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4782 - sparse_categorical_accuracy: 0.1686 - val_loss: 3.3962 - val_sparse_categorical_accuracy: 0.1740\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4780 - sparse_categorical_accuracy: 0.1675 - val_loss: 3.3989 - val_sparse_categorical_accuracy: 0.1740\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4730 - sparse_categorical_accuracy: 0.1666 - val_loss: 3.3926 - val_sparse_categorical_accuracy: 0.1745\n",
      "\n",
      "9\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4744 - sparse_categorical_accuracy: 0.1701 - val_loss: 3.4028 - val_sparse_categorical_accuracy: 0.1685\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4525 - sparse_categorical_accuracy: 0.1719 - val_loss: 3.4022 - val_sparse_categorical_accuracy: 0.1705\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 44s - loss: 3.4469 - sparse_categorical_accuracy: 0.1724 - val_loss: 3.4052 - val_sparse_categorical_accuracy: 0.1700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    retrain(32)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 53s - loss: 3.5100 - sparse_categorical_accuracy: 0.1637 - val_loss: 3.4454 - val_sparse_categorical_accuracy: 0.1630\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4904 - sparse_categorical_accuracy: 0.1639 - val_loss: 3.4346 - val_sparse_categorical_accuracy: 0.1640\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4876 - sparse_categorical_accuracy: 0.1640 - val_loss: 3.4519 - val_sparse_categorical_accuracy: 0.1605\n",
      "\n",
      "1\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4874 - sparse_categorical_accuracy: 0.1648 - val_loss: 3.4797 - val_sparse_categorical_accuracy: 0.1690\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4813 - sparse_categorical_accuracy: 0.1647 - val_loss: 3.4718 - val_sparse_categorical_accuracy: 0.1690\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4767 - sparse_categorical_accuracy: 0.1648 - val_loss: 3.4736 - val_sparse_categorical_accuracy: 0.1690\n",
      "\n",
      "2\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4987 - sparse_categorical_accuracy: 0.1594 - val_loss: 3.4760 - val_sparse_categorical_accuracy: 0.1625\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4986 - sparse_categorical_accuracy: 0.1600 - val_loss: 3.4667 - val_sparse_categorical_accuracy: 0.1630\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4962 - sparse_categorical_accuracy: 0.1595 - val_loss: 3.4575 - val_sparse_categorical_accuracy: 0.1635\n",
      "\n",
      "3\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4860 - sparse_categorical_accuracy: 0.1663 - val_loss: 3.4905 - val_sparse_categorical_accuracy: 0.1690\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4819 - sparse_categorical_accuracy: 0.1659 - val_loss: 3.4826 - val_sparse_categorical_accuracy: 0.1690\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4789 - sparse_categorical_accuracy: 0.1658 - val_loss: 3.4806 - val_sparse_categorical_accuracy: 0.1690\n",
      "\n",
      "4\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.5019 - sparse_categorical_accuracy: 0.1632 - val_loss: 3.5258 - val_sparse_categorical_accuracy: 0.1685\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4968 - sparse_categorical_accuracy: 0.1632 - val_loss: 3.5175 - val_sparse_categorical_accuracy: 0.1685\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4979 - sparse_categorical_accuracy: 0.1632 - val_loss: 3.5257 - val_sparse_categorical_accuracy: 0.1685\n",
      "\n",
      "5\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4808 - sparse_categorical_accuracy: 0.1593 - val_loss: 3.5718 - val_sparse_categorical_accuracy: 0.1610\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4738 - sparse_categorical_accuracy: 0.1593 - val_loss: 3.5557 - val_sparse_categorical_accuracy: 0.1610\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4734 - sparse_categorical_accuracy: 0.1593 - val_loss: 3.5630 - val_sparse_categorical_accuracy: 0.1610\n",
      "\n",
      "6\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.5019 - sparse_categorical_accuracy: 0.1557 - val_loss: 3.4975 - val_sparse_categorical_accuracy: 0.1735\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.5072 - sparse_categorical_accuracy: 0.1557 - val_loss: 3.5037 - val_sparse_categorical_accuracy: 0.1735\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.5068 - sparse_categorical_accuracy: 0.1556 - val_loss: 3.4804 - val_sparse_categorical_accuracy: 0.1735\n",
      "\n",
      "7\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4732 - sparse_categorical_accuracy: 0.1693 - val_loss: 3.5164 - val_sparse_categorical_accuracy: 0.1585\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4706 - sparse_categorical_accuracy: 0.1690 - val_loss: 3.5377 - val_sparse_categorical_accuracy: 0.1560\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4729 - sparse_categorical_accuracy: 0.1693 - val_loss: 3.5211 - val_sparse_categorical_accuracy: 0.1585\n",
      "\n",
      "8\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4931 - sparse_categorical_accuracy: 0.1617 - val_loss: 3.4933 - val_sparse_categorical_accuracy: 0.1520\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4905 - sparse_categorical_accuracy: 0.1613 - val_loss: 3.4882 - val_sparse_categorical_accuracy: 0.1520\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4881 - sparse_categorical_accuracy: 0.1613 - val_loss: 3.4964 - val_sparse_categorical_accuracy: 0.1520\n",
      "\n",
      "9\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4896 - sparse_categorical_accuracy: 0.1642 - val_loss: 3.4826 - val_sparse_categorical_accuracy: 0.1550\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4890 - sparse_categorical_accuracy: 0.1643 - val_loss: 3.4764 - val_sparse_categorical_accuracy: 0.1550\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 52s - loss: 3.4852 - sparse_categorical_accuracy: 0.1643 - val_loss: 3.4809 - val_sparse_categorical_accuracy: 0.1550\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    retrain(64)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 71s - loss: 3.4853 - sparse_categorical_accuracy: 0.1654 - val_loss: 3.4380 - val_sparse_categorical_accuracy: 0.1610\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4824 - sparse_categorical_accuracy: 0.1654 - val_loss: 3.4380 - val_sparse_categorical_accuracy: 0.1610\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4814 - sparse_categorical_accuracy: 0.1654 - val_loss: 3.4492 - val_sparse_categorical_accuracy: 0.1610\n",
      "\n",
      "1\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4795 - sparse_categorical_accuracy: 0.1636 - val_loss: 3.4621 - val_sparse_categorical_accuracy: 0.1825\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4792 - sparse_categorical_accuracy: 0.1636 - val_loss: 3.4416 - val_sparse_categorical_accuracy: 0.1825\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4739 - sparse_categorical_accuracy: 0.1636 - val_loss: 3.4335 - val_sparse_categorical_accuracy: 0.1825\n",
      "\n",
      "2\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 71s - loss: 3.4776 - sparse_categorical_accuracy: 0.1662 - val_loss: 3.5012 - val_sparse_categorical_accuracy: 0.1685\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 72s - loss: 3.4785 - sparse_categorical_accuracy: 0.1662 - val_loss: 3.4870 - val_sparse_categorical_accuracy: 0.1685\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 71s - loss: 3.4778 - sparse_categorical_accuracy: 0.1662 - val_loss: 3.4872 - val_sparse_categorical_accuracy: 0.1685\n",
      "\n",
      "3\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 71s - loss: 3.4654 - sparse_categorical_accuracy: 0.1709 - val_loss: 3.5083 - val_sparse_categorical_accuracy: 0.1615\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 71s - loss: 3.4577 - sparse_categorical_accuracy: 0.1709 - val_loss: 3.5077 - val_sparse_categorical_accuracy: 0.1615\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 71s - loss: 3.4610 - sparse_categorical_accuracy: 0.1709 - val_loss: 3.5089 - val_sparse_categorical_accuracy: 0.1615\n",
      "\n",
      "4\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 71s - loss: 3.4723 - sparse_categorical_accuracy: 0.1697 - val_loss: 3.4541 - val_sparse_categorical_accuracy: 0.1710\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4706 - sparse_categorical_accuracy: 0.1697 - val_loss: 3.4580 - val_sparse_categorical_accuracy: 0.1710\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4703 - sparse_categorical_accuracy: 0.1697 - val_loss: 3.4525 - val_sparse_categorical_accuracy: 0.1710\n",
      "\n",
      "5\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4764 - sparse_categorical_accuracy: 0.1679 - val_loss: 3.4746 - val_sparse_categorical_accuracy: 0.1725\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4721 - sparse_categorical_accuracy: 0.1679 - val_loss: 3.4800 - val_sparse_categorical_accuracy: 0.1725\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4740 - sparse_categorical_accuracy: 0.1679 - val_loss: 3.4809 - val_sparse_categorical_accuracy: 0.1725\n",
      "\n",
      "6\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4554 - sparse_categorical_accuracy: 0.1721 - val_loss: 3.4706 - val_sparse_categorical_accuracy: 0.1695\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4529 - sparse_categorical_accuracy: 0.1721 - val_loss: 3.4801 - val_sparse_categorical_accuracy: 0.1695\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4529 - sparse_categorical_accuracy: 0.1721 - val_loss: 3.4719 - val_sparse_categorical_accuracy: 0.1695\n",
      "\n",
      "7\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4550 - sparse_categorical_accuracy: 0.1684 - val_loss: 3.4534 - val_sparse_categorical_accuracy: 0.1685\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4553 - sparse_categorical_accuracy: 0.1684 - val_loss: 3.4444 - val_sparse_categorical_accuracy: 0.1685\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4544 - sparse_categorical_accuracy: 0.1684 - val_loss: 3.4495 - val_sparse_categorical_accuracy: 0.1685\n",
      "\n",
      "8\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4517 - sparse_categorical_accuracy: 0.1698 - val_loss: 3.4384 - val_sparse_categorical_accuracy: 0.1615\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4496 - sparse_categorical_accuracy: 0.1698 - val_loss: 3.4467 - val_sparse_categorical_accuracy: 0.1615\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4483 - sparse_categorical_accuracy: 0.1698 - val_loss: 3.4474 - val_sparse_categorical_accuracy: 0.1615\n",
      "\n",
      "9\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4565 - sparse_categorical_accuracy: 0.1686 - val_loss: 3.4631 - val_sparse_categorical_accuracy: 0.1660\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4538 - sparse_categorical_accuracy: 0.1686 - val_loss: 3.4729 - val_sparse_categorical_accuracy: 0.1660\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 70s - loss: 3.4551 - sparse_categorical_accuracy: 0.1686 - val_loss: 3.4647 - val_sparse_categorical_accuracy: 0.1660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    retrain(128)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable             Type              Data/Info\n",
      "------------------------------------------------\n",
      "Bidirectional        type              <class 'keras.layers.wrappers.Bidirectional'>\n",
      "Conv1D               type              <class 'keras.layers.convolutional.Conv1D'>\n",
      "ConvHyper            type              <class '__main__.ConvHyper'>\n",
      "DeconvHyper          type              <class '__main__.DeconvHyper'>\n",
      "Dense                type              <class 'keras.layers.core.Dense'>\n",
      "Dropout              type              <class 'keras.layers.core.Dropout'>\n",
      "Embedding            type              <class 'keras.layers.embeddings.Embedding'>\n",
      "EmbeddingHyper       type              <class '__main__.EmbeddingHyper'>\n",
      "GRU                  type              <class 'keras.layers.recurrent.GRU'>\n",
      "Input                function          <function Input at 0x7f34fa45cc80>\n",
      "LSTM                 type              <class 'keras.layers.recurrent.LSTM'>\n",
      "Model                type              <class 'keras.engine.training.Model'>\n",
      "ReHyper              function          <function ReHyper at 0x7f341ec6b0d0>\n",
      "RnnCnnHyper          type              <class '__main__.RnnCnnHyper'>\n",
      "RnnHyper             type              <class '__main__.RnnHyper'>\n",
      "UpSampling1D         type              <class 'keras.layers.convolutional.UpSampling1D'>\n",
      "bytelevel            module            <module 'bytelevel' from '../bytelevel.py'>\n",
      "conv                 Conv1D            <keras.layers.convolution<...>object at 0x7f341844d780>\n",
      "conv0                Conv1D            <keras.layers.convolution<...>object at 0x7f33e0608a58>\n",
      "conv1                Conv1D            <keras.layers.convolution<...>object at 0x7f33eb61d908>\n",
      "conv_h               ConvHyper         <__main__.ConvHyper object at 0x7f33eb8581d0>\n",
      "dataset              function          <function dataset at 0x7f33e28c9b70>\n",
      "drop                 Dropout           <keras.layers.core.Dropou<...>object at 0x7f33e235d2b0>\n",
      "drop1                Dropout           <keras.layers.core.Dropou<...>object at 0x7f33f4188518>\n",
      "drop2                Dropout           <keras.layers.core.Dropou<...>object at 0x7f33ed002f98>\n",
      "embed                Embedding         <keras.layers.embeddings.<...>object at 0x7f33e2659978>\n",
      "embed_h              EmbeddingHyper    <__main__.EmbeddingHyper <...>object at 0x7f33eb8586d8>\n",
      "explore              function          <function explore at 0x7f354ff1b6a8>\n",
      "fetch_20newsgroups   function          <function fetch_20newsgroups at 0x7f34f0412a60>\n",
      "h                    Tensor            Tensor(\"probs_71/Softmax:<...>=(?, 256), dtype=float32)\n",
      "histories            list              n=30\n",
      "history              History           <keras.callbacks.History <...>object at 0x7f33dc643128>\n",
      "hyper                RnnCnnHyper       <__main__.RnnCnnHyper object at 0x7f33fc99c710>\n",
      "i                    int               9\n",
      "max_len              int               64\n",
      "model                Model             <keras.engine.training.Mo<...>object at 0x7f33de116b70>\n",
      "np                   module            <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "pad_sequences        function          <function pad_sequences at 0x7f34db7dbbf8>\n",
      "pickle               module            <module 'pickle' from '/u<...>lib/python3.6/pickle.py'>\n",
      "pprint               function          <function pprint at 0x7f356d6a0400>\n",
      "pred                 Dense             <keras.layers.core.Dense <...>object at 0x7f33e061a550>\n",
      "r                    RandomState       <mtrand.RandomState object at 0x7f34f03c9c60>\n",
      "random_chop          function          <function random_chop at 0x7f34f03c6268>\n",
      "retrain              function          <function retrain at 0x7f33f41a5ea0>\n",
      "rnn                  Bidirectional     <keras.layers.wrappers.Bi<...>object at 0x7f33e061a2b0>\n",
      "rnn_h                RnnHyper          <__main__.RnnHyper object at 0x7f33eb858da0>\n",
      "seed                 int               62245\n",
      "sys                  module            <module 'sys' (built-in)>\n",
      "test                 Bunch             {'data': ['From: v064mb9k<...>tion_20newsgroups.py`\\n'}\n",
      "train                Bunch             {'data': [\"From: lerxst@w<...>tion_20newsgroups.py`\\n'}\n",
      "val_acc              function          <function <lambda> at 0x7f341981b840>\n",
      "x                    Tensor            Tensor(\"text_input_59:0\",<...>pe=(?, ?), dtype=float32)\n",
      "x_test               ndarray           2000x65: 130000 elems, type `int32`, 520000 bytes (507.8125 kb)\n",
      "x_train              ndarray           11314x65: 735410 elems, type `int32`, 2941640 bytes (2.8053665161132812 Mb)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_h = EmbeddingHyper(256, 128)\n",
    "conv_h = ConvHyper(128, 6, 4)\n",
    "rnn_h = RnnHyper(128, is_lstm=False, is_bidirectional=False)\n",
    "hyper = RnnCnnHyper(embed_h, conv_h, rnn_h)\n",
    "dec_h = DeconvHyper(128, 6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec, up = dec_h.make_layer('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb, con, rnn, den = hyper.make_layers('', return_sequences=False)\n",
    "dernn = GRU(128, return_sequences=True, unroll=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tden = TimeDistributed(den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 64, 128)\n",
      "(?, 16, 128)\n",
      "(?, 128)\n",
      "(?, 16, 128)\n",
      "(?, 16, 128)\n",
      "(?, 64, 128)\n",
      "(?, 64, 128)\n",
      "(?, 64, 256)\n"
     ]
    }
   ],
   "source": [
    "x = Input(shape=(max_len,), name='text_input')\n",
    "h = emb(x)\n",
    "print(h.shape)\n",
    "h = con(h)\n",
    "print(h.shape)\n",
    "h = rnn(h)\n",
    "print(h.shape)\n",
    "h = RepeatVector(16)(h)\n",
    "print(h.shape)\n",
    "h = dernn(h)\n",
    "print(h.shape)\n",
    "h = up(h)\n",
    "print(h.shape)\n",
    "h = dec(h)\n",
    "print(h.shape)\n",
    "h = tden(h)\n",
    "print(h.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(x, h)\n",
    "model.compile(optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/norvig/big.txt', 'r') as f:\n",
    "    big = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg EBook of The Adventures of Sherlock Holmes\\nby Sir Arthur Conan Doyle\\n(#15 in our series by Sir Arthur Conan Doyle)\\n\\nCopyright laws are changing all over the world. Be sure to check the\\ncopyright laws for your country before downloading or redistributing\\nthis or any other Project Gutenberg eBook.\\n\\nThis header should be the first thing seen when viewing this Project\\nGutenberg file.  Please do not remove it.  Do not change or edit the\\nheader without written permission.\\n\\nPlease read the \"legal small print,\" and other information about the\\neBook and Project Gutenberg at the bottom of this file.  Included is\\nimportant information about your specific rights and restrictions in\\nhow the file may be used.  You can also find out about how to make a\\ndonation to Project Gutenberg, and how to get involved.\\n\\n\\n**Welcome To The World of Free Plain Vanilla Electronic Texts**\\n\\n**eBooks Readable By Both Humans and By Computers, Since 1971**\\n\\n*****These eBooks Were Prepared By Thousan'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6488666"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_chunks = [big[i:i+100000] for i in range(0, len(big), 100000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(big_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.shuffle(big_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_train = ''.join(big_chunks[:55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_test = ''.join(big_chunks[55:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_data(max_len, n, r):\n",
    "    def random_slice(data):\n",
    "        i = r.randint(len(data) - max_len)\n",
    "        return data[i : i + max_len]\n",
    "    train = [random_slice(big_train) for _ in range(n)]\n",
    "    test = [random_slice(big_test) for _ in range(int(0.1 * n))]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoData(object):\n",
    "    def __init__(self, text, max_len):\n",
    "        self.text = text\n",
    "        self.max_len = max_len\n",
    "        x = bytelevel.encode(text)\n",
    "        self.x = pad_sequences(x, max_len)\n",
    "        self.y = bytelevel.onehot(self.x)\n",
    "        \n",
    "    @staticmethod\n",
    "    def Random(max_len, n, r):\n",
    "        train, test = big_data(max_len, n, r)\n",
    "        return AutoData(train, max_len), AutoData(test, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = AutoData.Random(max_len, 10000, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 43s - loss: 3.1414 - categorical_accuracy: 0.1587 - val_loss: 3.1124 - val_categorical_accuracy: 0.1576\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train.x, \n",
    "             y=train.y,\n",
    "            epochs=1, batch_size=10,\n",
    "            validation_data=(test.x, test.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 65)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 27s - loss: 3.0283 - categorical_accuracy: 0.1605 - val_loss: 2.9872 - val_categorical_accuracy: 0.1629\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.9185 - categorical_accuracy: 0.1653 - val_loss: 2.8777 - val_categorical_accuracy: 0.1697\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.8254 - categorical_accuracy: 0.1715 - val_loss: 2.8015 - val_categorical_accuracy: 0.1743\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.7422 - categorical_accuracy: 0.1781 - val_loss: 2.7191 - val_categorical_accuracy: 0.1811\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.6677 - categorical_accuracy: 0.1856 - val_loss: 2.6568 - val_categorical_accuracy: 0.1900\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.6003 - categorical_accuracy: 0.1937 - val_loss: 2.5967 - val_categorical_accuracy: 0.1961\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.5405 - categorical_accuracy: 0.2023 - val_loss: 2.5435 - val_categorical_accuracy: 0.2049\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.4838 - categorical_accuracy: 0.2106 - val_loss: 2.5044 - val_categorical_accuracy: 0.2112\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.4313 - categorical_accuracy: 0.2190 - val_loss: 2.4600 - val_categorical_accuracy: 0.2177\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.3808 - categorical_accuracy: 0.2285 - val_loss: 2.4196 - val_categorical_accuracy: 0.2277\n",
      "\n",
      "1\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.3678 - categorical_accuracy: 0.2317 - val_loss: 2.3431 - val_categorical_accuracy: 0.2433\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.3053 - categorical_accuracy: 0.2440 - val_loss: 2.3106 - val_categorical_accuracy: 0.2511\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.2515 - categorical_accuracy: 0.2563 - val_loss: 2.2715 - val_categorical_accuracy: 0.2609\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.2003 - categorical_accuracy: 0.2688 - val_loss: 2.2372 - val_categorical_accuracy: 0.2706\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.1547 - categorical_accuracy: 0.2819 - val_loss: 2.1942 - val_categorical_accuracy: 0.2846\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.1086 - categorical_accuracy: 0.2958 - val_loss: 2.1501 - val_categorical_accuracy: 0.2988\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.0653 - categorical_accuracy: 0.3099 - val_loss: 2.1149 - val_categorical_accuracy: 0.3077\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 27s - loss: 2.0237 - categorical_accuracy: 0.3251 - val_loss: 2.0881 - val_categorical_accuracy: 0.3227\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.9791 - categorical_accuracy: 0.3434 - val_loss: 2.0361 - val_categorical_accuracy: 0.3401\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 28s - loss: 1.9309 - categorical_accuracy: 0.3642 - val_loss: 1.9917 - val_categorical_accuracy: 0.3632\n",
      "\n",
      "2\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 28s - loss: 1.9358 - categorical_accuracy: 0.3776 - val_loss: 1.9013 - val_categorical_accuracy: 0.3958\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 28s - loss: 1.8422 - categorical_accuracy: 0.4089 - val_loss: 1.8454 - val_categorical_accuracy: 0.4174\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.7696 - categorical_accuracy: 0.4334 - val_loss: 1.7986 - val_categorical_accuracy: 0.4330\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 28s - loss: 1.7011 - categorical_accuracy: 0.4558 - val_loss: 1.7257 - val_categorical_accuracy: 0.4578\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 28s - loss: 1.6359 - categorical_accuracy: 0.4785 - val_loss: 1.6780 - val_categorical_accuracy: 0.4742\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 28s - loss: 1.5700 - categorical_accuracy: 0.5008 - val_loss: 1.6266 - val_categorical_accuracy: 0.4942\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 28s - loss: 1.5125 - categorical_accuracy: 0.5197 - val_loss: 1.5717 - val_categorical_accuracy: 0.5092\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 28s - loss: 1.4554 - categorical_accuracy: 0.5385 - val_loss: 1.5141 - val_categorical_accuracy: 0.5266\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 28s - loss: 1.4041 - categorical_accuracy: 0.5548 - val_loss: 1.4804 - val_categorical_accuracy: 0.5396\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 28s - loss: 1.3567 - categorical_accuracy: 0.5688 - val_loss: 1.4384 - val_categorical_accuracy: 0.5537\n",
      "\n",
      "3\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 28s - loss: 1.3702 - categorical_accuracy: 0.5668 - val_loss: 1.3718 - val_categorical_accuracy: 0.5698\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.2908 - categorical_accuracy: 0.5893 - val_loss: 1.3368 - val_categorical_accuracy: 0.5821\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.2412 - categorical_accuracy: 0.6048 - val_loss: 1.3017 - val_categorical_accuracy: 0.5928\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.2035 - categorical_accuracy: 0.6157 - val_loss: 1.2831 - val_categorical_accuracy: 0.5979\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.1734 - categorical_accuracy: 0.6241 - val_loss: 1.2854 - val_categorical_accuracy: 0.5981\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.1484 - categorical_accuracy: 0.6319 - val_loss: 1.2566 - val_categorical_accuracy: 0.6069\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.1240 - categorical_accuracy: 0.6396 - val_loss: 1.2356 - val_categorical_accuracy: 0.6147\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.1019 - categorical_accuracy: 0.6455 - val_loss: 1.2159 - val_categorical_accuracy: 0.6197\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.0856 - categorical_accuracy: 0.6509 - val_loss: 1.2079 - val_categorical_accuracy: 0.6222\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 28s - loss: 1.0668 - categorical_accuracy: 0.6568 - val_loss: 1.2059 - val_categorical_accuracy: 0.6230\n",
      "\n",
      "4\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.1358 - categorical_accuracy: 0.6387 - val_loss: 1.1562 - val_categorical_accuracy: 0.6335\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.0862 - categorical_accuracy: 0.6524 - val_loss: 1.1307 - val_categorical_accuracy: 0.6427\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.0571 - categorical_accuracy: 0.6617 - val_loss: 1.1299 - val_categorical_accuracy: 0.6410\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.0381 - categorical_accuracy: 0.6670 - val_loss: 1.1169 - val_categorical_accuracy: 0.6439\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 27s - loss: 1.0196 - categorical_accuracy: 0.6721 - val_loss: 1.1335 - val_categorical_accuracy: 0.6437\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 28s - loss: 1.0022 - categorical_accuracy: 0.6776 - val_loss: 1.1168 - val_categorical_accuracy: 0.6471\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.9866 - categorical_accuracy: 0.6828 - val_loss: 1.1017 - val_categorical_accuracy: 0.6514\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.9753 - categorical_accuracy: 0.6859 - val_loss: 1.0929 - val_categorical_accuracy: 0.6534\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.9618 - categorical_accuracy: 0.6895 - val_loss: 1.0898 - val_categorical_accuracy: 0.6556\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 26s - loss: 0.9525 - categorical_accuracy: 0.6921 - val_loss: 1.0833 - val_categorical_accuracy: 0.6579\n",
      "\n",
      "5\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 26s - loss: 1.0293 - categorical_accuracy: 0.6710 - val_loss: 1.0549 - val_categorical_accuracy: 0.6670\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 26s - loss: 0.9840 - categorical_accuracy: 0.6848 - val_loss: 1.0535 - val_categorical_accuracy: 0.6688\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 26s - loss: 0.9625 - categorical_accuracy: 0.6905 - val_loss: 1.0282 - val_categorical_accuracy: 0.6768\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.9449 - categorical_accuracy: 0.6955 - val_loss: 1.0299 - val_categorical_accuracy: 0.6749\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.9296 - categorical_accuracy: 0.7006 - val_loss: 1.0207 - val_categorical_accuracy: 0.6819\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.9167 - categorical_accuracy: 0.7037 - val_loss: 1.0242 - val_categorical_accuracy: 0.6799\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.9048 - categorical_accuracy: 0.7071 - val_loss: 1.0297 - val_categorical_accuracy: 0.6773\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8924 - categorical_accuracy: 0.7114 - val_loss: 1.0052 - val_categorical_accuracy: 0.6870\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8799 - categorical_accuracy: 0.7152 - val_loss: 1.0185 - val_categorical_accuracy: 0.6823\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8737 - categorical_accuracy: 0.7167 - val_loss: 1.0040 - val_categorical_accuracy: 0.6872\n",
      "\n",
      "6\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.9473 - categorical_accuracy: 0.6966 - val_loss: 0.9790 - val_categorical_accuracy: 0.6871\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.9051 - categorical_accuracy: 0.7090 - val_loss: 0.9602 - val_categorical_accuracy: 0.6953\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8840 - categorical_accuracy: 0.7153 - val_loss: 0.9558 - val_categorical_accuracy: 0.6963\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8683 - categorical_accuracy: 0.7197 - val_loss: 0.9751 - val_categorical_accuracy: 0.6913\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8582 - categorical_accuracy: 0.7229 - val_loss: 0.9659 - val_categorical_accuracy: 0.6937\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8459 - categorical_accuracy: 0.7264 - val_loss: 0.9620 - val_categorical_accuracy: 0.6965\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.8349 - categorical_accuracy: 0.7295 - val_loss: 0.9506 - val_categorical_accuracy: 0.6997\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8269 - categorical_accuracy: 0.7321 - val_loss: 0.9719 - val_categorical_accuracy: 0.6938\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8190 - categorical_accuracy: 0.7342 - val_loss: 0.9583 - val_categorical_accuracy: 0.6975\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8095 - categorical_accuracy: 0.7373 - val_loss: 0.9473 - val_categorical_accuracy: 0.7012\n",
      "\n",
      "7\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8932 - categorical_accuracy: 0.7136 - val_loss: 0.9025 - val_categorical_accuracy: 0.7113\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8521 - categorical_accuracy: 0.7255 - val_loss: 0.9139 - val_categorical_accuracy: 0.7098\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8323 - categorical_accuracy: 0.7314 - val_loss: 0.9171 - val_categorical_accuracy: 0.7082\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.8207 - categorical_accuracy: 0.7340 - val_loss: 0.8991 - val_categorical_accuracy: 0.7128\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8094 - categorical_accuracy: 0.7378 - val_loss: 0.9031 - val_categorical_accuracy: 0.7126\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.7978 - categorical_accuracy: 0.7411 - val_loss: 0.8981 - val_categorical_accuracy: 0.7152\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.7914 - categorical_accuracy: 0.7432 - val_loss: 0.9092 - val_categorical_accuracy: 0.7118\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.7808 - categorical_accuracy: 0.7463 - val_loss: 0.9002 - val_categorical_accuracy: 0.7142\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.7743 - categorical_accuracy: 0.7479 - val_loss: 0.8987 - val_categorical_accuracy: 0.7148\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.7686 - categorical_accuracy: 0.7503 - val_loss: 0.9098 - val_categorical_accuracy: 0.7148\n",
      "\n",
      "8\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.8519 - categorical_accuracy: 0.7267 - val_loss: 0.8912 - val_categorical_accuracy: 0.7184\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.8110 - categorical_accuracy: 0.7384 - val_loss: 0.8682 - val_categorical_accuracy: 0.7261\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.7930 - categorical_accuracy: 0.7438 - val_loss: 0.8703 - val_categorical_accuracy: 0.7257\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.7809 - categorical_accuracy: 0.7473 - val_loss: 0.8820 - val_categorical_accuracy: 0.7254\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.7700 - categorical_accuracy: 0.7498 - val_loss: 0.8733 - val_categorical_accuracy: 0.7242\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.7592 - categorical_accuracy: 0.7537 - val_loss: 0.8822 - val_categorical_accuracy: 0.7239\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.7518 - categorical_accuracy: 0.7557 - val_loss: 0.8766 - val_categorical_accuracy: 0.7253\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.7457 - categorical_accuracy: 0.7575 - val_loss: 0.8840 - val_categorical_accuracy: 0.7251\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.7397 - categorical_accuracy: 0.7592 - val_loss: 0.8760 - val_categorical_accuracy: 0.7249\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.7312 - categorical_accuracy: 0.7617 - val_loss: 0.8722 - val_categorical_accuracy: 0.7265\n",
      "\n",
      "9\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.8169 - categorical_accuracy: 0.7378 - val_loss: 0.8360 - val_categorical_accuracy: 0.7344\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.7754 - categorical_accuracy: 0.7499 - val_loss: 0.8466 - val_categorical_accuracy: 0.7322\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.7609 - categorical_accuracy: 0.7541 - val_loss: 0.8444 - val_categorical_accuracy: 0.7338\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.7477 - categorical_accuracy: 0.7578 - val_loss: 0.8382 - val_categorical_accuracy: 0.7357\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.7351 - categorical_accuracy: 0.7619 - val_loss: 0.8267 - val_categorical_accuracy: 0.7372\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.7275 - categorical_accuracy: 0.7643 - val_loss: 0.8283 - val_categorical_accuracy: 0.7396\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 28s - loss: 0.7188 - categorical_accuracy: 0.7667 - val_loss: 0.8412 - val_categorical_accuracy: 0.7362\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 27s - loss: 0.7135 - categorical_accuracy: 0.7683 - val_loss: 0.8360 - val_categorical_accuracy: 0.7366\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.7069 - categorical_accuracy: 0.7701 - val_loss: 0.8405 - val_categorical_accuracy: 0.7368\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 27s - loss: 0.7028 - categorical_accuracy: 0.7715 - val_loss: 0.8315 - val_categorical_accuracy: 0.7396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    train, test = AutoData.Random(max_len, 10000, r)\n",
    "    history = model.fit(x=train.x, \n",
    "            y=train.y,\n",
    "            epochs=10, batch_size=10,\n",
    "            validation_data=(test.x, test.y))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s love had\\nended.  he did not need an  fang if shas sand. He aee',\n",
       " 'a parade dons not betin tilt all the droose ars aleebbled,\" sho ',\n",
       " ' promoter, began to interess him sa salaly that theequustion tth',\n",
       " 'st to that grandhuv, the\\nsispalss pateeven terdeeness. His aft e']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytelevel.prediction2str(model.predict(test.x[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s love had\\nended. \"He did not need anything of that kind. He nei',\n",
       " 'a parade does not begin till all the troops are\\nassembled,\" said',\n",
       " ' promoter,\\nbegan to interest him so keenly that the question of ',\n",
       " 'st to that grandeur, the\\nsimplest paternal tenderness. His eyes ']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.text[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
