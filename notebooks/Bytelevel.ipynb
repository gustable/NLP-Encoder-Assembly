{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from text_vae import Hyper, TextVae\n",
    "import bytelevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_20newsgroups(subset='train')\n",
    "test = fetch_20newsgroups(subset='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 52\n",
    "r = np.random.RandomState(42)\n",
    "\n",
    "def random_chop(s, r, m):\n",
    "    n = len(s)\n",
    "    if n <= m:\n",
    "        return s\n",
    "    k = r.randint(n - m)\n",
    "    s = s[k:]\n",
    "    return s[:m]\n",
    "\n",
    "def dataset(x):\n",
    "    x = [random_chop(s, r, maxlen + 1) for s in x]\n",
    "    x = bytelevel.encode(x)\n",
    "    x = pad_sequences(x, maxlen + 1)\n",
    "    return x\n",
    "\n",
    "x_train = dataset(train['data'])\n",
    "x_test = dataset(test['data'])\n",
    "x_test = x_test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = Hyper(vocab_size=256, max_length=50)\n",
    "model = TextVae(hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_input',\n",
       " 'embedder',\n",
       " 'encoder_rnn_1',\n",
       " 'encoder_rnn_2',\n",
       " 'encoder_output',\n",
       " 'dense_1',\n",
       " 'dense_2',\n",
       " 'lambda_1',\n",
       " 'repeat_vector_1',\n",
       " 'decoder_rnn_1',\n",
       " 'decoder_rnn_2',\n",
       " 'decoded_mean']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[foo.name for foo in model.vae.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "x = Input(shape=(hyper.max_length,), name='text_input_kinder')\n",
    "h = model.embedder(x)\n",
    "h = model.encoder_rnn_1(h)\n",
    "h = model.encoder_rnn_2(h)\n",
    "p = Dense(256, activation='softmax')(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "kindergarten = Model(x, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kindergarten.compile(optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "11314/11314 [==============================] - 570s - loss: 3.1966 - sparse_categorical_accuracy: 0.2098 - val_loss: 2.8093 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 2/10\n",
      "11314/11314 [==============================] - 568s - loss: 2.7245 - sparse_categorical_accuracy: 0.2849 - val_loss: 2.6421 - val_sparse_categorical_accuracy: 0.3105\n",
      "Epoch 3/10\n",
      "11314/11314 [==============================] - 570s - loss: 2.4875 - sparse_categorical_accuracy: 0.3322 - val_loss: 2.4964 - val_sparse_categorical_accuracy: 0.3420\n",
      "Epoch 4/10\n",
      "11314/11314 [==============================] - 570s - loss: 2.1725 - sparse_categorical_accuracy: 0.3929 - val_loss: 2.4131 - val_sparse_categorical_accuracy: 0.3575\n",
      "Epoch 5/10\n",
      "11314/11314 [==============================] - 570s - loss: 1.8100 - sparse_categorical_accuracy: 0.4808 - val_loss: 2.4482 - val_sparse_categorical_accuracy: 0.3655\n",
      "Epoch 6/10\n",
      "11314/11314 [==============================] - 586s - loss: 1.3891 - sparse_categorical_accuracy: 0.5904 - val_loss: 2.5859 - val_sparse_categorical_accuracy: 0.3595\n",
      "Epoch 7/10\n",
      "11314/11314 [==============================] - 616s - loss: 0.9896 - sparse_categorical_accuracy: 0.7142 - val_loss: 2.7252 - val_sparse_categorical_accuracy: 0.3630\n",
      "Epoch 8/10\n",
      "11314/11314 [==============================] - 616s - loss: 0.5730 - sparse_categorical_accuracy: 0.8480 - val_loss: 2.9766 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 9/10\n",
      "11314/11314 [==============================] - 612s - loss: 0.2720 - sparse_categorical_accuracy: 0.9397 - val_loss: 3.1808 - val_sparse_categorical_accuracy: 0.3540\n",
      "Epoch 10/10\n",
      "11314/11314 [==============================] - 605s - loss: 0.1436 - sparse_categorical_accuracy: 0.9741 - val_loss: 3.4060 - val_sparse_categorical_accuracy: 0.3480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ede68f828>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kindergarten.fit(x=x_train[:, :50], \n",
    "                 y=x_train[:, 50],\n",
    "                epochs=10, batch_size=10,\n",
    "                validation_data=(x_test[:, :50], x_test[:, 50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[121,  32, 115, ..., 101, 114,  10],\n",
       "       [ 73,  76,  76, ...,  83,  65,  10],\n",
       "       [116, 104, 101, ..., 101, 119,  10],\n",
       "       ...,\n",
       "       [103, 115,  32, ..., 100, 117,  10],\n",
       "       [110, 121, 111, ..., 110,  97,  10],\n",
       "       [117, 114, 101, ..., 115,  45,  10]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_kinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11314 samples, validate on 7532 samples\n",
      "Epoch 1/2\n",
      "11314/11314 [==============================] - 929s - loss: 0.8339 - val_loss: 0.8180\n",
      "Epoch 2/2\n",
      "11314/11314 [==============================] - 926s - loss: 0.7804 - val_loss: 0.7688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5abe3f7048>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=x_train_one_hot, epochs=2, batch_size=10, validation_data=(x_test, x_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11314 samples, validate on 7532 samples\n",
      "Epoch 1/10\n",
      "11314/11314 [==============================] - 927s - loss: 0.7523 - val_loss: 0.7499\n",
      "Epoch 2/10\n",
      "11314/11314 [==============================] - 929s - loss: 0.7363 - val_loss: 0.7363\n",
      "Epoch 3/10\n",
      "11314/11314 [==============================] - 928s - loss: 0.7273 - val_loss: 0.7342\n",
      "Epoch 4/10\n",
      "11314/11314 [==============================] - 928s - loss: 0.7174 - val_loss: 0.7193\n",
      "Epoch 5/10\n",
      "11314/11314 [==============================] - 929s - loss: 0.7134 - val_loss: 0.7252\n",
      "Epoch 6/10\n",
      "11314/11314 [==============================] - 929s - loss: 0.7059 - val_loss: 0.7120\n",
      "Epoch 7/10\n",
      "11314/11314 [==============================] - 926s - loss: 0.6990 - val_loss: 0.7039\n",
      "Epoch 8/10\n",
      "11314/11314 [==============================] - 927s - loss: 0.6934 - val_loss: 0.6978\n",
      "Epoch 9/10\n",
      "11314/11314 [==============================] - 926s - loss: 0.6888 - val_loss: 0.6998\n",
      "Epoch 10/10\n",
      "11314/11314 [==============================] - 932s - loss: 0.6848 - val_loss: 0.6959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5a306853c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=x_train_one_hot, epochs=10, batch_size=10, validation_data=(x_test, x_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11314 samples, validate on 7532 samples\n",
      "Epoch 1/4\n",
      "11314/11314 [==============================] - 928s - loss: 0.6804 - val_loss: 0.6862\n",
      "Epoch 2/4\n",
      "11314/11314 [==============================] - 930s - loss: 0.6746 - val_loss: 0.6835\n",
      "Epoch 3/4\n",
      "11314/11314 [==============================] - 929s - loss: 0.6697 - val_loss: 0.6869\n",
      "Epoch 4/4\n",
      "11314/11314 [==============================] - 929s - loss: 0.6644 - val_loss: 0.6821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5a31e0b358>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=x_train_one_hot, epochs=4, batch_size=10, validation_data=(x_test, x_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11314 samples, validate on 7532 samples\n",
      "Epoch 1/4\n",
      "11314/11314 [==============================] - 928s - loss: 0.6639 - val_loss: 0.6757\n",
      "Epoch 2/4\n",
      "11314/11314 [==============================] - 928s - loss: 0.6582 - val_loss: 0.6782\n",
      "Epoch 3/4\n",
      "11314/11314 [==============================] - 928s - loss: 0.6537 - val_loss: 0.6731\n",
      "Epoch 4/4\n",
      "11314/11314 [==============================] - 927s - loss: 0.6510 - val_loss: 0.6783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5a31e0b2e8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=x_train_one_hot, epochs=4, batch_size=10, validation_data=(x_test, x_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 32, 115, 117, 109, 109, 101, 114,  32, 105, 115,  32, 116, 104,\n",
       "        101,  32,  98, 101, 115, 116,  32, 116, 105, 109, 101,  32, 116,\n",
       "        111,  32,  98, 117, 121,  46,  10,  10,   9,   9,   9,  78, 101,\n",
       "        105, 108,  32,  71,  97, 110, 100, 108, 101, 114,  10],\n",
       "       [ 76,  76,  69,  82,  32,  47,  47,  32,  49,  54,  50,  48,  51,\n",
       "         32,  87,  79,  79,  68,  83,  32,  47,  47,  32,  77,  85,  83,\n",
       "         75,  69,  71,  79,  44,  32,  87,  73,  83,  46,  32,  53,  51,\n",
       "         49,  53,  48,  32,  47,  47,  32,  85,  83,  65,  10],\n",
       "       [104, 101,  32, 110, 111, 110, 101, 120, 105, 115, 116, 101, 110,\n",
       "         99, 101,  32, 111, 102,  32,  71, 111, 100,  63,  10,  10,  73,\n",
       "        110,  32,  97,  32, 119, 111, 114, 100,  44,  32, 121, 101, 115,\n",
       "         46,  10,  10,  10, 109,  97, 116, 104, 101, 119,  10]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = model.encode(x_test[:3, :50])\n",
    "decode = model.generate(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ao                          ee..\\n\\n\\n\\naaa  \\n\\n\\naiee\\n',\n",
       " 'LIA                                             \\n\\n',\n",
       " 'oe                                 eee..\\n\\n\\n\\naiiee\\n']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytelevel.prediction2str(decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\\nSubject: Need info on 88-89 Bonneville\\nOrganization: University at Buffalo\\nLines: 10\\nNews-Software: VAX/VMS VNEWS 1.41\\nNntp-Posting-Host: ubvmsd.cc.buffalo.edu\\n\\n\\n I am a little confused on all of the models of the 88-89 bonnevilles.\\nI have heard of the LE SE LSE SSE SSEI. Could someone tell me the\\ndifferences are far as features or performance. I am also curious to\\nknow what the book value is for prefereably the 89 model. And how much\\nless than book value can you usually get them for. In other words how\\nmuch are they in demand this time of year. I have heard that the mid-spring\\nearly summer is the best time to buy.\\n\\n\\t\\t\\tNeil Gandler\\n',\n",
       " 'From: Rick Miller <rick@ee.uwm.edu>\\nSubject: X-Face?\\nOrganization: Just me.\\nLines: 17\\nDistribution: world\\nNNTP-Posting-Host: 129.89.2.33\\nSummary: Go ahead... swamp me.  <EEP!>\\n\\nI\\'m not familiar at all with the format of these \"X-Face:\" thingies, but\\nafter seeing them in some folks\\' headers, I\\'ve *got* to *see* them (and\\nmaybe make one of my own)!\\n\\nI\\'ve got \"dpg-view\" on my Linux box (which displays \"uncompressed X-Faces\")\\nand I\\'ve managed to compile [un]compface too... but now that I\\'m *looking*\\nfor them, I can\\'t seem to find any X-Face:\\'s in anyones news headers!  :-(\\n\\nCould you, would you, please send me your \"X-Face:\" header?\\n\\nI *know* I\\'ll probably get a little swamped, but I can handle it.\\n\\n\\t...I hope.\\n\\nRick Miller  <rick@ee.uwm.edu> | <ricxjo@discus.mil.wi.us>   Ricxjo Muelisto\\nSend a postcard, get one back! | Enposxtigu bildkarton kaj vi ricevos alion!\\n          RICK MILLER // 16203 WOODS // MUSKEGO, WIS. 53150 // USA\\n',\n",
       " 'From: mathew <mathew@mantis.co.uk>\\nSubject: Re: STRONG & weak Atheism\\nOrganization: Mantis Consultants, Cambridge. UK.\\nX-Newsreader: rusnews v1.02\\nLines: 9\\n\\nacooper@mac.cc.macalstr.edu (Turin Turambar, ME Department of Utter Misery) writes:\\n> Did that FAQ ever got modified to re-define strong atheists as not those who\\n> assert the nonexistence of God, but as those who assert that they BELIEVE in \\n> the nonexistence of God?\\n\\nIn a word, yes.\\n\\n\\nmathew\\n']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['data'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  e                         ee..\\n\\n\\t\\t\\taan   \\nerinn\\n',\n",
       " 'A                                              \\n\\n\\n',\n",
       " 'he                                eeee.\\n\\n\\n-aeneen\\n']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode = model.encode(x_test[:3, :50])\n",
    "decode = model.generate(encode)\n",
    "bytelevel.prediction2str(decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' an                        eee.\\n\\t\\t\\t\\t\\t-       eee\\n\\n',\n",
       " 'L5 E                                          F\\n\\n\\n',\n",
       " 'ho                                 eee..\\n\\n\\n-aaae\\n\\n']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode = model.encode(x_test[:3, :50])\n",
    "decode = model.generate(encode)\n",
    "bytelevel.prediction2str(decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
