{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bytelevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Conv1D, Input, GRU, LSTM, Bidirectional, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.RandomState(42)\n",
    "\n",
    "def random_chop(s, r, m):\n",
    "    n = len(s)\n",
    "    if n <= m:\n",
    "        return s\n",
    "    k = r.randint(n - m)\n",
    "    s = s[k:]\n",
    "    return s[:m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_20newsgroups(subset='train')\n",
    "test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "\n",
    "def dataset(x):\n",
    "    x = [random_chop(s, r, max_len + 1) for s in x]\n",
    "    x = bytelevel.encode(x)\n",
    "    x = pad_sequences(x, max_len + 1)\n",
    "    return x\n",
    "\n",
    "x_train = dataset(train['data'])\n",
    "x_test = dataset(test['data'])\n",
    "x_test = x_test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingHyper(object):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "    @staticmethod\n",
    "    def Random(r):\n",
    "        embedding_dim = r.choice([2 ** i for i in range(6, 10)])\n",
    "        return EmbeddingHyper(256, embedding_dim)\n",
    "        \n",
    "    def display(self):\n",
    "        print(\"embedding\")\n",
    "        print(\"vocab size=%d\" % self.vocab_size)\n",
    "        print(\"embedding dimension=%d\" % self.embedding_dim)\n",
    "        \n",
    "    def make_layer(self, name='embedder'):\n",
    "        return Embedding(self.vocab_size, \n",
    "            self.embedding_dim , name=name)\n",
    "    \n",
    "class ConvHyper(object):\n",
    "    def __init__(self, filters, kernel_size=3, stride=2):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        \n",
    "    @staticmethod\n",
    "    def Random(r):\n",
    "        filters = r.choice([2 ** i for i in range(6, 10)])\n",
    "        kernel_size = r.randint(8) + 2\n",
    "        stride = r.randint(4) + 1\n",
    "        return ConvHyper(filters, kernel_size, stride)\n",
    "        \n",
    "    def display(self):\n",
    "        print(\"conv 1d\")\n",
    "        print(\"filters=%d\" % self.filters)\n",
    "        print(\"kernel size=%d\" % self.kernel_size)\n",
    "        print(\"stride = %d\" % self.stride)\n",
    "        \n",
    "    def make_layer(self, name):\n",
    "        return Conv1D(64, 4, strides=2, activation='relu', name=name)\n",
    "    \n",
    "class RnnHyper(object):\n",
    "    def __init__(self, hidden_dim, is_lstm, is_bidirectional):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.is_lstm = is_lstm\n",
    "        self.is_bidirectional = is_bidirectional\n",
    "        \n",
    "    @staticmethod\n",
    "    def Random(r):\n",
    "        hidden_dim = r.choice([2 ** i for i in range(6, 10)])\n",
    "        is_lstm = bool(r.randint(2))\n",
    "        is_bidirectional = bool(r.randint(2))\n",
    "        return RnnHyper(hidden_dim, is_lstm, is_bidirectional)\n",
    "\n",
    "    def display(self):\n",
    "        print(\"RNN\")\n",
    "        print(\"hidden dimension=%d\" % self.hidden_dim)\n",
    "        if self.is_bidirectional:\n",
    "            print(\"bidirectional\")\n",
    "        if self.is_lstm:\n",
    "            print(\"lstm\")\n",
    "        else:\n",
    "            print(\"gru\")            \n",
    "        \n",
    "    def make_layer(self, name, return_sequences):\n",
    "        if self.is_lstm:\n",
    "            make_rnn = LSTM\n",
    "        else:\n",
    "            make_rnn = GRU\n",
    "        if self.is_bidirectional:\n",
    "            return Bidirectional(make_rnn(self.hidden_dim, return_sequences=return_sequences), name=name)\n",
    "        return make_rnn(self.hidden_dim, return_sequences=return_sequences, name=name)\n",
    "    \n",
    "class RnnCnnHyper(object):\n",
    "    def __init__(self, embedder, conv, rnn):\n",
    "        self.embedder = embedder\n",
    "        self.conv = conv\n",
    "        self.rnn = rnn\n",
    "        \n",
    "    @staticmethod\n",
    "    def Random(r):\n",
    "        embedder = EmbeddingHyper.Random(r)\n",
    "        conv = ConvHyper.Random(r)\n",
    "        rnn = RnnHyper.Random(r)\n",
    "        \n",
    "        return RnnCnnHyper(embedder, conv, rnn)\n",
    "\n",
    "    def display(self):\n",
    "        self.embedder.display()\n",
    "        print()\n",
    "        self.conv.display()\n",
    "        print()\n",
    "        self.rnn.display()\n",
    "        print()\n",
    "        \n",
    "    def make_layers(self, name, return_sequences):\n",
    "        if name is not None and len(name):\n",
    "            prefix = '%s_' % name\n",
    "        else:\n",
    "            prefix = ''\n",
    "        embedder = self.embedder.make_layer(name='%sembedder' % prefix)\n",
    "        conv = self.conv.make_layer(name='%sconv' % prefix)\n",
    "        rnn = self.rnn.make_layer(name='%srnn' % prefix, return_sequences=return_sequences)\n",
    "        dense = Dense(self.embedder.vocab_size, activation='softmax', name='%sprobs' % prefix)\n",
    "        return embedder, conv, rnn, dense\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def explore(seed, count, max_len):\n",
    "    r = np.random.RandomState(seed)\n",
    "    histories = []\n",
    "    \n",
    "    def dataset(x):\n",
    "        x = [random_chop(s, r, max_len + 1) for s in x]\n",
    "        x = bytelevel.encode(x)\n",
    "        x = pad_sequences(x, max_len + 1)\n",
    "        return x\n",
    "\n",
    "    x_train = dataset(train['data'])\n",
    "    x_test = dataset(test['data'])\n",
    "    x_test = x_test[:2000]\n",
    "\n",
    "    for i in range(count):\n",
    "        seed = r.randint(200000)\n",
    "        name = \"RnnCnn%d\" % seed\n",
    "        r_i = np.random.RandomState(seed)\n",
    "        hyper = RnnCnnHyper.Random(r_i)\n",
    "        hyper.display()\n",
    "\n",
    "        embed, conv, rnn, pred = hyper.make_layers('', False)\n",
    "\n",
    "        x = Input(shape=(max_len,), name='text_input')\n",
    "        h = embed(x)\n",
    "        print(h.shape)\n",
    "        h = conv(h)\n",
    "        print(h.shape)\n",
    "        h = rnn(h)\n",
    "        print(h.shape)\n",
    "        h = pred(h)\n",
    "        print(h.shape)\n",
    "\n",
    "        model = Model(x, h)\n",
    "        model.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "        history = model.fit(x=x_train[:, :max_len], \n",
    "                     y=x_train[:, max_len],\n",
    "                    epochs=3, batch_size=10,\n",
    "                    validation_data=(x_test[:, :max_len], x_test[:, max_len]))\n",
    "\n",
    "        histories.append([seed, history])\n",
    "        \n",
    "        with open(\"../models/%s.pkl\" % name, 'wb') as f:\n",
    "            pickle.dump([seed, hyper, history.history], f)\n",
    "            \n",
    "        model.save(\"../models/%s.h5\" % name)\n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "    \n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=3\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "lstm\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 24, 64)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 37s - loss: 3.1988 - sparse_categorical_accuracy: 0.2133 - val_loss: 2.8394 - val_sparse_categorical_accuracy: 0.2650\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 33s - loss: 2.7334 - sparse_categorical_accuracy: 0.2804 - val_loss: 2.6833 - val_sparse_categorical_accuracy: 0.2960\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 33s - loss: 2.5444 - sparse_categorical_accuracy: 0.3169 - val_loss: 2.6066 - val_sparse_categorical_accuracy: 0.3225\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=4\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=512\n",
      "lstm\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 24, 64)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 80s - loss: 3.1495 - sparse_categorical_accuracy: 0.2188 - val_loss: 2.8230 - val_sparse_categorical_accuracy: 0.2875\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 76s - loss: 2.6896 - sparse_categorical_accuracy: 0.2946 - val_loss: 2.6629 - val_sparse_categorical_accuracy: 0.3060\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 77s - loss: 2.4592 - sparse_categorical_accuracy: 0.3423 - val_loss: 2.5445 - val_sparse_categorical_accuracy: 0.3425\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=64\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=3\n",
      "stride = 3\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 64)\n",
      "(?, 24, 64)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 42s - loss: 3.2923 - sparse_categorical_accuracy: 0.1958 - val_loss: 2.9235 - val_sparse_categorical_accuracy: 0.2470\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 38s - loss: 2.8003 - sparse_categorical_accuracy: 0.2682 - val_loss: 2.7454 - val_sparse_categorical_accuracy: 0.2805\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 38s - loss: 2.6059 - sparse_categorical_accuracy: 0.3061 - val_loss: 2.6759 - val_sparse_categorical_accuracy: 0.2960\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=6\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "bidirectional\n",
      "lstm\n",
      "\n",
      "(?, 50, 128)\n",
      "(?, 24, 64)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 50s - loss: 3.3672 - sparse_categorical_accuracy: 0.1838 - val_loss: 3.0445 - val_sparse_categorical_accuracy: 0.2380\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 46s - loss: 2.8996 - sparse_categorical_accuracy: 0.2582 - val_loss: 2.8175 - val_sparse_categorical_accuracy: 0.2820\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 46s - loss: 2.6976 - sparse_categorical_accuracy: 0.2884 - val_loss: 2.7161 - val_sparse_categorical_accuracy: 0.2940\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=2\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=512\n",
      "lstm\n",
      "\n",
      "(?, 50, 128)\n",
      "(?, 24, 64)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 75s - loss: 3.2909 - sparse_categorical_accuracy: 0.1967 - val_loss: 2.9513 - val_sparse_categorical_accuracy: 0.2420\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 71s - loss: 2.8061 - sparse_categorical_accuracy: 0.2708 - val_loss: 2.7398 - val_sparse_categorical_accuracy: 0.2815\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 71s - loss: 2.5953 - sparse_categorical_accuracy: 0.3036 - val_loss: 2.6187 - val_sparse_categorical_accuracy: 0.3105\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=2\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 24, 64)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 43s - loss: 3.1677 - sparse_categorical_accuracy: 0.2227 - val_loss: 2.8236 - val_sparse_categorical_accuracy: 0.2655\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 39s - loss: 2.6861 - sparse_categorical_accuracy: 0.2988 - val_loss: 2.6733 - val_sparse_categorical_accuracy: 0.2960\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 39s - loss: 2.4829 - sparse_categorical_accuracy: 0.3394 - val_loss: 2.6255 - val_sparse_categorical_accuracy: 0.3090\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=7\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "gru\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 24, 64)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 29s - loss: 3.1328 - sparse_categorical_accuracy: 0.2249 - val_loss: 2.8037 - val_sparse_categorical_accuracy: 0.2845\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 26s - loss: 2.6401 - sparse_categorical_accuracy: 0.3095 - val_loss: 2.6546 - val_sparse_categorical_accuracy: 0.2965\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 26s - loss: 2.4156 - sparse_categorical_accuracy: 0.3473 - val_loss: 2.5598 - val_sparse_categorical_accuracy: 0.3450\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=64\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=6\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "gru\n",
      "\n",
      "(?, 50, 64)\n",
      "(?, 24, 64)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 29s - loss: 3.3103 - sparse_categorical_accuracy: 0.1932 - val_loss: 2.9052 - val_sparse_categorical_accuracy: 0.2470\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 25s - loss: 2.7967 - sparse_categorical_accuracy: 0.2738 - val_loss: 2.6964 - val_sparse_categorical_accuracy: 0.2915\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 25s - loss: 2.5971 - sparse_categorical_accuracy: 0.3130 - val_loss: 2.6348 - val_sparse_categorical_accuracy: 0.3050\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=6\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 128)\n",
      "(?, 24, 64)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 53s - loss: 3.1911 - sparse_categorical_accuracy: 0.2101 - val_loss: 2.8426 - val_sparse_categorical_accuracy: 0.2625\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 49s - loss: 2.7094 - sparse_categorical_accuracy: 0.2880 - val_loss: 2.6800 - val_sparse_categorical_accuracy: 0.2865\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 49s - loss: 2.4971 - sparse_categorical_accuracy: 0.3263 - val_loss: 2.6359 - val_sparse_categorical_accuracy: 0.3240\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=5\n",
      "stride = 1\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 128)\n",
      "(?, 24, 64)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 43s - loss: 3.2509 - sparse_categorical_accuracy: 0.2047 - val_loss: 2.8717 - val_sparse_categorical_accuracy: 0.2535\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 39s - loss: 2.7228 - sparse_categorical_accuracy: 0.2856 - val_loss: 2.6814 - val_sparse_categorical_accuracy: 0.2965\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 39s - loss: 2.5116 - sparse_categorical_accuracy: 0.3304 - val_loss: 2.5796 - val_sparse_categorical_accuracy: 0.3295\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=64\n",
      "\n",
      "conv 1d\n",
      "filters=64\n",
      "kernel size=9\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=512\n",
      "lstm\n",
      "\n",
      "(?, 50, 64)\n",
      "(?, 24, 64)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 75s - loss: 3.2626 - sparse_categorical_accuracy: 0.1958 - val_loss: 2.9057 - val_sparse_categorical_accuracy: 0.2505\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 71s - loss: 2.7955 - sparse_categorical_accuracy: 0.2670 - val_loss: 2.7184 - val_sparse_categorical_accuracy: 0.2930\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314/11314 [==============================] - 70s - loss: 2.6017 - sparse_categorical_accuracy: 0.3064 - val_loss: 2.6169 - val_sparse_categorical_accuracy: 0.3095\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=9\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 24, 64)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 43s - loss: 3.1920 - sparse_categorical_accuracy: 0.2135 - val_loss: 2.8192 - val_sparse_categorical_accuracy: 0.2750\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 39s - loss: 2.6923 - sparse_categorical_accuracy: 0.2986 - val_loss: 2.6750 - val_sparse_categorical_accuracy: 0.2955\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 39s - loss: 2.4858 - sparse_categorical_accuracy: 0.3375 - val_loss: 2.6154 - val_sparse_categorical_accuracy: 0.3255\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=64\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=4\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "lstm\n",
      "\n",
      "(?, 50, 64)\n",
      "(?, 24, 64)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 30s - loss: 3.3218 - sparse_categorical_accuracy: 0.1957 - val_loss: 2.9831 - val_sparse_categorical_accuracy: 0.2510\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 26s - loss: 2.8731 - sparse_categorical_accuracy: 0.2618 - val_loss: 2.8057 - val_sparse_categorical_accuracy: 0.2570\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 26s - loss: 2.7271 - sparse_categorical_accuracy: 0.2856 - val_loss: 2.7502 - val_sparse_categorical_accuracy: 0.2810\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=8\n",
      "stride = 3\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 128)\n",
      "(?, 24, 64)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 53s - loss: 3.2017 - sparse_categorical_accuracy: 0.2125 - val_loss: 2.8272 - val_sparse_categorical_accuracy: 0.2645\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 49s - loss: 2.7108 - sparse_categorical_accuracy: 0.2898 - val_loss: 2.6756 - val_sparse_categorical_accuracy: 0.3030\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 49s - loss: 2.4947 - sparse_categorical_accuracy: 0.3335 - val_loss: 2.6194 - val_sparse_categorical_accuracy: 0.3080\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=4\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "lstm\n",
      "\n",
      "(?, 50, 128)\n",
      "(?, 24, 64)\n",
      "(?, 64)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 30s - loss: 3.3652 - sparse_categorical_accuracy: 0.1793 - val_loss: 3.0698 - val_sparse_categorical_accuracy: 0.2305\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 26s - loss: 2.9480 - sparse_categorical_accuracy: 0.2470 - val_loss: 2.8460 - val_sparse_categorical_accuracy: 0.2595\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 26s - loss: 2.7830 - sparse_categorical_accuracy: 0.2711 - val_loss: 2.7573 - val_sparse_categorical_accuracy: 0.2825\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=64\n",
      "kernel size=5\n",
      "stride = 3\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "lstm\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 24, 64)\n",
      "(?, 64)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 32s - loss: 3.2999 - sparse_categorical_accuracy: 0.2010 - val_loss: 2.9643 - val_sparse_categorical_accuracy: 0.2490\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 28s - loss: 2.8552 - sparse_categorical_accuracy: 0.2641 - val_loss: 2.8022 - val_sparse_categorical_accuracy: 0.2775\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 28s - loss: 2.7034 - sparse_categorical_accuracy: 0.2891 - val_loss: 2.7166 - val_sparse_categorical_accuracy: 0.2980\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=64\n",
      "kernel size=8\n",
      "stride = 3\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "gru\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 24, 64)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 30s - loss: 3.1235 - sparse_categorical_accuracy: 0.2273 - val_loss: 2.7651 - val_sparse_categorical_accuracy: 0.2770\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 26s - loss: 2.6355 - sparse_categorical_accuracy: 0.3019 - val_loss: 2.6093 - val_sparse_categorical_accuracy: 0.3130\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 26s - loss: 2.4071 - sparse_categorical_accuracy: 0.3542 - val_loss: 2.5761 - val_sparse_categorical_accuracy: 0.3455\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=9\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 24, 64)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 45s - loss: 3.0897 - sparse_categorical_accuracy: 0.2353 - val_loss: 2.7252 - val_sparse_categorical_accuracy: 0.2950\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 41s - loss: 2.5771 - sparse_categorical_accuracy: 0.3201 - val_loss: 2.6038 - val_sparse_categorical_accuracy: 0.3170\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 41s - loss: 2.3226 - sparse_categorical_accuracy: 0.3745 - val_loss: 2.5488 - val_sparse_categorical_accuracy: 0.3415\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=6\n",
      "stride = 3\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "gru\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 24, 64)\n",
      "(?, 64)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 27s - loss: 3.2575 - sparse_categorical_accuracy: 0.2086 - val_loss: 2.8606 - val_sparse_categorical_accuracy: 0.2760\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 23s - loss: 2.7420 - sparse_categorical_accuracy: 0.2931 - val_loss: 2.6784 - val_sparse_categorical_accuracy: 0.3115\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 22s - loss: 2.5552 - sparse_categorical_accuracy: 0.3275 - val_loss: 2.6288 - val_sparse_categorical_accuracy: 0.3225\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=2\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "bidirectional\n",
      "lstm\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 24, 64)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 53s - loss: 3.2218 - sparse_categorical_accuracy: 0.2109 - val_loss: 2.8776 - val_sparse_categorical_accuracy: 0.2520\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 49s - loss: 2.7428 - sparse_categorical_accuracy: 0.2846 - val_loss: 2.7284 - val_sparse_categorical_accuracy: 0.3005\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 49s - loss: 2.5645 - sparse_categorical_accuracy: 0.3203 - val_loss: 2.6395 - val_sparse_categorical_accuracy: 0.3205\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=64\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=8\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 64)\n",
      "(?, 24, 64)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 53s - loss: 3.2701 - sparse_categorical_accuracy: 0.2010 - val_loss: 2.8878 - val_sparse_categorical_accuracy: 0.2560\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 49s - loss: 2.7679 - sparse_categorical_accuracy: 0.2721 - val_loss: 2.7169 - val_sparse_categorical_accuracy: 0.2820\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 49s - loss: 2.5683 - sparse_categorical_accuracy: 0.3141 - val_loss: 2.6361 - val_sparse_categorical_accuracy: 0.3195\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=64\n",
      "kernel size=2\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "lstm\n",
      "\n",
      "(?, 50, 128)\n",
      "(?, 24, 64)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 37s - loss: 3.2440 - sparse_categorical_accuracy: 0.2012 - val_loss: 2.9220 - val_sparse_categorical_accuracy: 0.2420\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314/11314 [==============================] - 32s - loss: 2.7855 - sparse_categorical_accuracy: 0.2725 - val_loss: 2.7239 - val_sparse_categorical_accuracy: 0.2800\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 32s - loss: 2.6007 - sparse_categorical_accuracy: 0.3093 - val_loss: 2.6359 - val_sparse_categorical_accuracy: 0.3110\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=6\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=512\n",
      "bidirectional\n",
      "lstm\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 24, 64)\n",
      "(?, 1024)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 148s - loss: 3.3638 - sparse_categorical_accuracy: 0.1818 - val_loss: 2.9860 - val_sparse_categorical_accuracy: 0.2285\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 144s - loss: 2.7956 - sparse_categorical_accuracy: 0.2741 - val_loss: 2.6894 - val_sparse_categorical_accuracy: 0.2780\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 144s - loss: 2.5122 - sparse_categorical_accuracy: 0.3309 - val_loss: 2.5797 - val_sparse_categorical_accuracy: 0.3250\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=5\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 24, 64)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 56s - loss: 3.0835 - sparse_categorical_accuracy: 0.2353 - val_loss: 2.7534 - val_sparse_categorical_accuracy: 0.2780\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 51s - loss: 2.6032 - sparse_categorical_accuracy: 0.3153 - val_loss: 2.6055 - val_sparse_categorical_accuracy: 0.3170\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 51s - loss: 2.3317 - sparse_categorical_accuracy: 0.3699 - val_loss: 2.5798 - val_sparse_categorical_accuracy: 0.3235\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=64\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=2\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "lstm\n",
      "\n",
      "(?, 50, 64)\n",
      "(?, 24, 64)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 37s - loss: 3.3351 - sparse_categorical_accuracy: 0.1884 - val_loss: 2.9739 - val_sparse_categorical_accuracy: 0.2325\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 32s - loss: 2.8606 - sparse_categorical_accuracy: 0.2568 - val_loss: 2.7783 - val_sparse_categorical_accuracy: 0.2750\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 32s - loss: 2.6797 - sparse_categorical_accuracy: 0.2876 - val_loss: 2.6832 - val_sparse_categorical_accuracy: 0.2915\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=2\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "lstm\n",
      "\n",
      "(?, 50, 256)\n",
      "(?, 24, 64)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 32s - loss: 3.2156 - sparse_categorical_accuracy: 0.2159 - val_loss: 2.8536 - val_sparse_categorical_accuracy: 0.2765\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 27s - loss: 2.7732 - sparse_categorical_accuracy: 0.2768 - val_loss: 2.7333 - val_sparse_categorical_accuracy: 0.2920\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 27s - loss: 2.6188 - sparse_categorical_accuracy: 0.3063 - val_loss: 2.6563 - val_sparse_categorical_accuracy: 0.3100\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=2\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "gru\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 24, 64)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 29s - loss: 3.0621 - sparse_categorical_accuracy: 0.2356 - val_loss: 2.7796 - val_sparse_categorical_accuracy: 0.2745\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 24s - loss: 2.6073 - sparse_categorical_accuracy: 0.3115 - val_loss: 2.6098 - val_sparse_categorical_accuracy: 0.3215\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 24s - loss: 2.3899 - sparse_categorical_accuracy: 0.3570 - val_loss: 2.5459 - val_sparse_categorical_accuracy: 0.3315\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=4\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=512\n",
      "lstm\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 24, 64)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 78s - loss: 3.1194 - sparse_categorical_accuracy: 0.2198 - val_loss: 2.8156 - val_sparse_categorical_accuracy: 0.2695\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 73s - loss: 2.6762 - sparse_categorical_accuracy: 0.2934 - val_loss: 2.6592 - val_sparse_categorical_accuracy: 0.3010\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 73s - loss: 2.4537 - sparse_categorical_accuracy: 0.3379 - val_loss: 2.5716 - val_sparse_categorical_accuracy: 0.3205\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=64\n",
      "kernel size=5\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "bidirectional\n",
      "lstm\n",
      "\n",
      "(?, 50, 512)\n",
      "(?, 24, 64)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 54s - loss: 3.1606 - sparse_categorical_accuracy: 0.2188 - val_loss: 2.8312 - val_sparse_categorical_accuracy: 0.2630\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 49s - loss: 2.6797 - sparse_categorical_accuracy: 0.2940 - val_loss: 2.6757 - val_sparse_categorical_accuracy: 0.2910\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 49s - loss: 2.4872 - sparse_categorical_accuracy: 0.3330 - val_loss: 2.5906 - val_sparse_categorical_accuracy: 0.3225\n",
      "\n",
      "\n",
      "\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=64\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=9\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=64\n",
      "bidirectional\n",
      "lstm\n",
      "\n",
      "(?, 50, 64)\n",
      "(?, 24, 64)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "Train on 11314 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "11314/11314 [==============================] - 51s - loss: 3.4022 - sparse_categorical_accuracy: 0.1790 - val_loss: 3.0775 - val_sparse_categorical_accuracy: 0.2345\n",
      "Epoch 2/3\n",
      "11314/11314 [==============================] - 46s - loss: 2.9303 - sparse_categorical_accuracy: 0.2496 - val_loss: 2.8419 - val_sparse_categorical_accuracy: 0.2610\n",
      "Epoch 3/3\n",
      "11314/11314 [==============================] - 46s - loss: 2.7403 - sparse_categorical_accuracy: 0.2828 - val_loss: 2.7358 - val_sparse_categorical_accuracy: 0.2825\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "histories = explore(42, 30, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [2.839404977560043, 2.683288841843605, 2.606572616696358],\n",
       " 'val_sparse_categorical_accuracy': [0.26500000633299353,\n",
       "  0.29600000645965335,\n",
       "  0.3225000076368451],\n",
       " 'loss': [3.198784228641489, 2.7334388353514, 2.544429989676183],\n",
       " 'sparse_categorical_accuracy': [0.21327559238628002,\n",
       "  0.28036062140989076,\n",
       "  0.31686406924764826]}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histories[0][1].history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories.sort(key=lambda x: x[1].history['val_sparse_categorical_accuracy'][-1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = lambda x: x[1].history['val_sparse_categorical_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.34550000783056023,\n",
       " 0.3450000071153045,\n",
       " 0.342500007674098,\n",
       " 0.3415000081434846,\n",
       " 0.33150000784546135,\n",
       " 0.3295000068470836,\n",
       " 0.3255000079423189,\n",
       " 0.3250000071525574,\n",
       " 0.3240000067651272,\n",
       " 0.32350000690668823,\n",
       " 0.32250000767409803,\n",
       " 0.3225000076368451,\n",
       " 0.3225000067800283,\n",
       " 0.32050000689923763,\n",
       " 0.3205000068619847,\n",
       " 0.3195000072568655,\n",
       " 0.31100000750273465,\n",
       " 0.31050000626593827,\n",
       " 0.31000000700354574,\n",
       " 0.30950000673532485,\n",
       " 0.30900000665336846,\n",
       " 0.30800000615417955,\n",
       " 0.305000007301569,\n",
       " 0.2980000066384673,\n",
       " 0.2960000068694353,\n",
       " 0.2940000068768859,\n",
       " 0.2915000059828162,\n",
       " 0.2825000066310167,\n",
       " 0.28250000648200513,\n",
       " 0.2810000065341592]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[val_acc(x) for x in histories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReHyper(seed):\n",
    "    r = np.random.RandomState(seed)\n",
    "    hyper = RnnCnnHyper.Random(r)\n",
    "    return hyper, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper, _ =ReHyper(histories[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176609\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=64\n",
      "kernel size=8\n",
      "stride = 3\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "gru\n",
      "\n",
      "70218\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=256\n",
      "\n",
      "conv 1d\n",
      "filters=256\n",
      "kernel size=7\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=256\n",
      "gru\n",
      "\n",
      "159467\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=4\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=512\n",
      "lstm\n",
      "\n",
      "97357\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=512\n",
      "kernel size=9\n",
      "stride = 2\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "bidirectional\n",
      "gru\n",
      "\n",
      "62245\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=512\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=2\n",
      "stride = 4\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "gru\n",
      "\n",
      "150338\n",
      "embedding\n",
      "vocab size=256\n",
      "embedding dimension=128\n",
      "\n",
      "conv 1d\n",
      "filters=128\n",
      "kernel size=5\n",
      "stride = 1\n",
      "\n",
      "RNN\n",
      "hidden dimension=128\n",
      "bidirectional\n",
      "gru\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seed, _ in histories[:6]:\n",
    "    hyper, _ = ReHyper(seed)\n",
    "    print(seed)\n",
    "    hyper.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
