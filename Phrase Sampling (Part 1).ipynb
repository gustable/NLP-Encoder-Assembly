{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GETTING AND LOADING A CORPUS\n",
    "\n",
    "https://nlpforhackers.io/corpora/\n",
    "http://lucumr.pocoo.org/2015/11/18/pythons-hidden-re-gems/\n",
    "\n",
    "The goal of this step is to develop an initial list of each character and their spoken lines, or a cleanish list of the lines within the text. (Dictionaries are Hash value arbitrary, so may not be ordered the same. Lists are used instead.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "9261\n",
      "9276\n"
     ]
    }
   ],
   "source": [
    "# Select and Read a file into \"f\" using a list and stripping out all Project Gutenberg headers and footers\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "data_folder = Path(\"data/poe/\")\n",
    "file_to_open = data_folder / \"2149-0.txt\"\n",
    "f = open(file_to_open, 'r')\n",
    "first_document = list(f)\n",
    "#print(first_document)\n",
    "\n",
    "# Determine whether a Project Gutenberg Text\n",
    "first_header_index = 0\n",
    "second_header_index = 0\n",
    "footer_index = 0\n",
    "if any(\"GUTENBERG\" in s for s in first_document):\n",
    "    for first_header_index in range( len(first_document) ):\n",
    "        if ( ( first_document[first_header_index].find('*END*THE SMALL PRINT!') ) != -1 ) :\n",
    "            break\n",
    "        else:\n",
    "            for first_header_index in range( len(first_document) ):\n",
    "                if ( ( first_document[first_header_index].find('START OF THIS PROJECT GUTENBERG') ) != -1 ) :\n",
    "                    break        \n",
    "        \n",
    "    second_document = list(first_document[first_header_index + 1 :])\n",
    "\n",
    "    for second_header_index in range( len(second_document) ):\n",
    "        if ( ( second_document[second_header_index].find('www.gutenberg.org') ) != -1 ) :\n",
    "            break            \n",
    "    for footer_index in range( len(first_document) ):\n",
    "        if ( ( first_document[footer_index].find('End of Project') ) != -1 ) :\n",
    "            break\n",
    "        else:\n",
    "            for footer_index in range( len(first_document) ):\n",
    "                if ( ( first_document[footer_index].find('End of the Project') ) != -1 ) :\n",
    "                    break    \n",
    "        \n",
    "    print(first_header_index)            \n",
    "    print(second_header_index)\n",
    "    print(footer_index)     \n",
    "    \n",
    "    script = list()\n",
    "    if (second_header_index < (first_header_index + 100)):\n",
    "        script = list(first_document[first_header_index +1 + second_header_index +1 : footer_index-1])\n",
    "    else:\n",
    "        script = list(first_document[first_header_index +1 : footer_index-1])\n",
    "else:\n",
    "    script = first_document\n",
    "\n",
    "#print(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile a list of speakers\n",
    "r = re.compile(\"[A-Z0-9][A-Z0-9]+\")\n",
    "speakers = []\n",
    "for line in script:\n",
    "    mtch = r.match(line)\n",
    "    if mtch:\n",
    "        speakers.append(mtch.group())\n",
    "#print(speakers)\n",
    "\n",
    "#Omit speakers from the list of text\n",
    "s = re.compile(r\"\\b[A-Z{3}\\.]+\\b\")\n",
    "spoken = list(filter(lambda i: not r.search(i), script))\n",
    "\n",
    "#print(spoken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RE-CREATING SENTENCES AND PHRASES\n",
    "\n",
    "During this step, we concatenate lines in batches to allow the identification of sentences with regular expressions. Then we identify phrases with stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate lines into list entries for future sentence splitting\n",
    "\n",
    "newLines = []\n",
    "singleLine = ''\n",
    "singleLines = []\n",
    "\n",
    "#Remove all line returns(ok)\n",
    "for j in range(0, len(spoken)):\n",
    "    spoken[j] = spoken[j].replace('\\n', '')\n",
    "    \n",
    "#Split 5 lines at a time into new list\n",
    "for k in range( 0, len(spoken), 3):\n",
    "    newLines = []\n",
    "    for line in range( 0, 3 ):\n",
    "        try:\n",
    "            newLines.append(' '+spoken[line+k])\n",
    "        except:\n",
    "            #print(\"Index Error at\", k, line)\n",
    "            break\n",
    "    #Join 5-line groups into one line and append to a list\n",
    "    singleLine = ''.join(newLines)\n",
    "    singleLines.append(singleLine)\n",
    "\n",
    "#print(singleLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create list of sentences\n",
    "sentences = []\n",
    "for m in range(0, len(singleLines)):\n",
    "    mtch = re.findall(\"[A-Z][^\\.!?]*[\\.!?]\", singleLines[m], re.M|re.I)\n",
    "    if mtch:\n",
    "        sentences.append(mtch)\n",
    "\n",
    "#print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Clean the stopword list\n",
    "stoplist = []\n",
    "clean_line = []\n",
    "data_folder = Path(\"data/\")\n",
    "file_to_open = data_folder / \"snowball_stop.txt\"\n",
    "f = open(file_to_open, 'r')\n",
    "full_stop = list(f)\n",
    "\n",
    "for n in range( 0, len(full_stop), 1 ):\n",
    "    clean_line = full_stop[n].split('|')\n",
    "    stoplist.append(clean_line[0])\n",
    "\n",
    "for p in range(len(stoplist)):\n",
    "    stoplist[p] = stoplist[p].replace('\\n', '')\n",
    "    \n",
    "#print(stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create list of phrases using stopwords\n",
    "phrases = []\n",
    "candidate_phrases = []\n",
    "\n",
    "for q in range(len(sentences)):\n",
    "    for r in sentences[q]:\n",
    "        words = re.split(\"\\\\s+\", r)\n",
    "        previous_stop = False\n",
    " \n",
    "        # Examine each word to determine if it is a phrase boundary marker or part of a phrase or alone\n",
    "        for w in words:\n",
    " \n",
    "            if w in stoplist and not previous_stop:\n",
    "                # phrase boundary encountered, so put a hard indicator\n",
    "                candidate_phrases.append(\";\")\n",
    "                previous_stop = True\n",
    "            elif w not in stoplist and len(w) > 3:\n",
    "                # keep adding words to list until a phrase boundary is detected\n",
    "                candidate_phrases.append(w.strip())\n",
    "                previous_stop = False\n",
    " \n",
    "    # Create a list of candidate phrases without boundary demarcation\n",
    "    phrases = re.split(\";+\", ' '.join(candidate_phrases))\n",
    "\n",
    "# Clean up phrases    \n",
    "re2 = re.compile('[^\\.!?,\"(){}\\*:]*[\\.!?,\"(){}\\*:]')\n",
    "for s in range(len(phrases)):\n",
    "    phrases[s] = re.sub(re2, '', phrases[s])\n",
    "    phrases[s] = phrases[s].strip(' ')\n",
    "    phrases[s] = phrases[s].replace(' ', '_')\n",
    "    phrases[s] = phrases[s].replace('__', '_')\n",
    "    phrases[s] = phrases[s].strip('_')\n",
    "\n",
    "for s in range(len(phrases)):\n",
    "    try:\n",
    "        phrases.remove('')\n",
    "        phrases.remove(' ')\n",
    "        phrases.remove('/n')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#for t in range(50):\n",
    "    #print(phrases[t])\n",
    "\n",
    "#print(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERFORM A PHRASE FREQUENCY COUNT\n",
    "\n",
    "Now we can identify common phrases by performing a frequency count on each phrase.  Moreover, if the corpus is large enough, commonly used phrases will be evident with higher counts across many texts.  For this reason the phrase list along with counts, will be stored in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('flashed', 35)\n",
      "('spoke_much', 35)\n",
      "('watch', 35)\n",
      "('long_time_heard_moving_among', 35)\n",
      "('told', 35)\n",
      "('were', 35)\n",
      "('have_recovered', 35)\n",
      "('present', 35)\n",
      "('vessel', 35)\n",
      "(\"mate's_gang\", 35)\n",
      "('have_never_seen_rigged_either', 35)\n",
      "('bear', 35)\n",
      "('endeavouring', 35)\n",
      "('galley', 35)\n",
      "('bowsprit', 35)\n",
      "('never_even_succeed', 35)\n",
      "('small_leather_trunk_belonging', 35)\n",
      "('returned_without', 35)\n",
      "('lengths', 35)\n",
      "('Peters', 35)\n",
      "('conduct', 35)\n",
      "('thought_likely', 35)\n",
      "('still_dared', 35)\n",
      "('ecstatic', 35)\n",
      "('commenced_cutting', 35)\n",
      "('their_bodies_being_carried', 35)\n",
      "('head', 35)\n",
      "('resemblance', 35)\n",
      "('ensued_upon_drinking', 35)\n",
      "('addition', 35)\n",
      "('three_pounds', 35)\n",
      "('never', 35)\n",
      "('never_left', 35)\n",
      "('incredible', 35)\n",
      "('fifty', 35)\n",
      "('account_given', 34)\n",
      "('sent', 34)\n",
      "('longer', 34)\n",
      "('sober', 34)\n",
      "('minute', 34)\n",
      "('water', 34)\n",
      "('insensible_upon', 34)\n",
      "('avoid_coming', 34)\n",
      "('nature', 34)\n",
      "('reviving', 34)\n",
      "('severest_gales_ever_experienced', 34)\n",
      "('have_effectually_cooled_incipient_passion', 34)\n",
      "('bring', 34)\n",
      "('Augustus_going', 34)\n",
      "('companion_showed', 34)\n"
     ]
    }
   ],
   "source": [
    "# Phrase frequency count\n",
    "from operator import itemgetter\n",
    "wordfreq = []\n",
    "for u in range(len(phrases)):\n",
    "    utterance = phrases[u]\n",
    "    uttcnt = 0\n",
    "    uttcnt = phrases.count(utterance)\n",
    "    if uttcnt > 1:\n",
    "        wordfreq.append(uttcnt)\n",
    "    \n",
    "zipped = list(zip(phrases, wordfreq))\n",
    "sortzip = sorted(zipped, key=itemgetter(1), reverse=True)\n",
    "\n",
    "for v in range(50):\n",
    "    print(sortzip[v])"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAACACAIAAACHjocOAAAdT0lEQVR4Ae1d/ZmCvtLNvs8tACwBbwVoCbgV4JaAVqBbAlrBuiXIViCUoFaglgB24H3enfs7m8tn5EvQ8Y/dGJJJcoKHycwkvN1uN8EfRoARYAQYgadG4P+eenQ8OEaAEWAEGIH/R4C5nu8DRoARYASeHwHm+uefYx4hI8AIMALM9XwPMAKMACPw/Agw1z//HPMIGQFGgBFgrud7gBFgBNpGIIqi6XQ6Go3abvj+9nzfHw6Hm83m/qrdqvGvbnWHe8MIMALPjkAURZZlHY/Hr6+v7o91Mplomjafz6/X63K57H6Hs3r4xvH1WdBwPiPACNSOQBRF4/H4crksFovValW7/IYEDofD3vU5BgXbcGKA8FdGgBFoCgEQveM4PSJ6IcR+vzcMY71e91e1Z65v6rZmuYwAIxBDwLKsy+Vi23YV8/dwOHxLfKbTaayt2Fff9xOV/puh4jbQdX2322matl6v+/WUAg5swwEUnGAEGIEGEZhOpz8/P6ZpHg6HKs2cz+fr9RqG4c/Pz/f3N0SFYajrOr4mE77vX69X13WPx6MQwjCMxWJh/H6Gw2GyfDLH9/3393chxG63m0wmyQKdzrnxhxFgBBiBhhFwXZd48HQ61dXUdrs1TRP0ulgsVCSHYSiEsG1bpXCyDA1E07QwDJNXu5zDej1uFU4wAoxAIwgcDofxeCyE2G63hcYW9R7MZjPDMC6XC2n3mqZFUVRYPYqiwWBQuAjIkTOZTIIgqL5AyWmiiUtsr28CVZbJCDACfwh8fHwIIRzHqZHohRBBEFiWtVgsqKXr9ep53l+rGan9fm+aZr61J6Pqf7O3260Q4ng89stPy1yfP618lRFgBCohMJvNLpeLpmkw41QS90/lKIrCMByNRsPhEJYc2Xz/T8H4f3pCxHPv+a7rOtH9er32ff+eqo8sy1z/SPS5bUbguRHwfZ/49/v7u4oqnURpu91alkX5n5+flAiC4Hw+JwvLOdW5XggxnU6pdVqyyPI7m2au7+zUcMcYgX4jEEURUaFlWfVab2DAIYCm06mmaZQuVO2Px2MtITS06bdHm2mZ6/v9c+LeMwKdReDz8/N6vQohmjgLIaaeO45DOORzve/7MPhUxG04HFKj6/W6cDFRsa1aqjPX1wIjC2EEGIH/QeB8PhPt2ratGL3+P/VzvxC3ymLB9fke2tgTIreR4ovwQMzn8+LSjy7BXP/oGeD2GYFnRAA2dBBijaNMUvZwOIT5PqfFZMUqvdJ1naKAgiDovpOW4+urzDXXZQQYgRQEEFBv27ZKHGSKiNwsco3OZjO5lOd58JSeTidZ66diFFlf72mPJJN24XbcksN6vXy3cJoRYARqQKBRpT7mmEV3ZQ/ter1GPhIUWY+vtSR0XSfz0eVyaeKpVksnSQhzfY1gsihGgBEQvu8HQUDnECSV6+oAJY31kAmrfaqHtl4DDhrFZq4c2xEKPzDBXP9A8LlpRuAJEYBODeatd5A5lI31hBAieZRmEAQw8tTYpeFwaNs27aSteKxbjb1KimKuT2LCOYwAI1ASgSiKSKnXNK2WMPZkP3K4Xtd1eGhjqn0URcfjUeX44mSLhTl4qnVZtWeuL5xHLsAIMAKqCIBhQX+qNZXL5XC9EAIWlePxKGvZ+bWUG08vSO8pFEL8/Px01kPLXJ8+eZzLCDACJRCAYtsQ1+cY66m3oF0hBB48We7cEgPMqgLrkNxoVuGH5DPXPwR2bpQReEIE6GUgQgjTNJvwyipSNqz2Mu02qtfTKZ40oz8/P92cWub6bs4L94oR6B8C4FYoubWPQYWy5SUFeWijKLpcLg0Z62mMo9HIMAwhxOVykW1HtSNQWiBzfWnouCIjwAj8IRBFEVRaikv5u1ZfSiWWRtd1dICCglSeENX7iEbpxOPqAuuVwFxfL54sjRF4UQQo/EYIoWlaQwac8/k8GAxUzkaGak9adjtcnxUC1JEbgrm+IxPB3WAE+o0AuP6xBhwCcTKZkEVFCOG6bjtcjxjT6/XaQTMOc32/f2Dce0agIwjAcAFTRu0du4uyodr//Pw0bazHSKHaAw1ceniCuf7hU8AdYAR6j8D5fKaj6oUQ9BrxJoZUjuuFEKDgJnoly0RDWOXIVx+bZq5/LP7cOiPwDAjAK2sYhoo9vcSY6dBgdeGyhxYUXKLdu6qgoePxeFfFFgoz17cAMjfBCDw5AlBj63rrUxIvvOUqeSkrB4H2oOCsknXly2GdXTvRnrm+rllmOYzA6yIArq+XVQ+Hg+d5q9VqOBySpjwajTabjSKNIuZdpuCmJwk+YWDSdIuK8v+lWI6LMQIVEfA8z3Xdy+VC9lPXdRuKzKvYz9aq0wafMAwvl8v1ejUMo/YXcLczFvkEmHqN9ZZlwQ1AYzkej/TCvzAMVew5i8WiZc61LIv2lLXcbvFc3/jDCDSPAAVFfH19UVN0QNXpdGq+5e62gFO66FfqOE53+5rbMznmJLfgS1yUX6TeqQGzDaf4cfjiJaIo2mw2URSVxmG1Wn1/f1uWRS+Nm06n2M1YWuYTVFytVrfbbbfb9X0s+/2ehgDzRd9HVKX/8sqmyq+mSh9S6zLXp8LCmX8IjMfj+XwON9ffBeUU1UXYtRyzoSzjaQtOJhMg09NBIuaEuZ5ePIt5xFMQOQ9MMNc/EPweNH04HMjCrmlaue7i9UDw2i0WC8MwXNfFPsNykp+m1mAw6PVYwGjNBeH0CB/Zi4CnYBf6z77ZLsxCd/sA/xKY+t6+QouHJ3b1+7lXDpfvLAJwn7JeT3NkGAZpSPS3IxPHen1HJqKj3QDXy1bIu/pKEko/Ku5qiwu3j4B88AtzPeEPHLDiaX9eki0y1ycx4Zw/BOhmNU1TXpn+XS5KIRqPV/dFUPX1ehiG6Do4DjmvmcDdznr9a94A/Rs1DjkprZVXXxb0D7UX67FMZ313PNQ1dcAB1q26JFeRw3p9FfSevC6YujTXwzdVWkJrEPu+TyGh97boed5yuby31tOUl7m+3OLvaaDAQORAhu6EXTLXY4I4EUcAXF/RWK9pWvdZIAiC7+/ve0ODPM/7+PjAu/fiCL7Ad6iuMsG9wLjzhgi9nl5JmFe0xWt95frD4TAajXRdHw6Hq9UqCzHf93VdT249j6JoMpnouq54sEaW/CfLHw6Hb9IHITSDwQDZhWwoCyGl73q9ovrb25vszesOgKvVyrbtIAgKB4g+E9FrmtaaCy6KIjofRv1MGOptFEW+769Wq81mE8P/fD6TzHK/Bej1MsEBotdMyH4L2Z/xWDR6yfVQpqIochzn8/Mzi+7pbDzop8D68/MzCILr9UpnayD/xRPb7Xb3zwdbvW3b/idvt9/v5Q3xqXBBiOu6VMBxHFlCmwdRpfYwK9PzPHW6l4ke4aRZkqvnHw6HyWRiWVYYhpZlGYZxPB6Hw+FsNsu3EkRRNJvNqLxpmoPB4PPzczQaHQ4H3/cnkwkWJe/v77HHgEq3wfWs1wMuGQrgg6sPS3TqxAaVzpxOJ8MwwjCkwqCeZF08UW3bjl0FkQkhYpf4KyEAiLbbbTlMIGG325WT8JBatIvVsqyc1umu0zStliN96LCgnPNw6KmJ04Tkjtm2TQsLORPpMAy13w9+L3SJjuKRx7jf7x3HiRWDnJwEdFjTNHOKvdQlMA+9AbEjY+8f01mWJXMHDpBK3qY4aSTrR0IP2I7MRNe6gY37SWAVu1pdgmJDtRfLp/t6if52u+VzfQ7R08DJ773f75M4UPBf6v1Puqf8U0pWV8mBDis/OVQqPncZKO+u63ZkpD3jelLqZexIrdA0Tc6kNB4DqcoXPXsNw0hWfGwOFCXcLlUSpbUt+g1XwSdnah6LsErrWXRfO9Hncz3pK/mzcDqdhBDJnwB0ndT7n54Q1QkaXJ9cPavg/Kxl8JtdLBYdGWPPzkhYr9d4ZbAQ4nw+kzks9dX1ZKbXNC3VnKrrOpkvMSsdSbiuW5evbzAYlHtyVI+sRwRC96MtU+fd87zpdPrz8zOZTOC0bNlGL4SgY+OgtaR2dTgcWpYVBMFqtZKjP+GmSr3/TdMMgqD6nYY4nNS+cWZ3EOgZ1wshZK5HoIicCXApuDuHawaDQdZVeo9EFS+i7/vj8bhErOH094NRPCQBmsjCp7BX8PIpxms+EPCsscTovn2iPxwOhfcwdZ643nVdmeuzxiXn18jUHIcjA4t0jQhDZrlEz+JwNpuNzJ4UQqBpWpKUoYvlsNXlckm9GkXRYDAYj8f5EQ45iC+Xy/f39yrnAOcIb+FSda6Hwoj94jnd7izgiMwZDocfHx/kBU1Vk3NGV/oS4g4KW6TV2/V6xSNWPlw39TYmDiq37Cs9Iq74QAR6xvUyUjhuN1WpL2SrfEVS0zTHceTnity0StowjNSOqdR9eBlCzzCM0ghgx6yiXt9ZwD3PM02TTIVBEBTSbo1zBwwLZcJojkesEALbgPFbkOVQZo23KPogt3JXWt6E8fD0XT1PFgYackxOslirOR3xG5ToBoyYOREISYcVGtrtduxNAhpygnx9ZC6T8+9Kkzqfg/9d0h5YGJGj9JrcJnpChJuMucSSqLBRUHzME0ju2aQDNiu/sKFkAbBVrOlkycIciOpCorC3+QUwhO6QTI/1+hwDjhCi0NAZBEGqRxeT9LIJqIGpBi5FWAh/RaVeUWb7xTabzXw+pzh69W1W7fcTymPMaE7bry6Xi7zlyvf9j48P27ZhI2q/w6kt5rNny1dTe1giMzYjJSTUVaV/vlkaOQJFUvkaxvocrvn5+cnabVsXuOXkbDabGvfajcfj5BER+R2rzvWwGkMzzW+xm1dB9Pv9fjgcxly1LfRZnSbgAITpgLq3XC5d1x2NRpvN5vPzk+4risBJurgqjgh9qCiHqzeEQF+5HmyYyia4mqWZ+r7fWa/Uer1G/6vPumma5bg+1VhPe+sLewWTQs6ztlDIYwvEiJ460zLdU3QNxRbn+wlww8RueCg0sN0/FtUXaV12hseevg9EoK82HLitUikbKkYW0N/f30mvFJ0cMp1OFRktNm1UfTabjUajKiuG8/lc43IVKnast1lfoygi9GKsIYTwPC8V7aQozE5SiFy4I4DLXaJ0KtHTJUTmqB+RlpSvmIONx8AzqyI9XA3DiD0S8AzIqlg9Hz8x2JGqy3wmCeqLs8ZHXSOttCkKHrPUPYH4kaTu7z+dTqm7SXEeCJ0tde9wUJ0cX9V3n9/bgVrKY7Nl8hgcwzBS0U62q+iYBWKdAlxlZ2zWrtokFCo5Wb7Z2+2m2BDRRHLKNE1LPSBBpVeKZcD13XFCKva8uWKIbujUeTh91ethHEhqLlEUYY9Vqq4xn89xBCOepXSkLYUYXn4/uKSSmM1mi8VCjlCE1VulenfKYEkUU+Fns5lt2zG1MavbKo7ZbgKuuGGqNe3++/tb07QgCHLWZ7SItG07aayzLGs+n3uelzVT1fOht+LOqS6z7xJkKPAsfPig+sr1o9GIlEecyAooHcf5+voiqkpeXa1WhmEkF+A4uJzOXcg3PqAtSpD1HzxIjx/8BmKFO/411f+x2Wz2+72iYUrxHbMdBFyR6GkGa6T7VI2EWtF1PQgCTdM+Pj5kKzDuIt/3Pz8/TdNMJXTSaT4+PmLh6vTih+l0utlsMF+QeVcCOkHOKO4S+GSFO8QDzS1kmpZM56AJIRDYezqdbNumOOX9fk9PVKxh5auxvoVhiPUvhe3ja6xk6lc0QVdp3d1TGw6O4qLz+U6nk+M4pmmmWsNS0UAkXw6GHQScjFf3HlOsaGNJBep2u4VhiBvVMIz9fp+K8+l0siwrZpAJw5DuVdz/qa3AL0WHG9PfGJ9WMb8QArRNN7UDL5gJQ6gQInX3z0Mw6dk5l0mMvr6+TNOkO9gwDJl26cdAeodhGJZl5bAPJNMTAl9LJKpLKNFovVVc1zUMQ9M00zRlSFVawR63VNpKSqgOV3UJt9uNhqzokJBH4ThO/jmUcmE5DaBizJvF3bT7zzAM85/PYrHI6TA9dBeLRepEhGG42+1c1yX0Uj1Ycm+z0vIossq8Wj7UHSFEzgS1DEvvub5evOiBnNzBqN4KuWWSOxXVJfS9JFmBFLnjxQFPsnAyp9z9QMCqHJ4ehiFN2b0PdeqY7Poq19VyteR26WFZuDrZbrfQC23bbo6F5b6VG10Ttfpqr4+pQnV9Xa/XsaM075VMLtm7zP33NtHx8uSYTd3jluz5iwMuO/MJnGROEjSVHNruq3Lspa7rpIeWiyaAvV4IkepRUOltiTK073exWKADSKRKm81mHx8fjuNEvx/DMP79739X9FWkNiSEgOuC1kxZxdrOb+IB0lOZNENYj59OpxK2NjJflqjYU9Bi3Ua0mYp+yoDH0KvrKwFbqOfKzQkhFJdicq3b7fZw2zQcEjkeMlK0sdqGj6HcUiaGQPIr5INMkmXaz2G9/u/hSkE7uHUo3O3vslqKlKPaN6CrNd52qfP5PBwO397eNpsNtU3RrpZlqeinDHhDE0bgJ8ORs5ojfbxcxAiin/F2mqxWGsrHciQZXIcW6XRxUDBisvOXAqh+bwLINyT/3v5Qeeb6P9xo8yFuiMvlgjBKKjT5/eQsVA+Hw/V6fR0DDo5YwY+HrAGyvfIP30SKAU9AUluG4zjH4zEnKl9uieZL9rLKV/PTuq7DUgGOy69S41U6mZwWJVlioYjgh0mWH9d1cx4PWdJU8oFDagSzioRGyrS/lOhsi3SvU/ccx4m5buBbzwqToFiOTu2Uaxpq/Hho+Uzcre7ZZsAbnSAimhzLBrVOs6Dixc3qLRjtLqtRlrS78mFByuk/7tK7JFcpDKZWCfyr0tBddTkO5w+uMAwty7J/P0mDexiGxu8n54amuypZ96+N50rRSRXEJoTPXTZfBrzp24FCKi3LSjJ+GIa05dA0zeTVuzoGs+dds39XE1mFsRbJ+dER88JYnyWqrnzSeKjRmL5YVxPl5DDX341bjt5KE3y3xD5XoDg2egrmrHiqDJEBr4IeuU8dx7EsyzRN6/dDifzwfPVGYbJr/9U0WFJk9RbBAg3dnMl2YQAQolvs2tczjbFK6k6CbKMw93enY4325IFvQn9NwEvMJvmZSlRUrALCvV6vURSpuOUVJRcWowBfWGmS5eG5lX3IyWI15kCvByw1Cq8iin2z96F3Pp9l37rsp6Wokv6+T/w+INoqzYC3hXT5dmQPJ7i1vDjlmnglUQ7X4zjonDLKDSoVRIutPV2UutW1VUZyQdS1HBzDi+0S1EPeLtvQTDHgDQFbr1josK2ZSm63m4qxnjSzNo1LYN6GgvdLTxzr9Zia4sThcNA0jZaotFIjZSGKoo+PD8uyoGgUy+ISCggw4AogdaIItGZotTV2K4qi5XI5Go3oeE68YwtriNh2FtrzQUd7Uvjj9XqVT/pUDEUtMQR5Iy4wKSGniSpvt9utCblPKXM2myFWVwixXC6v12sYhtfr1XGc5OnhTwlCm4NiwNtEu0pbvu+/v78LITRNkw2bVWRS3dVqRYc2f39/E6evVqvtdhsEAW3+SupYh8OBlt3H45Fsqo7jwJE2GAxiz4bqnYQEeqMZnfop8z4KPDJRekXAFRkBRoARAAJgsZzwRxRWTJBqnIxyprAiajEnsh5vr6sYVKrYW5wHTmdqqddqpyTbcHCLcoIRYATKIwCTPUwr5WX91pxOp0EQpL6GxXVdtJJjKkGZ1tykCLjEMqIiCDVWZ66vEUwWxQi8LgI42RQMWwWL5XJJB28kXy0nhNB1HeFwOQYZch7Ax1alPyp1z+cz3j4oxyap1G2hDHN9CyBzE4zA8yOA3bPVuf5wONBh17ZtZ1E5OV1zlHqcxZZfBhMTRVFFny1OhVJsEU23k2CubwdnboUReHIEdF2HGadiQBo2qeD5EcMO8nNYFcStYsCJomgwGIzH4yqO5S4bcIQQzPWxu4i/MgKMQEkEQM2phhdFoYfDgVYGmqZlWUKwdMjh+nv3r2qa5jhO6U2/URQh3hTmLMUht1OMub4dnLkVRuD5EQDHwZpRYsx4TkBaUggeBlkWHiEEmFdFr9d1PYoiOaI62Wh+jqzUl35g5DdR8SpzfUUAuTojwAj8FwFd16Foe55XDheZNLMkEI/nkzjp9a05ZvGIggEqq/OPymeufxTy3C4j8IQI4NwCcN9dg4yiCKEsWVQOY31+XKPK8+CuvuUUPp/P1JxhGDlLjRwJLVxirm8BZG6CEXgVBCaTCUVDBkFQws+JNzoZhpFlCVEx1sMxC3dxoxOABxs8Fo02V044c3053LgWI8AIpCOA4+yRSC+Xm5vD0TDWy68IxSE5JBWO2azFARWLomg2m02n09FohMdDbr/SLzLXp+PCuYwAI/DECEynU3oDLcXI3zVS7JDKetE5wl3gGBBCeJ6Hc2epOThm5WLJnnx+frqu63neYDDIcQUnK8o5nueR3WmxWGStReTyj0qzXv8o5LldRuBpEYB/crVa3TVIcCXeVx6rDg1aVti/v79jTK3imF2tVrZtU4uX30+sLcWvNFhN0zBqxYptF2vn2B1uhRFgBF4KASLrEgfHk8c1ed4ZvUwRzwC8tjsMw2QrRKP575jF1Sovn0DUUM4RbB2Zd9br2364cnuMwCsgQAr49Xq9N2idrPzJCH3P8+bzORyzwHC73cYMNThMOMfoH0UR/KjUVXyFZJUElPrlcqlS/pFlOvLM4W4wAozAkyFAVJtUuguHScqyZVlhGN5ut9Pp5DiOaZr0lcI66Y3zu91O0zTKh1jo2tD9cSk1QWuF1Ev5mWioa6+gSu12t950ntpFzmQEGIE+IoBgmBIvJjydTrZtG78f0zRjrP319WUYhqZppmkmj8tHjH/sGZCK4W63K33cPHmSDcNIldy1TOb6rs0I94cReB4EYBg5nU6tjYrWE6ZpqrRI9p/kA6OwLp4oJeoWCm+iANvrH2lA47YZgedGwHVdspDM5/PWRkoBl7HInNTWoygKggCbXc/ns2KU/fl8pohS13U7u1E2NmTm+hgg/JURYARqQ0DXdTJqB0FQ+oScu3oDxyyWFDnVY17Z7+9vxPnk1BJC0IPEsqweuGT/GQlz/T9I8H9GgBFoAIHJZAJvaolTE/J7dD6fh8Ph29sbon0ogMeyLITq50ggjwLO1blcLvJe3KyKm83meDxqmgbfbFbJbuU3YRhimYwAI8AIyAiQWRwh7fKlKmnQNCSTsV7Rhk4PIeqA4zgqTgU4nGPu4iqjaKcu+2bbwZlbYQReGgHa8SSEKBGTkwMcIut3u93tdiMipnDMnFq4FIahZVn270fl8RCGIcXeqDeBth6eeLvdbt1aaHBvGAFG4BkROBwOdLDBbrfLeuHUvePebDbz+ZwERlE0Ho81TVP0r97blhBiMpkEQWBZFs5VLiHkUVWY6x+FPLfLCLwcAp7nkVdzv9/XFb7ieZ7runT6mG3b957Aoz4H0+n05+fHNM3mniXqnSlRkrm+BGhchRFgBEoiQHSvadp+v1dxhJZspu5qy+VyvV4bhrHf71W8vnW3X4M8jsOpAUQWwQgwAooITKfT7XZ7vV7H4zHiIxXrPqrYarVar9e0R7enRC+EYL3+UfcPt8sIvC4Cvu+/v78bhtF9uqeumqYZBEF/iZ65/nV/bDxyRuCxCJzP5+v1WpfVvrmxRFF0uVy6389CBFivL4SICzACjAAj0HsE2F7f+ynkATACjAAjUIgAc30hRFyAEWAEGIHeI8Bc3/sp5AEwAowAI1CIAHN9IURcgBFgBBiB3iPAXN/7KeQBMAKMACNQiABzfSFEXIARYAQYgd4jwFzf+ynkATACjAAjUIgAc30hRFyAEWAEGIHeI8Bc3/sp5AEwAowAI1CIAHN9IURcgBFgBBiB3iPAXN/7KeQBMAKMACNQiABzfSFEXIARYAQYgd4jwFzf+ynkATACjAAjUIgAc30hRFyAEWAEGIHeI8Bc3/sp5AEwAowAI1CIAHN9IURcgBFgBBiB3iPAXN/7KeQBMAKMACNQiMB/AB3zO335BSlgAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TERM FREQUENCY–INVERSE DOCUMENT FREQUENCY (TF-IDF)\n",
    "![image.png](attachment:image.png)\n",
    "The quintessential early Natural Language Processing tool, the TF-IDF analysis for context and sentiment evaluation is useful only over a large corpus. It must be understood that the corpus is not just a sample to be evaluated, but instead is the entire population that sets a 'benchmark' for evaluation, if you will. \n",
    "\n",
    "Here we establish a Term Frequency (TF) count of word frequencies, just as we showed a phrase frequency count in the last step in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraordinary\n",
      "series\n",
      "of\n",
      "adventure\n",
      "in\n",
      "the\n",
      "South\n",
      "Seas\n",
      "and\n",
      "elsewhere,\n",
      "of\n",
      "which\n",
      "an\n",
      "account\n",
      "is\n",
      "given\n",
      "in\n",
      "the\n",
      "following\n",
      "pages,\n",
      "accident\n",
      "threw\n",
      "me\n",
      "into\n",
      "the\n",
      "society\n",
      "of\n",
      "several\n",
      "gentlemen\n",
      "in\n",
      "Richmond,\n",
      "Va.\n",
      "interest\n",
      "in\n",
      "all\n",
      "matters\n",
      "relating\n",
      "to\n",
      "the\n",
      "regions\n",
      "I\n",
      "had\n",
      "visited,\n",
      "and\n",
      "who\n",
      "were\n",
      "constantly\n",
      "urging\n",
      "it\n",
      "upon\n"
     ]
    }
   ],
   "source": [
    "#Establish wordList\n",
    "wordList = []\n",
    "for u in range(len(sentences)):\n",
    "    for v in sentences[u]:\n",
    "        words = re.split(\"\\\\s+\", v)\n",
    "        wordList.extend(words)\n",
    "        \n",
    "for w in range(50):\n",
    "    print(wordList[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish wordDict\n",
    "wordDict = {}\n",
    "for w in range(len(wordList)):\n",
    "    newWord = wordList[w]\n",
    "    newWord = newWord.lower()\n",
    "    newWord = newWord.replace('.', '')\n",
    "    wordDict[w] = newWord\n",
    "print(wordDict)\n",
    "    \n",
    "#Perform word counts on dict\n",
    "countDict = {}\n",
    "for x in range(len(wordDict)):\n",
    "    term = wordDict[x]\n",
    "    count = 1\n",
    "    for y in range(len(wordDict)):\n",
    "        try:\n",
    "            if wordDict[y].find(term) > 0:\n",
    "                count += 1\n",
    "        except:\n",
    "            pass\n",
    "        countDict[term] = count\n",
    "\n",
    "#for k, v in countDict.items():\n",
    "    #print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Computes ratio of word's appearances to total words\n",
    "bow = wordList\n",
    "bowCount = len(bow) #BOW = Bag of Words\n",
    "tfDict = {}\n",
    "for term, count in countDict.items():\n",
    "    tfDict[term] = count/float(bowCount)\n",
    "\n",
    "num = dict(sorted(tfDict.items(), key=lambda x: x[1], reverse = True))\n",
    "for k, v in num.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO BE CONTINUED...\n",
    "At this point, this notebook is finished. Please refer to Part 2 for a continuation of this process, wherein the code in this notebook is converted into objects and a multiple document corpus is compiled."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
