{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bytelevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Conv1D, Input, GRU, LSTM, Bidirectional, Dense, UpSampling1D, Dropout, TimeDistributed, RepeatVector\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyper_params import *\n",
    "import text_encoder as te\n",
    "import text_decoder as td\n",
    "from data_set import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/norvig/big.txt') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = make_chunks(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.shuffle(chunks)\n",
    "train_text, test_text = make_train_test(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_h = EmbeddingHyper(256, 64)\n",
    "conv_h = ConvHyper(128, 6, 4)\n",
    "rnn_h = RnnHyper(256, is_lstm=False, is_bidirectional=True, return_sequences=False)\n",
    "encoder_h = te.Hyper(embed_h, [conv_h, rnn_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dernn_h = RnnHyper(64, is_lstm=False, is_bidirectional=False, return_sequences=True, unroll=True)\n",
    "dec_h = DeconvHyper(128, 6, 4)\n",
    "decoder_h = td.Hyper(256, [dernn_h, dec_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder_h.make_layer()\n",
    "decoder = decoder_h.make_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(max_len):\n",
    "    x = Input(shape=(max_len,), name='text_input')\n",
    "    h = encoder(x)\n",
    "    h = decoder(h, max_len)\n",
    "    model = Model(x, h)\n",
    "    model.compile(optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['categorical_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model64, model128, model256 = make_model(64), make_model(128), make_model(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {64: model64, 128: model128, 256: model256 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_round(max_len, history=None):\n",
    "    if history is None:\n",
    "        initial_epoch = 0\n",
    "    else:\n",
    "        initial_epoch = len(history['loss'])\n",
    "    train, test = SlicedData.Random(train_text, test_text, max_len, 10000, r)\n",
    "    model = models[max_len]\n",
    "    newhistory = model.fit(x=train.x, y=train.y,\n",
    "                            epochs=initial_epoch+5, batch_size=100,\n",
    "                            validation_data=(test.x, test.y),\n",
    "                            initial_epoch=initial_epoch)\n",
    "    if history is None:\n",
    "        history = newhistory.history\n",
    "    else:\n",
    "        history = {key:history[key] + newhistory.history[key] for key in history.keys()}\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "10000/10000 [==============================] - 12s - loss: 3.4496 - categorical_accuracy: 0.1515 - val_loss: 3.1122 - val_categorical_accuracy: 0.1617\n",
      "Epoch 2/5\n",
      "10000/10000 [==============================] - 11s - loss: 3.1191 - categorical_accuracy: 0.1600 - val_loss: 3.0871 - val_categorical_accuracy: 0.1617\n",
      "Epoch 3/5\n",
      "10000/10000 [==============================] - 11s - loss: 3.0979 - categorical_accuracy: 0.1601 - val_loss: 3.0794 - val_categorical_accuracy: 0.1616\n",
      "Epoch 4/5\n",
      "10000/10000 [==============================] - 12s - loss: 3.0905 - categorical_accuracy: 0.1601 - val_loss: 3.0739 - val_categorical_accuracy: 0.1617\n",
      "Epoch 5/5\n",
      "10000/10000 [==============================] - 12s - loss: 3.0823 - categorical_accuracy: 0.1601 - val_loss: 3.0673 - val_categorical_accuracy: 0.1617\n",
      "1\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 12s - loss: 3.0769 - categorical_accuracy: 0.1589 - val_loss: 3.0486 - val_categorical_accuracy: 0.1627\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 12s - loss: 3.0578 - categorical_accuracy: 0.1590 - val_loss: 3.0342 - val_categorical_accuracy: 0.1633\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 12s - loss: 3.0392 - categorical_accuracy: 0.1595 - val_loss: 3.0183 - val_categorical_accuracy: 0.1634\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 12s - loss: 3.0222 - categorical_accuracy: 0.1604 - val_loss: 3.0043 - val_categorical_accuracy: 0.1642\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 12s - loss: 3.0050 - categorical_accuracy: 0.1613 - val_loss: 2.9921 - val_categorical_accuracy: 0.1657\n",
      "2\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 11/15\n",
      "10000/10000 [==============================] - 12s - loss: 2.9812 - categorical_accuracy: 0.1639 - val_loss: 2.9617 - val_categorical_accuracy: 0.1674\n",
      "Epoch 12/15\n",
      "10000/10000 [==============================] - 12s - loss: 2.9601 - categorical_accuracy: 0.1653 - val_loss: 2.9552 - val_categorical_accuracy: 0.1652\n",
      "Epoch 13/15\n",
      "10000/10000 [==============================] - 12s - loss: 2.9399 - categorical_accuracy: 0.1662 - val_loss: 2.9296 - val_categorical_accuracy: 0.1681\n",
      "Epoch 14/15\n",
      "10000/10000 [==============================] - 12s - loss: 2.9210 - categorical_accuracy: 0.1672 - val_loss: 2.9167 - val_categorical_accuracy: 0.1685\n",
      "Epoch 15/15\n",
      "10000/10000 [==============================] - 12s - loss: 2.9002 - categorical_accuracy: 0.1686 - val_loss: 2.8930 - val_categorical_accuracy: 0.1703\n",
      "3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-953ff07aa858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-dce2011a2780>\u001b[0m in \u001b[0;36mtraining_round\u001b[0;34m(max_len, history)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSlicedData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     newhistory = model.fit(x=train.x, y=train.y,\n",
      "\u001b[0;32m~/repos/reading-club/dependencies/nlp-encoder-assembly/data_set.py\u001b[0m in \u001b[0;36mRandom\u001b[0;34m(train_text, test_text, max_len, n, r)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtest_slices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrandom_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSlicedData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSlicedData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/reading-club/dependencies/nlp-encoder-assembly/data_set.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text, max_len)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytelevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytelevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/reading-club/dependencies/nlp-encoder-assembly/bytelevel.py\u001b[0m in \u001b[0;36monehot\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    print(i)\n",
    "    history = training_round(64, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_h = EmbeddingHyper(256, 64)\n",
    "conv_h = ConvHyper(128, 6, 4)\n",
    "rnn_h = RnnHyper(256, is_lstm=False, is_bidirectional=True, return_sequences=False)\n",
    "dec_h = DeconvHyper(128, 6, 4)\n",
    "\n",
    "emb = embed_h.make_layer('')\n",
    "cnn0 = conv_h.make_layer('cnn0')\n",
    "cnn1 = conv_h.make_layer('cnn1')\n",
    "cnn2 = conv_h.make_layer('cnn2')\n",
    "rnn = rnn_h.make_layer('encoder_rnn')\n",
    "\n",
    "dernn = GRU(256, return_sequences=True, unroll=True)\n",
    "dec0, up = dec_h.make_layers('dcnn0')\n",
    "dec1, _ = dec_h.make_layers('dcnn1')\n",
    "dec2, _ = dec_h.make_layers('dcnn2')\n",
    "dense = Dense(256, activation='softmax', name='probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 256, 64)\n",
      "(?, 64, 128)\n",
      "(?, 16, 128)\n",
      "(?, 4, 128)\n",
      "(?, 512)\n",
      "(?, 4, 512)\n",
      "(?, 4, 256)\n",
      "(?, 16, 256)\n",
      "(?, 16, 128)\n",
      "(?, 64, 128)\n",
      "(?, 64, 128)\n",
      "(?, 256, 128)\n",
      "(?, 256, 128)\n",
      "(?, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "max_len = 256\n",
    "x = Input(shape=(max_len,), name='text_input')\n",
    "h = emb(x)\n",
    "print(h.shape)\n",
    "h = cnn0(h)\n",
    "print(h.shape)\n",
    "h = cnn1(h)\n",
    "print(h.shape)\n",
    "h = cnn2(h)\n",
    "print(h.shape)\n",
    "h = rnn(h)\n",
    "print(h.shape)\n",
    "h = RepeatVector(int(max_len / 64))(h)\n",
    "print(h.shape)\n",
    "h = dernn(h)\n",
    "print(h.shape)\n",
    "h = up(h)\n",
    "print(h.shape)\n",
    "h = dec0(h)\n",
    "print(h.shape)\n",
    "h = up(h)\n",
    "print(h.shape)\n",
    "h = dec1(h)\n",
    "print(h.shape)\n",
    "h = up(h)\n",
    "print(h.shape)\n",
    "h = dec2(h)\n",
    "print(h.shape)\n",
    "h = TimeDistributed(dense)(h)\n",
    "print(h.shape)\n",
    "model = Model(x, h)\n",
    "model.compile(optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(max_len):\n",
    "    x = Input(shape=(max_len,), name='text_input')\n",
    "    h = emb(x)\n",
    "    print(h.shape)\n",
    "    h = cnn0(h)\n",
    "    print(h.shape)\n",
    "    h = cnn1(h)\n",
    "    print(h.shape)\n",
    "    h = cnn2(h)\n",
    "    print(h.shape)\n",
    "    h = rnn(h)\n",
    "    print(h.shape)\n",
    "    h = RepeatVector(int(max_len / 64))(h)\n",
    "    print(h.shape)\n",
    "    h = dernn(h)\n",
    "    print(h.shape)\n",
    "    h = up(h)\n",
    "    print(h.shape)\n",
    "    h = dec0(h)\n",
    "    print(h.shape)\n",
    "    h = up(h)\n",
    "    print(h.shape)\n",
    "    h = dec1(h)\n",
    "    print(h.shape)\n",
    "    h = up(h)\n",
    "    print(h.shape)\n",
    "    h = dec2(h)\n",
    "    print(h.shape)\n",
    "    h = TimeDistributed(dense)(h)\n",
    "    print(h.shape)\n",
    "    model = Model(x, h)\n",
    "    model.compile(optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 64, 64)\n",
      "(?, 16, 128)\n",
      "(?, 4, 128)\n",
      "(?, 1, 128)\n",
      "(?, 512)\n",
      "(?, 1, 512)\n",
      "(?, 1, 256)\n",
      "(?, 4, 256)\n",
      "(?, 4, 128)\n",
      "(?, 16, 128)\n",
      "(?, 16, 128)\n",
      "(?, 64, 128)\n",
      "(?, 64, 128)\n",
      "(?, 64, 256)\n",
      "(?, 128, 64)\n",
      "(?, 32, 128)\n",
      "(?, 8, 128)\n",
      "(?, 2, 128)\n",
      "(?, 512)\n",
      "(?, 2, 512)\n",
      "(?, 2, 256)\n",
      "(?, 8, 256)\n",
      "(?, 8, 128)\n",
      "(?, 32, 128)\n",
      "(?, 32, 128)\n",
      "(?, 128, 128)\n",
      "(?, 128, 128)\n",
      "(?, 128, 256)\n",
      "(?, 256, 64)\n",
      "(?, 64, 128)\n",
      "(?, 16, 128)\n",
      "(?, 4, 128)\n",
      "(?, 512)\n",
      "(?, 4, 512)\n",
      "(?, 4, 256)\n",
      "(?, 16, 256)\n",
      "(?, 16, 128)\n",
      "(?, 64, 128)\n",
      "(?, 64, 128)\n",
      "(?, 256, 128)\n",
      "(?, 256, 128)\n",
      "(?, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "model64, model128, model256 = make_model(64), make_model(128), make_model(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {64: model64, 128: model128, 256: model256 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_weights(m0, m1):\n",
    "    print([norm(v - u) for u, v in zip(m0.get_weights(), m1.get_weights())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_round(max_len, history=None):\n",
    "    if history is None:\n",
    "        initial_epoch = 0\n",
    "    else:\n",
    "        initial_epoch = len(history['loss'])\n",
    "    train, test = SlicedData.Random(train_text, test_text, max_len, 10000, r)\n",
    "    model = models[max_len]\n",
    "    newhistory = model.fit(x=train.x, y=train.y,\n",
    "                            epochs=initial_epoch+5, batch_size=32,\n",
    "                            validation_data=(test.x, test.y),\n",
    "                            initial_epoch=initial_epoch)\n",
    "    if history is None:\n",
    "        history = newhistory.history\n",
    "    else:\n",
    "        history = {key:history[key] + newhistory.history[key] for key in history.keys()}\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "10000/10000 [==============================] - 30s - loss: 3.1259 - categorical_accuracy: 0.1590 - val_loss: 3.0836 - val_categorical_accuracy: 0.1626\n",
      "Epoch 2/5\n",
      "10000/10000 [==============================] - 28s - loss: 3.1060 - categorical_accuracy: 0.1590 - val_loss: 3.0737 - val_categorical_accuracy: 0.1626\n",
      "Epoch 3/5\n",
      "10000/10000 [==============================] - 28s - loss: 3.0922 - categorical_accuracy: 0.1590 - val_loss: 3.0601 - val_categorical_accuracy: 0.1625\n",
      "Epoch 4/5\n",
      "10000/10000 [==============================] - 28s - loss: 3.0783 - categorical_accuracy: 0.1590 - val_loss: 3.0525 - val_categorical_accuracy: 0.1627\n",
      "Epoch 5/5\n",
      "10000/10000 [==============================] - 28s - loss: 3.0697 - categorical_accuracy: 0.1591 - val_loss: 3.0464 - val_categorical_accuracy: 0.1627\n"
     ]
    }
   ],
   "source": [
    "max_len = 256\n",
    "train, test = SlicedData.Random(train_text, test_text, max_len, 10000, r)\n",
    "history = model256.fit(x=train.x, \n",
    "        y=train.y,\n",
    "        epochs=5, batch_size=50,\n",
    "        validation_data=(test.x, test.y))\n",
    "history = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 34s - loss: 3.0613 - categorical_accuracy: 0.1602 - val_loss: 3.0410 - val_categorical_accuracy: 0.1628\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 31s - loss: 3.0467 - categorical_accuracy: 0.1604 - val_loss: 3.0299 - val_categorical_accuracy: 0.1630\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 31s - loss: 3.0326 - categorical_accuracy: 0.1616 - val_loss: 3.0135 - val_categorical_accuracy: 0.1651\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 31s - loss: 3.0183 - categorical_accuracy: 0.1635 - val_loss: 3.0058 - val_categorical_accuracy: 0.1666\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 31s - loss: 3.0050 - categorical_accuracy: 0.1656 - val_loss: 2.9925 - val_categorical_accuracy: 0.1685\n",
      "1\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 11/15\n",
      "10000/10000 [==============================] - 32s - loss: 3.0014 - categorical_accuracy: 0.1661 - val_loss: 2.9820 - val_categorical_accuracy: 0.1716\n",
      "Epoch 12/15\n",
      "10000/10000 [==============================] - 32s - loss: 2.9906 - categorical_accuracy: 0.1677 - val_loss: 2.9746 - val_categorical_accuracy: 0.1728\n",
      "Epoch 13/15\n",
      "10000/10000 [==============================] - 32s - loss: 2.9805 - categorical_accuracy: 0.1690 - val_loss: 2.9676 - val_categorical_accuracy: 0.1739\n",
      "Epoch 14/15\n",
      "10000/10000 [==============================] - 32s - loss: 2.9705 - categorical_accuracy: 0.1704 - val_loss: 2.9605 - val_categorical_accuracy: 0.1752\n",
      "Epoch 15/15\n",
      "10000/10000 [==============================] - 32s - loss: 2.9616 - categorical_accuracy: 0.1719 - val_loss: 2.9524 - val_categorical_accuracy: 0.1763\n",
      "2\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 32s - loss: 2.9528 - categorical_accuracy: 0.1728 - val_loss: 2.9340 - val_categorical_accuracy: 0.1778\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 32s - loss: 2.9369 - categorical_accuracy: 0.1748 - val_loss: 2.9283 - val_categorical_accuracy: 0.1787\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 32s - loss: 2.9281 - categorical_accuracy: 0.1761 - val_loss: 2.9207 - val_categorical_accuracy: 0.1795\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 32s - loss: 2.9188 - categorical_accuracy: 0.1775 - val_loss: 2.9133 - val_categorical_accuracy: 0.1809\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 32s - loss: 2.9126 - categorical_accuracy: 0.1786 - val_loss: 2.9109 - val_categorical_accuracy: 0.1818\n",
      "3\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 21/25\n",
      "10000/10000 [==============================] - 32s - loss: 2.9147 - categorical_accuracy: 0.1790 - val_loss: 2.9121 - val_categorical_accuracy: 0.1830\n",
      "Epoch 22/25\n",
      "10000/10000 [==============================] - 32s - loss: 2.9045 - categorical_accuracy: 0.1803 - val_loss: 2.9039 - val_categorical_accuracy: 0.1845\n",
      "Epoch 23/25\n",
      "10000/10000 [==============================] - 32s - loss: 2.8985 - categorical_accuracy: 0.1812 - val_loss: 2.9022 - val_categorical_accuracy: 0.1836\n",
      "Epoch 24/25\n",
      "10000/10000 [==============================] - 32s - loss: 2.8921 - categorical_accuracy: 0.1823 - val_loss: 2.8973 - val_categorical_accuracy: 0.1845\n",
      "Epoch 25/25\n",
      "10000/10000 [==============================] - 32s - loss: 2.8873 - categorical_accuracy: 0.1829 - val_loss: 2.8974 - val_categorical_accuracy: 0.1850\n",
      "4\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 26/30\n",
      "10000/10000 [==============================] - 32s - loss: 2.8964 - categorical_accuracy: 0.1815 - val_loss: 2.8935 - val_categorical_accuracy: 0.1845\n",
      "Epoch 27/30\n",
      "10000/10000 [==============================] - 32s - loss: 2.8866 - categorical_accuracy: 0.1828 - val_loss: 2.8933 - val_categorical_accuracy: 0.1841\n",
      "Epoch 28/30\n",
      "10000/10000 [==============================] - 32s - loss: 2.8810 - categorical_accuracy: 0.1836 - val_loss: 2.8895 - val_categorical_accuracy: 0.1852\n",
      "Epoch 29/30\n",
      "10000/10000 [==============================] - 32s - loss: 2.8756 - categorical_accuracy: 0.1844 - val_loss: 2.8867 - val_categorical_accuracy: 0.1857\n",
      "Epoch 30/30\n",
      "10000/10000 [==============================] - 32s - loss: 2.8707 - categorical_accuracy: 0.1850 - val_loss: 2.8835 - val_categorical_accuracy: 0.1857\n",
      "5\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 31/35\n",
      "10000/10000 [==============================] - 32s - loss: 2.8794 - categorical_accuracy: 0.1840 - val_loss: 2.8771 - val_categorical_accuracy: 0.1870\n",
      "Epoch 32/35\n",
      "10000/10000 [==============================] - 32s - loss: 2.8695 - categorical_accuracy: 0.1852 - val_loss: 2.8735 - val_categorical_accuracy: 0.1869\n",
      "Epoch 33/35\n",
      "10000/10000 [==============================] - 32s - loss: 2.8623 - categorical_accuracy: 0.1863 - val_loss: 2.8717 - val_categorical_accuracy: 0.1874\n",
      "Epoch 34/35\n",
      "10000/10000 [==============================] - 32s - loss: 2.8578 - categorical_accuracy: 0.1868 - val_loss: 2.8675 - val_categorical_accuracy: 0.1882\n",
      "Epoch 35/35\n",
      "10000/10000 [==============================] - 32s - loss: 2.8527 - categorical_accuracy: 0.1877 - val_loss: 2.8639 - val_categorical_accuracy: 0.1885\n",
      "6\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 36/40\n",
      "10000/10000 [==============================] - 32s - loss: 2.8591 - categorical_accuracy: 0.1869 - val_loss: 2.8580 - val_categorical_accuracy: 0.1884\n",
      "Epoch 37/40\n",
      "10000/10000 [==============================] - 32s - loss: 2.8488 - categorical_accuracy: 0.1885 - val_loss: 2.8512 - val_categorical_accuracy: 0.1891\n",
      "Epoch 38/40\n",
      "10000/10000 [==============================] - 32s - loss: 2.8432 - categorical_accuracy: 0.1892 - val_loss: 2.8526 - val_categorical_accuracy: 0.1889\n",
      "Epoch 39/40\n",
      "10000/10000 [==============================] - 32s - loss: 2.8388 - categorical_accuracy: 0.1899 - val_loss: 2.8492 - val_categorical_accuracy: 0.1895\n",
      "Epoch 40/40\n",
      "10000/10000 [==============================] - 32s - loss: 2.8352 - categorical_accuracy: 0.1904 - val_loss: 2.8489 - val_categorical_accuracy: 0.1895\n",
      "7\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 41/45\n",
      "10000/10000 [==============================] - 32s - loss: 2.8495 - categorical_accuracy: 0.1883 - val_loss: 2.8479 - val_categorical_accuracy: 0.1908\n",
      "Epoch 42/45\n",
      "10000/10000 [==============================] - 32s - loss: 2.8412 - categorical_accuracy: 0.1897 - val_loss: 2.8463 - val_categorical_accuracy: 0.1907\n",
      "Epoch 43/45\n",
      "10000/10000 [==============================] - 32s - loss: 2.8352 - categorical_accuracy: 0.1906 - val_loss: 2.8467 - val_categorical_accuracy: 0.1912\n",
      "Epoch 44/45\n",
      "10000/10000 [==============================] - 32s - loss: 2.8312 - categorical_accuracy: 0.1912 - val_loss: 2.8435 - val_categorical_accuracy: 0.1911\n",
      "Epoch 45/45\n",
      "10000/10000 [==============================] - 32s - loss: 2.8274 - categorical_accuracy: 0.1918 - val_loss: 2.8398 - val_categorical_accuracy: 0.1916\n",
      "8\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 32s - loss: 2.8396 - categorical_accuracy: 0.1894 - val_loss: 2.8374 - val_categorical_accuracy: 0.1925\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 32s - loss: 2.8289 - categorical_accuracy: 0.1913 - val_loss: 2.8368 - val_categorical_accuracy: 0.1922\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 32s - loss: 2.8242 - categorical_accuracy: 0.1920 - val_loss: 2.8343 - val_categorical_accuracy: 0.1932\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 32s - loss: 2.8202 - categorical_accuracy: 0.1926 - val_loss: 2.8368 - val_categorical_accuracy: 0.1923\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 32s - loss: 2.8171 - categorical_accuracy: 0.1931 - val_loss: 2.8323 - val_categorical_accuracy: 0.1931\n",
      "9\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 51/55\n",
      "10000/10000 [==============================] - 32s - loss: 2.8335 - categorical_accuracy: 0.1904 - val_loss: 2.8298 - val_categorical_accuracy: 0.1935\n",
      "Epoch 52/55\n",
      "10000/10000 [==============================] - 32s - loss: 2.8249 - categorical_accuracy: 0.1919 - val_loss: 2.8334 - val_categorical_accuracy: 0.1929\n",
      "Epoch 53/55\n",
      "10000/10000 [==============================] - 31s - loss: 2.8190 - categorical_accuracy: 0.1930 - val_loss: 2.8288 - val_categorical_accuracy: 0.1935\n",
      "Epoch 54/55\n",
      "10000/10000 [==============================] - 31s - loss: 2.8146 - categorical_accuracy: 0.1935 - val_loss: 2.8261 - val_categorical_accuracy: 0.1947\n",
      "Epoch 55/55\n",
      "10000/10000 [==============================] - 31s - loss: 2.8107 - categorical_accuracy: 0.1943 - val_loss: 2.8296 - val_categorical_accuracy: 0.1939\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    history = training_round(256, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 56/60\n",
      "10000/10000 [==============================] - 31s - loss: 2.8253 - categorical_accuracy: 0.1922 - val_loss: 2.8226 - val_categorical_accuracy: 0.1945\n",
      "Epoch 57/60\n",
      "10000/10000 [==============================] - 31s - loss: 2.8134 - categorical_accuracy: 0.1940 - val_loss: 2.8195 - val_categorical_accuracy: 0.1948\n",
      "Epoch 58/60\n",
      "10000/10000 [==============================] - 31s - loss: 2.8086 - categorical_accuracy: 0.1948 - val_loss: 2.8193 - val_categorical_accuracy: 0.1954\n",
      "Epoch 59/60\n",
      "10000/10000 [==============================] - 31s - loss: 2.8055 - categorical_accuracy: 0.1952 - val_loss: 2.8198 - val_categorical_accuracy: 0.1954\n",
      "Epoch 60/60\n",
      "10000/10000 [==============================] - 31s - loss: 2.8010 - categorical_accuracy: 0.1960 - val_loss: 2.8156 - val_categorical_accuracy: 0.1957\n",
      "1\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 61/65\n",
      "10000/10000 [==============================] - 32s - loss: 2.8175 - categorical_accuracy: 0.1938 - val_loss: 2.8168 - val_categorical_accuracy: 0.1959\n",
      "Epoch 62/65\n",
      "10000/10000 [==============================] - 32s - loss: 2.8064 - categorical_accuracy: 0.1955 - val_loss: 2.8145 - val_categorical_accuracy: 0.1966\n",
      "Epoch 63/65\n",
      "10000/10000 [==============================] - 32s - loss: 2.8017 - categorical_accuracy: 0.1963 - val_loss: 2.8136 - val_categorical_accuracy: 0.1970\n",
      "Epoch 64/65\n",
      "10000/10000 [==============================] - 32s - loss: 2.7971 - categorical_accuracy: 0.1971 - val_loss: 2.8132 - val_categorical_accuracy: 0.1971\n",
      "Epoch 65/65\n",
      "10000/10000 [==============================] - 32s - loss: 2.7942 - categorical_accuracy: 0.1978 - val_loss: 2.8115 - val_categorical_accuracy: 0.1969\n",
      "2\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 66/70\n",
      "10000/10000 [==============================] - 32s - loss: 2.8113 - categorical_accuracy: 0.1952 - val_loss: 2.8156 - val_categorical_accuracy: 0.1962\n",
      "Epoch 67/70\n",
      "10000/10000 [==============================] - 32s - loss: 2.7975 - categorical_accuracy: 0.1976 - val_loss: 2.8088 - val_categorical_accuracy: 0.1981\n",
      "Epoch 68/70\n",
      "10000/10000 [==============================] - 32s - loss: 2.7917 - categorical_accuracy: 0.1987 - val_loss: 2.8090 - val_categorical_accuracy: 0.1979\n",
      "Epoch 69/70\n",
      "10000/10000 [==============================] - 32s - loss: 2.7878 - categorical_accuracy: 0.1993 - val_loss: 2.8090 - val_categorical_accuracy: 0.1979\n",
      "Epoch 70/70\n",
      "10000/10000 [==============================] - 32s - loss: 2.7844 - categorical_accuracy: 0.1999 - val_loss: 2.8043 - val_categorical_accuracy: 0.1988\n",
      "3\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 71/75\n",
      "10000/10000 [==============================] - 32s - loss: 2.7995 - categorical_accuracy: 0.1969 - val_loss: 2.8049 - val_categorical_accuracy: 0.1988\n",
      "Epoch 72/75\n",
      "10000/10000 [==============================] - 32s - loss: 2.7869 - categorical_accuracy: 0.1992 - val_loss: 2.8053 - val_categorical_accuracy: 0.1989\n",
      "Epoch 73/75\n",
      "10000/10000 [==============================] - 32s - loss: 2.7816 - categorical_accuracy: 0.2001 - val_loss: 2.8033 - val_categorical_accuracy: 0.1988\n",
      "Epoch 74/75\n",
      "10000/10000 [==============================] - 32s - loss: 2.7763 - categorical_accuracy: 0.2012 - val_loss: 2.7964 - val_categorical_accuracy: 0.2004\n",
      "Epoch 75/75\n",
      "10000/10000 [==============================] - 32s - loss: 2.7707 - categorical_accuracy: 0.2020 - val_loss: 2.7949 - val_categorical_accuracy: 0.2012\n",
      "4\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 76/80\n",
      "10000/10000 [==============================] - 32s - loss: 2.7903 - categorical_accuracy: 0.1994 - val_loss: 2.7948 - val_categorical_accuracy: 0.2005\n",
      "Epoch 77/80\n",
      "10000/10000 [==============================] - 32s - loss: 2.7764 - categorical_accuracy: 0.2017 - val_loss: 2.7892 - val_categorical_accuracy: 0.2016\n",
      "Epoch 78/80\n",
      "10000/10000 [==============================] - 32s - loss: 2.7694 - categorical_accuracy: 0.2031 - val_loss: 2.7890 - val_categorical_accuracy: 0.2014\n",
      "Epoch 79/80\n",
      "10000/10000 [==============================] - 32s - loss: 2.7646 - categorical_accuracy: 0.2040 - val_loss: 2.7836 - val_categorical_accuracy: 0.2024\n",
      "Epoch 80/80\n",
      "10000/10000 [==============================] - 32s - loss: 2.7596 - categorical_accuracy: 0.2050 - val_loss: 2.7851 - val_categorical_accuracy: 0.2022\n",
      "5\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 81/85\n",
      "10000/10000 [==============================] - 32s - loss: 2.7796 - categorical_accuracy: 0.2013 - val_loss: 2.7828 - val_categorical_accuracy: 0.2025\n",
      "Epoch 82/85\n",
      "10000/10000 [==============================] - 32s - loss: 2.7665 - categorical_accuracy: 0.2040 - val_loss: 2.7778 - val_categorical_accuracy: 0.2033\n",
      "Epoch 83/85\n",
      "10000/10000 [==============================] - 32s - loss: 2.7599 - categorical_accuracy: 0.2055 - val_loss: 2.7771 - val_categorical_accuracy: 0.2042\n",
      "Epoch 84/85\n",
      "10000/10000 [==============================] - 32s - loss: 2.7544 - categorical_accuracy: 0.2066 - val_loss: 2.7722 - val_categorical_accuracy: 0.2054\n",
      "Epoch 85/85\n",
      "10000/10000 [==============================] - 32s - loss: 2.7504 - categorical_accuracy: 0.2080 - val_loss: 2.7719 - val_categorical_accuracy: 0.2057\n",
      "6\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 86/90\n",
      "10000/10000 [==============================] - 32s - loss: 2.7655 - categorical_accuracy: 0.2058 - val_loss: 2.7710 - val_categorical_accuracy: 0.2063\n",
      "Epoch 87/90\n",
      "10000/10000 [==============================] - 32s - loss: 2.7526 - categorical_accuracy: 0.2084 - val_loss: 2.7685 - val_categorical_accuracy: 0.2069\n",
      "Epoch 88/90\n",
      "10000/10000 [==============================] - 32s - loss: 2.7440 - categorical_accuracy: 0.2108 - val_loss: 2.7641 - val_categorical_accuracy: 0.2075\n",
      "Epoch 89/90\n",
      "10000/10000 [==============================] - 32s - loss: 2.7380 - categorical_accuracy: 0.2126 - val_loss: 2.7678 - val_categorical_accuracy: 0.2083\n",
      "Epoch 90/90\n",
      "10000/10000 [==============================] - 32s - loss: 2.7339 - categorical_accuracy: 0.2139 - val_loss: 2.7629 - val_categorical_accuracy: 0.2086\n",
      "7\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 91/95\n",
      "10000/10000 [==============================] - 32s - loss: 2.7518 - categorical_accuracy: 0.2108 - val_loss: 2.7551 - val_categorical_accuracy: 0.2109\n",
      "Epoch 92/95\n",
      "10000/10000 [==============================] - 32s - loss: 2.7372 - categorical_accuracy: 0.2147 - val_loss: 2.7502 - val_categorical_accuracy: 0.2135\n",
      "Epoch 93/95\n",
      "10000/10000 [==============================] - 32s - loss: 2.7271 - categorical_accuracy: 0.2173 - val_loss: 2.7443 - val_categorical_accuracy: 0.2154\n",
      "Epoch 94/95\n",
      "10000/10000 [==============================] - 32s - loss: 2.7196 - categorical_accuracy: 0.2199 - val_loss: 2.7454 - val_categorical_accuracy: 0.2156\n",
      "Epoch 95/95\n",
      "10000/10000 [==============================] - 32s - loss: 2.7131 - categorical_accuracy: 0.2220 - val_loss: 2.7434 - val_categorical_accuracy: 0.2169\n",
      "8\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 32s - loss: 2.7321 - categorical_accuracy: 0.2192 - val_loss: 2.7379 - val_categorical_accuracy: 0.2196\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 32s - loss: 2.7155 - categorical_accuracy: 0.2236 - val_loss: 2.7377 - val_categorical_accuracy: 0.2196\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 32s - loss: 2.7058 - categorical_accuracy: 0.2265 - val_loss: 2.7280 - val_categorical_accuracy: 0.2225\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 32s - loss: 2.6974 - categorical_accuracy: 0.2288 - val_loss: 2.7251 - val_categorical_accuracy: 0.2235\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 32s - loss: 2.6901 - categorical_accuracy: 0.2306 - val_loss: 2.7206 - val_categorical_accuracy: 0.2263\n",
      "9\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 101/105\n",
      "10000/10000 [==============================] - 32s - loss: 2.7068 - categorical_accuracy: 0.2280 - val_loss: 2.7091 - val_categorical_accuracy: 0.2281\n",
      "Epoch 102/105\n",
      "10000/10000 [==============================] - 32s - loss: 2.6906 - categorical_accuracy: 0.2319 - val_loss: 2.7046 - val_categorical_accuracy: 0.2295\n",
      "Epoch 103/105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 31s - loss: 2.6795 - categorical_accuracy: 0.2346 - val_loss: 2.7012 - val_categorical_accuracy: 0.2309\n",
      "Epoch 104/105\n",
      "10000/10000 [==============================] - 31s - loss: 2.6710 - categorical_accuracy: 0.2370 - val_loss: 2.6993 - val_categorical_accuracy: 0.2313\n",
      "Epoch 105/105\n",
      "10000/10000 [==============================] - 31s - loss: 2.6660 - categorical_accuracy: 0.2383 - val_loss: 2.6996 - val_categorical_accuracy: 0.2309\n",
      "10\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 106/110\n",
      "10000/10000 [==============================] - 31s - loss: 2.6862 - categorical_accuracy: 0.2341 - val_loss: 2.7015 - val_categorical_accuracy: 0.2309\n",
      "Epoch 107/110\n",
      "10000/10000 [==============================] - 31s - loss: 2.6712 - categorical_accuracy: 0.2376 - val_loss: 2.6933 - val_categorical_accuracy: 0.2338\n",
      "Epoch 108/110\n",
      "10000/10000 [==============================] - 32s - loss: 2.6632 - categorical_accuracy: 0.2393 - val_loss: 2.6900 - val_categorical_accuracy: 0.2345\n",
      "Epoch 109/110\n",
      "10000/10000 [==============================] - 32s - loss: 2.6565 - categorical_accuracy: 0.2409 - val_loss: 2.6971 - val_categorical_accuracy: 0.2336\n",
      "Epoch 110/110\n",
      "10000/10000 [==============================] - 32s - loss: 2.6506 - categorical_accuracy: 0.2424 - val_loss: 2.6892 - val_categorical_accuracy: 0.2350\n",
      "11\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 111/115\n",
      "10000/10000 [==============================] - 33s - loss: 2.6756 - categorical_accuracy: 0.2380 - val_loss: 2.6806 - val_categorical_accuracy: 0.2383\n",
      "Epoch 112/115\n",
      "10000/10000 [==============================] - 32s - loss: 2.6592 - categorical_accuracy: 0.2419 - val_loss: 2.6802 - val_categorical_accuracy: 0.2380\n",
      "Epoch 113/115\n",
      "10000/10000 [==============================] - 32s - loss: 2.6523 - categorical_accuracy: 0.2434 - val_loss: 2.6769 - val_categorical_accuracy: 0.2393\n",
      "Epoch 114/115\n",
      "10000/10000 [==============================] - 32s - loss: 2.6455 - categorical_accuracy: 0.2451 - val_loss: 2.6829 - val_categorical_accuracy: 0.2384\n",
      "Epoch 115/115\n",
      "10000/10000 [==============================] - 32s - loss: 2.6395 - categorical_accuracy: 0.2468 - val_loss: 2.6812 - val_categorical_accuracy: 0.2387\n",
      "12\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 32s - loss: 2.6608 - categorical_accuracy: 0.2421 - val_loss: 2.6614 - val_categorical_accuracy: 0.2423\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 32s - loss: 2.6452 - categorical_accuracy: 0.2457 - val_loss: 2.6558 - val_categorical_accuracy: 0.2433\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 32s - loss: 2.6370 - categorical_accuracy: 0.2477 - val_loss: 2.6567 - val_categorical_accuracy: 0.2441\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 32s - loss: 2.6304 - categorical_accuracy: 0.2493 - val_loss: 2.6552 - val_categorical_accuracy: 0.2447\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 32s - loss: 2.6247 - categorical_accuracy: 0.2507 - val_loss: 2.6560 - val_categorical_accuracy: 0.2448\n",
      "13\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 121/125\n",
      "10000/10000 [==============================] - 32s - loss: 2.6499 - categorical_accuracy: 0.2460 - val_loss: 2.6550 - val_categorical_accuracy: 0.2461\n",
      "Epoch 122/125\n",
      "10000/10000 [==============================] - 32s - loss: 2.6336 - categorical_accuracy: 0.2498 - val_loss: 2.6555 - val_categorical_accuracy: 0.2454\n",
      "Epoch 123/125\n",
      "10000/10000 [==============================] - 32s - loss: 2.6246 - categorical_accuracy: 0.2520 - val_loss: 2.6550 - val_categorical_accuracy: 0.2455\n",
      "Epoch 124/125\n",
      "10000/10000 [==============================] - 32s - loss: 2.6182 - categorical_accuracy: 0.2537 - val_loss: 2.6489 - val_categorical_accuracy: 0.2483\n",
      "Epoch 125/125\n",
      "10000/10000 [==============================] - 32s - loss: 2.6121 - categorical_accuracy: 0.2551 - val_loss: 2.6511 - val_categorical_accuracy: 0.2470\n",
      "14\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 126/130\n",
      "10000/10000 [==============================] - 32s - loss: 2.6347 - categorical_accuracy: 0.2506 - val_loss: 2.6395 - val_categorical_accuracy: 0.2515\n",
      "Epoch 127/130\n",
      "10000/10000 [==============================] - 32s - loss: 2.6164 - categorical_accuracy: 0.2549 - val_loss: 2.6394 - val_categorical_accuracy: 0.2505\n",
      "Epoch 128/130\n",
      "10000/10000 [==============================] - 32s - loss: 2.6068 - categorical_accuracy: 0.2572 - val_loss: 2.6277 - val_categorical_accuracy: 0.2546\n",
      "Epoch 129/130\n",
      "10000/10000 [==============================] - 32s - loss: 2.5997 - categorical_accuracy: 0.2589 - val_loss: 2.6346 - val_categorical_accuracy: 0.2533\n",
      "Epoch 130/130\n",
      "10000/10000 [==============================] - 32s - loss: 2.5931 - categorical_accuracy: 0.2607 - val_loss: 2.6326 - val_categorical_accuracy: 0.2544\n",
      "15\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 131/135\n",
      "10000/10000 [==============================] - 32s - loss: 2.6181 - categorical_accuracy: 0.2556 - val_loss: 2.6222 - val_categorical_accuracy: 0.2569\n",
      "Epoch 132/135\n",
      "10000/10000 [==============================] - 32s - loss: 2.6005 - categorical_accuracy: 0.2597 - val_loss: 2.6180 - val_categorical_accuracy: 0.2570\n",
      "Epoch 133/135\n",
      "10000/10000 [==============================] - 32s - loss: 2.5923 - categorical_accuracy: 0.2615 - val_loss: 2.6186 - val_categorical_accuracy: 0.2560\n",
      "Epoch 134/135\n",
      "10000/10000 [==============================] - 32s - loss: 2.5836 - categorical_accuracy: 0.2634 - val_loss: 2.6160 - val_categorical_accuracy: 0.2584\n",
      "Epoch 135/135\n",
      "10000/10000 [==============================] - 32s - loss: 2.5777 - categorical_accuracy: 0.2647 - val_loss: 2.6215 - val_categorical_accuracy: 0.2562\n",
      "16\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 136/140\n",
      "10000/10000 [==============================] - 32s - loss: 2.6033 - categorical_accuracy: 0.2596 - val_loss: 2.6085 - val_categorical_accuracy: 0.2595\n",
      "Epoch 137/140\n",
      "10000/10000 [==============================] - 32s - loss: 2.5869 - categorical_accuracy: 0.2635 - val_loss: 2.6045 - val_categorical_accuracy: 0.2605\n",
      "Epoch 138/140\n",
      "10000/10000 [==============================] - 32s - loss: 2.5757 - categorical_accuracy: 0.2658 - val_loss: 2.6004 - val_categorical_accuracy: 0.2620\n",
      "Epoch 139/140\n",
      "10000/10000 [==============================] - 32s - loss: 2.5697 - categorical_accuracy: 0.2672 - val_loss: 2.5979 - val_categorical_accuracy: 0.2613\n",
      "Epoch 140/140\n",
      "10000/10000 [==============================] - 32s - loss: 2.5623 - categorical_accuracy: 0.2688 - val_loss: 2.5992 - val_categorical_accuracy: 0.2615\n",
      "17\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 141/145\n",
      "10000/10000 [==============================] - 32s - loss: 2.5847 - categorical_accuracy: 0.2645 - val_loss: 2.5917 - val_categorical_accuracy: 0.2621\n",
      "Epoch 142/145\n",
      "10000/10000 [==============================] - 32s - loss: 2.5662 - categorical_accuracy: 0.2685 - val_loss: 2.5926 - val_categorical_accuracy: 0.2632\n",
      "Epoch 143/145\n",
      "10000/10000 [==============================] - 32s - loss: 2.5574 - categorical_accuracy: 0.2703 - val_loss: 2.5799 - val_categorical_accuracy: 0.2655\n",
      "Epoch 144/145\n",
      "10000/10000 [==============================] - 32s - loss: 2.5490 - categorical_accuracy: 0.2721 - val_loss: 2.5757 - val_categorical_accuracy: 0.2654\n",
      "Epoch 145/145\n",
      "10000/10000 [==============================] - 32s - loss: 2.5435 - categorical_accuracy: 0.2730 - val_loss: 2.5804 - val_categorical_accuracy: 0.2644\n",
      "18\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 146/150\n",
      "10000/10000 [==============================] - 32s - loss: 2.5666 - categorical_accuracy: 0.2683 - val_loss: 2.5830 - val_categorical_accuracy: 0.2635\n",
      "Epoch 147/150\n",
      "10000/10000 [==============================] - 32s - loss: 2.5480 - categorical_accuracy: 0.2720 - val_loss: 2.5733 - val_categorical_accuracy: 0.2658\n",
      "Epoch 148/150\n",
      "10000/10000 [==============================] - 32s - loss: 2.5365 - categorical_accuracy: 0.2744 - val_loss: 2.5730 - val_categorical_accuracy: 0.2659\n",
      "Epoch 149/150\n",
      "10000/10000 [==============================] - 32s - loss: 2.5265 - categorical_accuracy: 0.2766 - val_loss: 2.5636 - val_categorical_accuracy: 0.2678\n",
      "Epoch 150/150\n",
      "10000/10000 [==============================] - 31s - loss: 2.5197 - categorical_accuracy: 0.2774 - val_loss: 2.5735 - val_categorical_accuracy: 0.2668\n",
      "19\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 151/155\n",
      "10000/10000 [==============================] - 31s - loss: 2.5374 - categorical_accuracy: 0.2735 - val_loss: 2.5450 - val_categorical_accuracy: 0.2722\n",
      "Epoch 152/155\n",
      "10000/10000 [==============================] - 31s - loss: 2.5196 - categorical_accuracy: 0.2769 - val_loss: 2.5438 - val_categorical_accuracy: 0.2720\n",
      "Epoch 153/155\n",
      "10000/10000 [==============================] - 31s - loss: 2.5113 - categorical_accuracy: 0.2789 - val_loss: 2.5444 - val_categorical_accuracy: 0.2720\n",
      "Epoch 154/155\n",
      "10000/10000 [==============================] - 31s - loss: 2.5009 - categorical_accuracy: 0.2809 - val_loss: 2.5421 - val_categorical_accuracy: 0.2725\n",
      "Epoch 155/155\n",
      "10000/10000 [==============================] - 31s - loss: 2.4937 - categorical_accuracy: 0.2821 - val_loss: 2.5364 - val_categorical_accuracy: 0.2731\n",
      "20\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 156/160\n",
      "10000/10000 [==============================] - 31s - loss: 2.5200 - categorical_accuracy: 0.2774 - val_loss: 2.5390 - val_categorical_accuracy: 0.2722\n",
      "Epoch 157/160\n",
      "10000/10000 [==============================] - 31s - loss: 2.5005 - categorical_accuracy: 0.2813 - val_loss: 2.5268 - val_categorical_accuracy: 0.2742\n",
      "Epoch 158/160\n",
      "10000/10000 [==============================] - 31s - loss: 2.4947 - categorical_accuracy: 0.2824 - val_loss: 2.5292 - val_categorical_accuracy: 0.2740\n",
      "Epoch 159/160\n",
      "10000/10000 [==============================] - 31s - loss: 2.4831 - categorical_accuracy: 0.2848 - val_loss: 2.5207 - val_categorical_accuracy: 0.2746\n",
      "Epoch 160/160\n",
      "10000/10000 [==============================] - 31s - loss: 2.4787 - categorical_accuracy: 0.2856 - val_loss: 2.5212 - val_categorical_accuracy: 0.2753\n",
      "21\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 161/165\n",
      "10000/10000 [==============================] - 31s - loss: 2.5029 - categorical_accuracy: 0.2800 - val_loss: 2.5156 - val_categorical_accuracy: 0.2763\n",
      "Epoch 162/165\n",
      "10000/10000 [==============================] - 31s - loss: 2.4868 - categorical_accuracy: 0.2833 - val_loss: 2.5107 - val_categorical_accuracy: 0.2771\n",
      "Epoch 163/165\n",
      "10000/10000 [==============================] - 31s - loss: 2.4780 - categorical_accuracy: 0.2852 - val_loss: 2.5009 - val_categorical_accuracy: 0.2803\n",
      "Epoch 164/165\n",
      "10000/10000 [==============================] - 31s - loss: 2.4703 - categorical_accuracy: 0.2866 - val_loss: 2.5024 - val_categorical_accuracy: 0.2800\n",
      "Epoch 165/165\n",
      "10000/10000 [==============================] - 31s - loss: 2.4637 - categorical_accuracy: 0.2882 - val_loss: 2.5190 - val_categorical_accuracy: 0.2756\n",
      "22\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 166/170\n",
      "10000/10000 [==============================] - 31s - loss: 2.4884 - categorical_accuracy: 0.2836 - val_loss: 2.4968 - val_categorical_accuracy: 0.2795\n",
      "Epoch 167/170\n",
      "10000/10000 [==============================] - 31s - loss: 2.4705 - categorical_accuracy: 0.2873 - val_loss: 2.4959 - val_categorical_accuracy: 0.2798\n",
      "Epoch 168/170\n",
      "10000/10000 [==============================] - 31s - loss: 2.4639 - categorical_accuracy: 0.2888 - val_loss: 2.4979 - val_categorical_accuracy: 0.2803\n",
      "Epoch 169/170\n",
      "10000/10000 [==============================] - 31s - loss: 2.4589 - categorical_accuracy: 0.2900 - val_loss: 2.4942 - val_categorical_accuracy: 0.2808\n",
      "Epoch 170/170\n",
      "10000/10000 [==============================] - 31s - loss: 2.4515 - categorical_accuracy: 0.2913 - val_loss: 2.4950 - val_categorical_accuracy: 0.2809\n",
      "23\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 171/175\n",
      "10000/10000 [==============================] - 31s - loss: 2.4772 - categorical_accuracy: 0.2860 - val_loss: 2.4859 - val_categorical_accuracy: 0.2834\n",
      "Epoch 172/175\n",
      "10000/10000 [==============================] - 31s - loss: 2.4599 - categorical_accuracy: 0.2897 - val_loss: 2.4839 - val_categorical_accuracy: 0.2840\n",
      "Epoch 173/175\n",
      "10000/10000 [==============================] - 31s - loss: 2.4552 - categorical_accuracy: 0.2905 - val_loss: 2.4741 - val_categorical_accuracy: 0.2859\n",
      "Epoch 174/175\n",
      "10000/10000 [==============================] - 31s - loss: 2.4460 - categorical_accuracy: 0.2924 - val_loss: 2.4789 - val_categorical_accuracy: 0.2846\n",
      "Epoch 175/175\n",
      "10000/10000 [==============================] - 31s - loss: 2.4420 - categorical_accuracy: 0.2935 - val_loss: 2.4860 - val_categorical_accuracy: 0.2859\n",
      "24\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 176/180\n",
      "10000/10000 [==============================] - 31s - loss: 2.4611 - categorical_accuracy: 0.2897 - val_loss: 2.4784 - val_categorical_accuracy: 0.2848\n",
      "Epoch 177/180\n",
      "10000/10000 [==============================] - 31s - loss: 2.4450 - categorical_accuracy: 0.2932 - val_loss: 2.4607 - val_categorical_accuracy: 0.2884\n",
      "Epoch 178/180\n",
      "10000/10000 [==============================] - 31s - loss: 2.4402 - categorical_accuracy: 0.2941 - val_loss: 2.4702 - val_categorical_accuracy: 0.2871\n",
      "Epoch 179/180\n",
      "10000/10000 [==============================] - 31s - loss: 2.4349 - categorical_accuracy: 0.2953 - val_loss: 2.4630 - val_categorical_accuracy: 0.2890\n",
      "Epoch 180/180\n",
      "10000/10000 [==============================] - 31s - loss: 2.4275 - categorical_accuracy: 0.2971 - val_loss: 2.4638 - val_categorical_accuracy: 0.2889\n",
      "25\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 181/185\n",
      "10000/10000 [==============================] - 31s - loss: 2.4545 - categorical_accuracy: 0.2910 - val_loss: 2.4851 - val_categorical_accuracy: 0.2843\n",
      "Epoch 182/185\n",
      "10000/10000 [==============================] - 31s - loss: 2.4403 - categorical_accuracy: 0.2937 - val_loss: 2.4744 - val_categorical_accuracy: 0.2872\n",
      "Epoch 183/185\n",
      "10000/10000 [==============================] - 31s - loss: 2.4324 - categorical_accuracy: 0.2958 - val_loss: 2.4695 - val_categorical_accuracy: 0.2880\n",
      "Epoch 184/185\n",
      "10000/10000 [==============================] - 31s - loss: 2.4263 - categorical_accuracy: 0.2970 - val_loss: 2.4720 - val_categorical_accuracy: 0.2877\n",
      "Epoch 185/185\n",
      "10000/10000 [==============================] - 31s - loss: 2.4237 - categorical_accuracy: 0.2975 - val_loss: 2.4721 - val_categorical_accuracy: 0.2872\n",
      "26\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 186/190\n",
      "10000/10000 [==============================] - 31s - loss: 2.4481 - categorical_accuracy: 0.2925 - val_loss: 2.4658 - val_categorical_accuracy: 0.2873\n",
      "Epoch 187/190\n",
      "10000/10000 [==============================] - 31s - loss: 2.4311 - categorical_accuracy: 0.2963 - val_loss: 2.4472 - val_categorical_accuracy: 0.2924\n",
      "Epoch 188/190\n",
      "10000/10000 [==============================] - 31s - loss: 2.4252 - categorical_accuracy: 0.2976 - val_loss: 2.4368 - val_categorical_accuracy: 0.2944\n",
      "Epoch 189/190\n",
      "10000/10000 [==============================] - 31s - loss: 2.4231 - categorical_accuracy: 0.2978 - val_loss: 2.4481 - val_categorical_accuracy: 0.2915\n",
      "Epoch 190/190\n",
      "10000/10000 [==============================] - 31s - loss: 2.4162 - categorical_accuracy: 0.2995 - val_loss: 2.4404 - val_categorical_accuracy: 0.2935\n",
      "27\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 191/195\n",
      "10000/10000 [==============================] - 31s - loss: 2.4350 - categorical_accuracy: 0.2953 - val_loss: 2.4431 - val_categorical_accuracy: 0.2941\n",
      "Epoch 192/195\n",
      "10000/10000 [==============================] - 31s - loss: 2.4235 - categorical_accuracy: 0.2975 - val_loss: 2.4558 - val_categorical_accuracy: 0.2913\n",
      "Epoch 193/195\n",
      "10000/10000 [==============================] - 31s - loss: 2.4152 - categorical_accuracy: 0.2994 - val_loss: 2.4526 - val_categorical_accuracy: 0.2911\n",
      "Epoch 194/195\n",
      "10000/10000 [==============================] - 31s - loss: 2.4093 - categorical_accuracy: 0.3008 - val_loss: 2.4475 - val_categorical_accuracy: 0.2924\n",
      "Epoch 195/195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 31s - loss: 2.4061 - categorical_accuracy: 0.3013 - val_loss: 2.4456 - val_categorical_accuracy: 0.2931\n",
      "28\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 196/200\n",
      "10000/10000 [==============================] - 31s - loss: 2.4323 - categorical_accuracy: 0.2960 - val_loss: 2.4420 - val_categorical_accuracy: 0.2929\n",
      "Epoch 197/200\n",
      "10000/10000 [==============================] - 31s - loss: 2.4142 - categorical_accuracy: 0.2996 - val_loss: 2.4513 - val_categorical_accuracy: 0.2919\n",
      "Epoch 198/200\n",
      "10000/10000 [==============================] - 31s - loss: 2.4087 - categorical_accuracy: 0.3009 - val_loss: 2.4452 - val_categorical_accuracy: 0.2935\n",
      "Epoch 199/200\n",
      "10000/10000 [==============================] - 31s - loss: 2.4045 - categorical_accuracy: 0.3019 - val_loss: 2.4497 - val_categorical_accuracy: 0.2929\n",
      "Epoch 200/200\n",
      "10000/10000 [==============================] - 31s - loss: 2.3977 - categorical_accuracy: 0.3034 - val_loss: 2.4481 - val_categorical_accuracy: 0.2913\n",
      "29\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 201/205\n",
      "10000/10000 [==============================] - 31s - loss: 2.4288 - categorical_accuracy: 0.2969 - val_loss: 2.4455 - val_categorical_accuracy: 0.2937\n",
      "Epoch 202/205\n",
      "10000/10000 [==============================] - 31s - loss: 2.4103 - categorical_accuracy: 0.3011 - val_loss: 2.4257 - val_categorical_accuracy: 0.2974\n",
      "Epoch 203/205\n",
      "10000/10000 [==============================] - 31s - loss: 2.4071 - categorical_accuracy: 0.3015 - val_loss: 2.4290 - val_categorical_accuracy: 0.2969\n",
      "Epoch 204/205\n",
      "10000/10000 [==============================] - 31s - loss: 2.4020 - categorical_accuracy: 0.3026 - val_loss: 2.4461 - val_categorical_accuracy: 0.2935\n",
      "Epoch 205/205\n",
      "10000/10000 [==============================] - 31s - loss: 2.3970 - categorical_accuracy: 0.3037 - val_loss: 2.4263 - val_categorical_accuracy: 0.2982\n",
      "30\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 206/210\n",
      "10000/10000 [==============================] - 31s - loss: 2.4196 - categorical_accuracy: 0.2991 - val_loss: 2.4404 - val_categorical_accuracy: 0.2951\n",
      "Epoch 207/210\n",
      "10000/10000 [==============================] - 31s - loss: 2.4050 - categorical_accuracy: 0.3023 - val_loss: 2.4378 - val_categorical_accuracy: 0.2953\n",
      "Epoch 208/210\n",
      "10000/10000 [==============================] - 31s - loss: 2.3985 - categorical_accuracy: 0.3038 - val_loss: 2.4367 - val_categorical_accuracy: 0.2954\n",
      "Epoch 209/210\n",
      "10000/10000 [==============================] - 31s - loss: 2.3951 - categorical_accuracy: 0.3047 - val_loss: 2.4246 - val_categorical_accuracy: 0.2984\n",
      "Epoch 210/210\n",
      "10000/10000 [==============================] - 31s - loss: 2.3911 - categorical_accuracy: 0.3054 - val_loss: 2.4297 - val_categorical_accuracy: 0.2975\n",
      "31\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 211/215\n",
      "10000/10000 [==============================] - 31s - loss: 2.4112 - categorical_accuracy: 0.3016 - val_loss: 2.4309 - val_categorical_accuracy: 0.2968\n",
      "Epoch 212/215\n",
      "10000/10000 [==============================] - 31s - loss: 2.3980 - categorical_accuracy: 0.3045 - val_loss: 2.4396 - val_categorical_accuracy: 0.2964\n",
      "Epoch 213/215\n",
      "10000/10000 [==============================] - 31s - loss: 2.3939 - categorical_accuracy: 0.3049 - val_loss: 2.4319 - val_categorical_accuracy: 0.2980\n",
      "Epoch 214/215\n",
      "10000/10000 [==============================] - 31s - loss: 2.3879 - categorical_accuracy: 0.3066 - val_loss: 2.4292 - val_categorical_accuracy: 0.2973\n",
      "Epoch 215/215\n",
      "10000/10000 [==============================] - 31s - loss: 2.3856 - categorical_accuracy: 0.3070 - val_loss: 2.4342 - val_categorical_accuracy: 0.2970\n",
      "32\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 216/220\n",
      "10000/10000 [==============================] - 31s - loss: 2.4112 - categorical_accuracy: 0.3014 - val_loss: 2.4205 - val_categorical_accuracy: 0.2993\n",
      "Epoch 217/220\n",
      "10000/10000 [==============================] - 31s - loss: 2.3945 - categorical_accuracy: 0.3050 - val_loss: 2.4321 - val_categorical_accuracy: 0.2962\n",
      "Epoch 218/220\n",
      "10000/10000 [==============================] - 31s - loss: 2.3902 - categorical_accuracy: 0.3059 - val_loss: 2.4294 - val_categorical_accuracy: 0.2972\n",
      "Epoch 219/220\n",
      "10000/10000 [==============================] - 31s - loss: 2.3846 - categorical_accuracy: 0.3072 - val_loss: 2.4219 - val_categorical_accuracy: 0.2988\n",
      "Epoch 220/220\n",
      "10000/10000 [==============================] - 31s - loss: 2.3807 - categorical_accuracy: 0.3081 - val_loss: 2.4069 - val_categorical_accuracy: 0.3035\n",
      "33\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 221/225\n",
      "10000/10000 [==============================] - 31s - loss: 2.4022 - categorical_accuracy: 0.3038 - val_loss: 2.4277 - val_categorical_accuracy: 0.2969\n",
      "Epoch 222/225\n",
      "10000/10000 [==============================] - 31s - loss: 2.3894 - categorical_accuracy: 0.3064 - val_loss: 2.4109 - val_categorical_accuracy: 0.3015\n",
      "Epoch 223/225\n",
      "10000/10000 [==============================] - 31s - loss: 2.3843 - categorical_accuracy: 0.3071 - val_loss: 2.4195 - val_categorical_accuracy: 0.2993\n",
      "Epoch 224/225\n",
      "10000/10000 [==============================] - 31s - loss: 2.3757 - categorical_accuracy: 0.3093 - val_loss: 2.4192 - val_categorical_accuracy: 0.2998\n",
      "Epoch 225/225\n",
      "10000/10000 [==============================] - 31s - loss: 2.3745 - categorical_accuracy: 0.3093 - val_loss: 2.4187 - val_categorical_accuracy: 0.2999\n",
      "34\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 226/230\n",
      "10000/10000 [==============================] - 31s - loss: 2.3959 - categorical_accuracy: 0.3048 - val_loss: 2.4099 - val_categorical_accuracy: 0.3033\n",
      "Epoch 227/230\n",
      "10000/10000 [==============================] - 31s - loss: 2.3869 - categorical_accuracy: 0.3067 - val_loss: 2.4058 - val_categorical_accuracy: 0.3039\n",
      "Epoch 228/230\n",
      "10000/10000 [==============================] - 31s - loss: 2.3797 - categorical_accuracy: 0.3084 - val_loss: 2.4034 - val_categorical_accuracy: 0.3044\n",
      "Epoch 229/230\n",
      "10000/10000 [==============================] - 31s - loss: 2.3742 - categorical_accuracy: 0.3091 - val_loss: 2.4089 - val_categorical_accuracy: 0.3031\n",
      "Epoch 230/230\n",
      "10000/10000 [==============================] - 31s - loss: 2.3715 - categorical_accuracy: 0.3100 - val_loss: 2.4198 - val_categorical_accuracy: 0.3012\n",
      "35\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 231/235\n",
      "10000/10000 [==============================] - 31s - loss: 2.3970 - categorical_accuracy: 0.3044 - val_loss: 2.4036 - val_categorical_accuracy: 0.3044\n",
      "Epoch 232/235\n",
      "10000/10000 [==============================] - 31s - loss: 2.3807 - categorical_accuracy: 0.3082 - val_loss: 2.3997 - val_categorical_accuracy: 0.3056\n",
      "Epoch 233/235\n",
      "10000/10000 [==============================] - 31s - loss: 2.3781 - categorical_accuracy: 0.3085 - val_loss: 2.4139 - val_categorical_accuracy: 0.3023\n",
      "Epoch 234/235\n",
      "10000/10000 [==============================] - 31s - loss: 2.3742 - categorical_accuracy: 0.3094 - val_loss: 2.4018 - val_categorical_accuracy: 0.3044\n",
      "Epoch 235/235\n",
      "10000/10000 [==============================] - 31s - loss: 2.3676 - categorical_accuracy: 0.3112 - val_loss: 2.4023 - val_categorical_accuracy: 0.3056\n",
      "36\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 236/240\n",
      "10000/10000 [==============================] - 31s - loss: 2.3922 - categorical_accuracy: 0.3055 - val_loss: 2.4091 - val_categorical_accuracy: 0.3017\n",
      "Epoch 237/240\n",
      "10000/10000 [==============================] - 31s - loss: 2.3793 - categorical_accuracy: 0.3085 - val_loss: 2.4081 - val_categorical_accuracy: 0.3015\n",
      "Epoch 238/240\n",
      "10000/10000 [==============================] - 31s - loss: 2.3729 - categorical_accuracy: 0.3099 - val_loss: 2.4027 - val_categorical_accuracy: 0.3034\n",
      "Epoch 239/240\n",
      "10000/10000 [==============================] - 31s - loss: 2.3669 - categorical_accuracy: 0.3111 - val_loss: 2.4066 - val_categorical_accuracy: 0.3019\n",
      "Epoch 240/240\n",
      "10000/10000 [==============================] - 31s - loss: 2.3639 - categorical_accuracy: 0.3116 - val_loss: 2.4070 - val_categorical_accuracy: 0.3040\n",
      "37\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 241/245\n",
      "10000/10000 [==============================] - 31s - loss: 2.3843 - categorical_accuracy: 0.3079 - val_loss: 2.3990 - val_categorical_accuracy: 0.3045\n",
      "Epoch 242/245\n",
      "10000/10000 [==============================] - 31s - loss: 2.3716 - categorical_accuracy: 0.3105 - val_loss: 2.4023 - val_categorical_accuracy: 0.3032\n",
      "Epoch 243/245\n",
      "10000/10000 [==============================] - 31s - loss: 2.3688 - categorical_accuracy: 0.3109 - val_loss: 2.3861 - val_categorical_accuracy: 0.3082\n",
      "Epoch 244/245\n",
      "10000/10000 [==============================] - 31s - loss: 2.3629 - categorical_accuracy: 0.3123 - val_loss: 2.3940 - val_categorical_accuracy: 0.3047\n",
      "Epoch 245/245\n",
      "10000/10000 [==============================] - 31s - loss: 2.3610 - categorical_accuracy: 0.3128 - val_loss: 2.4105 - val_categorical_accuracy: 0.3025\n",
      "38\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 246/250\n",
      "10000/10000 [==============================] - 31s - loss: 2.3829 - categorical_accuracy: 0.3082 - val_loss: 2.3861 - val_categorical_accuracy: 0.3076\n",
      "Epoch 247/250\n",
      "10000/10000 [==============================] - 31s - loss: 2.3680 - categorical_accuracy: 0.3115 - val_loss: 2.3896 - val_categorical_accuracy: 0.3065\n",
      "Epoch 248/250\n",
      "10000/10000 [==============================] - 31s - loss: 2.3638 - categorical_accuracy: 0.3121 - val_loss: 2.3871 - val_categorical_accuracy: 0.3061\n",
      "Epoch 249/250\n",
      "10000/10000 [==============================] - 31s - loss: 2.3568 - categorical_accuracy: 0.3135 - val_loss: 2.3827 - val_categorical_accuracy: 0.3087\n",
      "Epoch 250/250\n",
      "10000/10000 [==============================] - 31s - loss: 2.3588 - categorical_accuracy: 0.3131 - val_loss: 2.3858 - val_categorical_accuracy: 0.3075\n",
      "39\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 251/255\n",
      "10000/10000 [==============================] - 31s - loss: 2.3804 - categorical_accuracy: 0.3092 - val_loss: 2.4023 - val_categorical_accuracy: 0.3040\n",
      "Epoch 252/255\n",
      "10000/10000 [==============================] - 31s - loss: 2.3687 - categorical_accuracy: 0.3117 - val_loss: 2.3883 - val_categorical_accuracy: 0.3069\n",
      "Epoch 253/255\n",
      "10000/10000 [==============================] - 31s - loss: 2.3650 - categorical_accuracy: 0.3122 - val_loss: 2.3925 - val_categorical_accuracy: 0.3046\n",
      "Epoch 254/255\n",
      "10000/10000 [==============================] - 31s - loss: 2.3582 - categorical_accuracy: 0.3139 - val_loss: 2.3913 - val_categorical_accuracy: 0.3062\n",
      "Epoch 255/255\n",
      "10000/10000 [==============================] - 31s - loss: 2.3550 - categorical_accuracy: 0.3143 - val_loss: 2.3918 - val_categorical_accuracy: 0.3059\n",
      "40\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 256/260\n",
      "10000/10000 [==============================] - 31s - loss: 2.3761 - categorical_accuracy: 0.3094 - val_loss: 2.3749 - val_categorical_accuracy: 0.3088\n",
      "Epoch 257/260\n",
      "10000/10000 [==============================] - 31s - loss: 2.3697 - categorical_accuracy: 0.3106 - val_loss: 2.3745 - val_categorical_accuracy: 0.3096\n",
      "Epoch 258/260\n",
      "10000/10000 [==============================] - 31s - loss: 2.3557 - categorical_accuracy: 0.3141 - val_loss: 2.3763 - val_categorical_accuracy: 0.3096\n",
      "Epoch 259/260\n",
      "10000/10000 [==============================] - 31s - loss: 2.3556 - categorical_accuracy: 0.3138 - val_loss: 2.3734 - val_categorical_accuracy: 0.3099\n",
      "Epoch 260/260\n",
      "10000/10000 [==============================] - 31s - loss: 2.3511 - categorical_accuracy: 0.3147 - val_loss: 2.3786 - val_categorical_accuracy: 0.3081\n",
      "41\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 261/265\n",
      "10000/10000 [==============================] - 31s - loss: 2.3742 - categorical_accuracy: 0.3098 - val_loss: 2.3949 - val_categorical_accuracy: 0.3041\n",
      "Epoch 262/265\n",
      "10000/10000 [==============================] - 31s - loss: 2.3608 - categorical_accuracy: 0.3128 - val_loss: 2.3908 - val_categorical_accuracy: 0.3064\n",
      "Epoch 263/265\n",
      "10000/10000 [==============================] - 31s - loss: 2.3544 - categorical_accuracy: 0.3141 - val_loss: 2.3902 - val_categorical_accuracy: 0.3067\n",
      "Epoch 264/265\n",
      "10000/10000 [==============================] - 31s - loss: 2.3506 - categorical_accuracy: 0.3147 - val_loss: 2.3887 - val_categorical_accuracy: 0.3071\n",
      "Epoch 265/265\n",
      "10000/10000 [==============================] - 31s - loss: 2.3456 - categorical_accuracy: 0.3160 - val_loss: 2.3833 - val_categorical_accuracy: 0.3089\n",
      "42\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 266/270\n",
      "10000/10000 [==============================] - 31s - loss: 2.3695 - categorical_accuracy: 0.3111 - val_loss: 2.3869 - val_categorical_accuracy: 0.3070\n",
      "Epoch 267/270\n",
      "10000/10000 [==============================] - 31s - loss: 2.3573 - categorical_accuracy: 0.3134 - val_loss: 2.3916 - val_categorical_accuracy: 0.3063\n",
      "Epoch 268/270\n",
      "10000/10000 [==============================] - 31s - loss: 2.3509 - categorical_accuracy: 0.3153 - val_loss: 2.3847 - val_categorical_accuracy: 0.3083\n",
      "Epoch 269/270\n",
      "10000/10000 [==============================] - 31s - loss: 2.3491 - categorical_accuracy: 0.3153 - val_loss: 2.3798 - val_categorical_accuracy: 0.3094\n",
      "Epoch 270/270\n",
      "10000/10000 [==============================] - 31s - loss: 2.3445 - categorical_accuracy: 0.3160 - val_loss: 2.3909 - val_categorical_accuracy: 0.3060\n",
      "43\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 271/275\n",
      "10000/10000 [==============================] - 31s - loss: 2.3694 - categorical_accuracy: 0.3109 - val_loss: 2.3721 - val_categorical_accuracy: 0.3106\n",
      "Epoch 272/275\n",
      "10000/10000 [==============================] - 31s - loss: 2.3547 - categorical_accuracy: 0.3145 - val_loss: 2.3908 - val_categorical_accuracy: 0.3068\n",
      "Epoch 273/275\n",
      "10000/10000 [==============================] - 31s - loss: 2.3491 - categorical_accuracy: 0.3156 - val_loss: 2.3910 - val_categorical_accuracy: 0.3070\n",
      "Epoch 274/275\n",
      "10000/10000 [==============================] - 31s - loss: 2.3439 - categorical_accuracy: 0.3166 - val_loss: 2.3810 - val_categorical_accuracy: 0.3100\n",
      "Epoch 275/275\n",
      "10000/10000 [==============================] - 31s - loss: 2.3426 - categorical_accuracy: 0.3167 - val_loss: 2.3838 - val_categorical_accuracy: 0.3079\n",
      "44\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 276/280\n",
      "10000/10000 [==============================] - 31s - loss: 2.3628 - categorical_accuracy: 0.3123 - val_loss: 2.3833 - val_categorical_accuracy: 0.3076\n",
      "Epoch 277/280\n",
      "10000/10000 [==============================] - 31s - loss: 2.3524 - categorical_accuracy: 0.3147 - val_loss: 2.3904 - val_categorical_accuracy: 0.3071\n",
      "Epoch 278/280\n",
      "10000/10000 [==============================] - 31s - loss: 2.3464 - categorical_accuracy: 0.3158 - val_loss: 2.3763 - val_categorical_accuracy: 0.3096\n",
      "Epoch 279/280\n",
      "10000/10000 [==============================] - 31s - loss: 2.3439 - categorical_accuracy: 0.3161 - val_loss: 2.3867 - val_categorical_accuracy: 0.3081\n",
      "Epoch 280/280\n",
      "10000/10000 [==============================] - 31s - loss: 2.3389 - categorical_accuracy: 0.3175 - val_loss: 2.3749 - val_categorical_accuracy: 0.3102\n",
      "45\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 281/285\n",
      "10000/10000 [==============================] - 31s - loss: 2.3615 - categorical_accuracy: 0.3130 - val_loss: 2.3799 - val_categorical_accuracy: 0.3089\n",
      "Epoch 282/285\n",
      "10000/10000 [==============================] - 31s - loss: 2.3497 - categorical_accuracy: 0.3150 - val_loss: 2.4015 - val_categorical_accuracy: 0.3018\n",
      "Epoch 283/285\n",
      "10000/10000 [==============================] - 31s - loss: 2.3443 - categorical_accuracy: 0.3161 - val_loss: 2.3748 - val_categorical_accuracy: 0.3087\n",
      "Epoch 284/285\n",
      "10000/10000 [==============================] - 31s - loss: 2.3419 - categorical_accuracy: 0.3169 - val_loss: 2.3830 - val_categorical_accuracy: 0.3065\n",
      "Epoch 285/285\n",
      "10000/10000 [==============================] - 31s - loss: 2.3373 - categorical_accuracy: 0.3179 - val_loss: 2.3741 - val_categorical_accuracy: 0.3086\n",
      "46\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 286/290\n",
      "10000/10000 [==============================] - 31s - loss: 2.3623 - categorical_accuracy: 0.3125 - val_loss: 2.3755 - val_categorical_accuracy: 0.3085\n",
      "Epoch 287/290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 31s - loss: 2.3491 - categorical_accuracy: 0.3155 - val_loss: 2.3676 - val_categorical_accuracy: 0.3115\n",
      "Epoch 288/290\n",
      "10000/10000 [==============================] - 31s - loss: 2.3417 - categorical_accuracy: 0.3172 - val_loss: 2.3668 - val_categorical_accuracy: 0.3119\n",
      "Epoch 289/290\n",
      "10000/10000 [==============================] - 31s - loss: 2.3392 - categorical_accuracy: 0.3175 - val_loss: 2.3673 - val_categorical_accuracy: 0.3124\n",
      "Epoch 290/290\n",
      "10000/10000 [==============================] - 31s - loss: 2.3370 - categorical_accuracy: 0.3178 - val_loss: 2.3670 - val_categorical_accuracy: 0.3106\n",
      "47\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 291/295\n",
      "10000/10000 [==============================] - 31s - loss: 2.3588 - categorical_accuracy: 0.3131 - val_loss: 2.3756 - val_categorical_accuracy: 0.3093\n",
      "Epoch 292/295\n",
      "10000/10000 [==============================] - 31s - loss: 2.3417 - categorical_accuracy: 0.3168 - val_loss: 2.3676 - val_categorical_accuracy: 0.3118\n",
      "Epoch 293/295\n",
      "10000/10000 [==============================] - 31s - loss: 2.3382 - categorical_accuracy: 0.3177 - val_loss: 2.3728 - val_categorical_accuracy: 0.3101\n",
      "Epoch 294/295\n",
      "10000/10000 [==============================] - 31s - loss: 2.3365 - categorical_accuracy: 0.3180 - val_loss: 2.3832 - val_categorical_accuracy: 0.3076\n",
      "Epoch 295/295\n",
      "10000/10000 [==============================] - 31s - loss: 2.3324 - categorical_accuracy: 0.3187 - val_loss: 2.3820 - val_categorical_accuracy: 0.3079\n",
      "48\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 296/300\n",
      "10000/10000 [==============================] - 31s - loss: 2.3529 - categorical_accuracy: 0.3145 - val_loss: 2.3673 - val_categorical_accuracy: 0.3112\n",
      "Epoch 297/300\n",
      "10000/10000 [==============================] - 31s - loss: 2.3400 - categorical_accuracy: 0.3172 - val_loss: 2.3728 - val_categorical_accuracy: 0.3115\n",
      "Epoch 298/300\n",
      "10000/10000 [==============================] - 31s - loss: 2.3341 - categorical_accuracy: 0.3185 - val_loss: 2.3686 - val_categorical_accuracy: 0.3119\n",
      "Epoch 299/300\n",
      "10000/10000 [==============================] - 31s - loss: 2.3297 - categorical_accuracy: 0.3196 - val_loss: 2.3806 - val_categorical_accuracy: 0.3080\n",
      "Epoch 300/300\n",
      "10000/10000 [==============================] - 31s - loss: 2.3311 - categorical_accuracy: 0.3192 - val_loss: 2.3673 - val_categorical_accuracy: 0.3121\n",
      "49\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 301/305\n",
      "10000/10000 [==============================] - 31s - loss: 2.3523 - categorical_accuracy: 0.3144 - val_loss: 2.3628 - val_categorical_accuracy: 0.3136\n",
      "Epoch 302/305\n",
      "10000/10000 [==============================] - 31s - loss: 2.3389 - categorical_accuracy: 0.3173 - val_loss: 2.3649 - val_categorical_accuracy: 0.3128\n",
      "Epoch 303/305\n",
      "10000/10000 [==============================] - 31s - loss: 2.3317 - categorical_accuracy: 0.3190 - val_loss: 2.3536 - val_categorical_accuracy: 0.3149\n",
      "Epoch 304/305\n",
      "10000/10000 [==============================] - 31s - loss: 2.3365 - categorical_accuracy: 0.3179 - val_loss: 2.3581 - val_categorical_accuracy: 0.3141\n",
      "Epoch 305/305\n",
      "10000/10000 [==============================] - 31s - loss: 2.3262 - categorical_accuracy: 0.3202 - val_loss: 2.3802 - val_categorical_accuracy: 0.3101\n",
      "50\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 306/310\n",
      "10000/10000 [==============================] - 31s - loss: 2.3529 - categorical_accuracy: 0.3147 - val_loss: 2.3645 - val_categorical_accuracy: 0.3109\n",
      "Epoch 307/310\n",
      "10000/10000 [==============================] - 31s - loss: 2.3397 - categorical_accuracy: 0.3175 - val_loss: 2.3592 - val_categorical_accuracy: 0.3123\n",
      "Epoch 308/310\n",
      "10000/10000 [==============================] - 31s - loss: 2.3339 - categorical_accuracy: 0.3184 - val_loss: 2.3633 - val_categorical_accuracy: 0.3126\n",
      "Epoch 309/310\n",
      "10000/10000 [==============================] - 31s - loss: 2.3304 - categorical_accuracy: 0.3193 - val_loss: 2.3470 - val_categorical_accuracy: 0.3165\n",
      "Epoch 310/310\n",
      "10000/10000 [==============================] - 31s - loss: 2.3270 - categorical_accuracy: 0.3202 - val_loss: 2.3724 - val_categorical_accuracy: 0.3085\n",
      "51\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 311/315\n",
      "10000/10000 [==============================] - 31s - loss: 2.3470 - categorical_accuracy: 0.3160 - val_loss: 2.3714 - val_categorical_accuracy: 0.3100\n",
      "Epoch 312/315\n",
      "10000/10000 [==============================] - 31s - loss: 2.3304 - categorical_accuracy: 0.3194 - val_loss: 2.3644 - val_categorical_accuracy: 0.3117\n",
      "Epoch 313/315\n",
      "10000/10000 [==============================] - 31s - loss: 2.3279 - categorical_accuracy: 0.3199 - val_loss: 2.3526 - val_categorical_accuracy: 0.3158\n",
      "Epoch 314/315\n",
      "10000/10000 [==============================] - 31s - loss: 2.3255 - categorical_accuracy: 0.3205 - val_loss: 2.3648 - val_categorical_accuracy: 0.3124\n",
      "Epoch 315/315\n",
      "10000/10000 [==============================] - 31s - loss: 2.3247 - categorical_accuracy: 0.3207 - val_loss: 2.3538 - val_categorical_accuracy: 0.3140\n",
      "52\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 316/320\n",
      "10000/10000 [==============================] - 31s - loss: 2.3448 - categorical_accuracy: 0.3165 - val_loss: 2.3520 - val_categorical_accuracy: 0.3145\n",
      "Epoch 317/320\n",
      "10000/10000 [==============================] - 31s - loss: 2.3349 - categorical_accuracy: 0.3186 - val_loss: 2.3545 - val_categorical_accuracy: 0.3147\n",
      "Epoch 318/320\n",
      "10000/10000 [==============================] - 31s - loss: 2.3311 - categorical_accuracy: 0.3194 - val_loss: 2.3613 - val_categorical_accuracy: 0.3131\n",
      "Epoch 319/320\n",
      "10000/10000 [==============================] - 31s - loss: 2.3272 - categorical_accuracy: 0.3203 - val_loss: 2.3715 - val_categorical_accuracy: 0.3106\n",
      "Epoch 320/320\n",
      "10000/10000 [==============================] - 31s - loss: 2.3243 - categorical_accuracy: 0.3207 - val_loss: 2.3596 - val_categorical_accuracy: 0.3139\n",
      "53\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 321/325\n",
      "10000/10000 [==============================] - 31s - loss: 2.3446 - categorical_accuracy: 0.3166 - val_loss: 2.3610 - val_categorical_accuracy: 0.3134\n",
      "Epoch 322/325\n",
      "10000/10000 [==============================] - 31s - loss: 2.3301 - categorical_accuracy: 0.3198 - val_loss: 2.3545 - val_categorical_accuracy: 0.3148\n",
      "Epoch 323/325\n",
      "10000/10000 [==============================] - 31s - loss: 2.3266 - categorical_accuracy: 0.3206 - val_loss: 2.3615 - val_categorical_accuracy: 0.3134\n",
      "Epoch 324/325\n",
      "10000/10000 [==============================] - 31s - loss: 2.3258 - categorical_accuracy: 0.3204 - val_loss: 2.3505 - val_categorical_accuracy: 0.3161\n",
      "Epoch 325/325\n",
      "10000/10000 [==============================] - 31s - loss: 2.3202 - categorical_accuracy: 0.3219 - val_loss: 2.3562 - val_categorical_accuracy: 0.3149\n",
      "54\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 326/330\n",
      "10000/10000 [==============================] - 31s - loss: 2.3419 - categorical_accuracy: 0.3177 - val_loss: 2.3599 - val_categorical_accuracy: 0.3143\n",
      "Epoch 327/330\n",
      "10000/10000 [==============================] - 31s - loss: 2.3317 - categorical_accuracy: 0.3196 - val_loss: 2.3716 - val_categorical_accuracy: 0.3105\n",
      "Epoch 328/330\n",
      "10000/10000 [==============================] - 31s - loss: 2.3254 - categorical_accuracy: 0.3211 - val_loss: 2.3524 - val_categorical_accuracy: 0.3153\n",
      "Epoch 329/330\n",
      "10000/10000 [==============================] - 31s - loss: 2.3210 - categorical_accuracy: 0.3222 - val_loss: 2.3604 - val_categorical_accuracy: 0.3134\n",
      "Epoch 330/330\n",
      "10000/10000 [==============================] - 31s - loss: 2.3193 - categorical_accuracy: 0.3225 - val_loss: 2.3594 - val_categorical_accuracy: 0.3136\n",
      "55\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 331/335\n",
      "10000/10000 [==============================] - 31s - loss: 2.3425 - categorical_accuracy: 0.3170 - val_loss: 2.3428 - val_categorical_accuracy: 0.3160\n",
      "Epoch 332/335\n",
      "10000/10000 [==============================] - 31s - loss: 2.3283 - categorical_accuracy: 0.3203 - val_loss: 2.3487 - val_categorical_accuracy: 0.3156\n",
      "Epoch 333/335\n",
      "10000/10000 [==============================] - 31s - loss: 2.3240 - categorical_accuracy: 0.3213 - val_loss: 2.3647 - val_categorical_accuracy: 0.3116\n",
      "Epoch 334/335\n",
      "10000/10000 [==============================] - 31s - loss: 2.3240 - categorical_accuracy: 0.3211 - val_loss: 2.3450 - val_categorical_accuracy: 0.3161\n",
      "Epoch 335/335\n",
      "10000/10000 [==============================] - 31s - loss: 2.3196 - categorical_accuracy: 0.3221 - val_loss: 2.3512 - val_categorical_accuracy: 0.3146\n",
      "56\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 336/340\n",
      "10000/10000 [==============================] - 31s - loss: 2.3353 - categorical_accuracy: 0.3188 - val_loss: 2.3845 - val_categorical_accuracy: 0.3071\n",
      "Epoch 337/340\n",
      "10000/10000 [==============================] - 31s - loss: 2.3261 - categorical_accuracy: 0.3209 - val_loss: 2.3817 - val_categorical_accuracy: 0.3080\n",
      "Epoch 338/340\n",
      "10000/10000 [==============================] - 31s - loss: 2.3172 - categorical_accuracy: 0.3225 - val_loss: 2.3516 - val_categorical_accuracy: 0.3160\n",
      "Epoch 339/340\n",
      "10000/10000 [==============================] - 31s - loss: 2.3142 - categorical_accuracy: 0.3234 - val_loss: 2.3599 - val_categorical_accuracy: 0.3143\n",
      "Epoch 340/340\n",
      "10000/10000 [==============================] - 31s - loss: 2.3143 - categorical_accuracy: 0.3233 - val_loss: 2.3699 - val_categorical_accuracy: 0.3117\n",
      "57\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 341/345\n",
      "10000/10000 [==============================] - 31s - loss: 2.3378 - categorical_accuracy: 0.3181 - val_loss: 2.3568 - val_categorical_accuracy: 0.3135\n",
      "Epoch 342/345\n",
      "10000/10000 [==============================] - 31s - loss: 2.3272 - categorical_accuracy: 0.3202 - val_loss: 2.3489 - val_categorical_accuracy: 0.3162\n",
      "Epoch 343/345\n",
      "10000/10000 [==============================] - 31s - loss: 2.3166 - categorical_accuracy: 0.3232 - val_loss: 2.3387 - val_categorical_accuracy: 0.3182\n",
      "Epoch 344/345\n",
      "10000/10000 [==============================] - 31s - loss: 2.3156 - categorical_accuracy: 0.3230 - val_loss: 2.3467 - val_categorical_accuracy: 0.3168\n",
      "Epoch 345/345\n",
      "10000/10000 [==============================] - 31s - loss: 2.3131 - categorical_accuracy: 0.3235 - val_loss: 2.3486 - val_categorical_accuracy: 0.3162\n",
      "58\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 346/350\n",
      "10000/10000 [==============================] - 31s - loss: 2.3315 - categorical_accuracy: 0.3193 - val_loss: 2.3599 - val_categorical_accuracy: 0.3135\n",
      "Epoch 347/350\n",
      "10000/10000 [==============================] - 31s - loss: 2.3231 - categorical_accuracy: 0.3211 - val_loss: 2.3486 - val_categorical_accuracy: 0.3159\n",
      "Epoch 348/350\n",
      "10000/10000 [==============================] - 31s - loss: 2.3181 - categorical_accuracy: 0.3223 - val_loss: 2.3528 - val_categorical_accuracy: 0.3139\n",
      "Epoch 349/350\n",
      "10000/10000 [==============================] - 31s - loss: 2.3098 - categorical_accuracy: 0.3242 - val_loss: 2.3387 - val_categorical_accuracy: 0.3166\n",
      "Epoch 350/350\n",
      "10000/10000 [==============================] - 31s - loss: 2.3101 - categorical_accuracy: 0.3238 - val_loss: 2.3404 - val_categorical_accuracy: 0.3167\n",
      "59\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 351/355\n",
      "10000/10000 [==============================] - 31s - loss: 2.3312 - categorical_accuracy: 0.3199 - val_loss: 2.3494 - val_categorical_accuracy: 0.3163\n",
      "Epoch 352/355\n",
      "10000/10000 [==============================] - 31s - loss: 2.3174 - categorical_accuracy: 0.3228 - val_loss: 2.3413 - val_categorical_accuracy: 0.3164\n",
      "Epoch 353/355\n",
      "10000/10000 [==============================] - 31s - loss: 2.3165 - categorical_accuracy: 0.3232 - val_loss: 2.3424 - val_categorical_accuracy: 0.3172\n",
      "Epoch 354/355\n",
      "10000/10000 [==============================] - 31s - loss: 2.3102 - categorical_accuracy: 0.3244 - val_loss: 2.3547 - val_categorical_accuracy: 0.3150\n",
      "Epoch 355/355\n",
      "10000/10000 [==============================] - 31s - loss: 2.3074 - categorical_accuracy: 0.3249 - val_loss: 2.3454 - val_categorical_accuracy: 0.3178\n",
      "60\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 356/360\n",
      "10000/10000 [==============================] - 31s - loss: 2.3259 - categorical_accuracy: 0.3214 - val_loss: 2.3397 - val_categorical_accuracy: 0.3171\n",
      "Epoch 357/360\n",
      "10000/10000 [==============================] - 31s - loss: 2.3166 - categorical_accuracy: 0.3230 - val_loss: 2.3382 - val_categorical_accuracy: 0.3182\n",
      "Epoch 358/360\n",
      "10000/10000 [==============================] - 31s - loss: 2.3109 - categorical_accuracy: 0.3244 - val_loss: 2.3403 - val_categorical_accuracy: 0.3176\n",
      "Epoch 359/360\n",
      "10000/10000 [==============================] - 31s - loss: 2.3086 - categorical_accuracy: 0.3247 - val_loss: 2.3436 - val_categorical_accuracy: 0.3159\n",
      "Epoch 360/360\n",
      "10000/10000 [==============================] - 31s - loss: 2.3041 - categorical_accuracy: 0.3259 - val_loss: 2.3447 - val_categorical_accuracy: 0.3161\n",
      "61\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 361/365\n",
      "10000/10000 [==============================] - 31s - loss: 2.3292 - categorical_accuracy: 0.3198 - val_loss: 2.3295 - val_categorical_accuracy: 0.3187\n",
      "Epoch 362/365\n",
      "10000/10000 [==============================] - 31s - loss: 2.3129 - categorical_accuracy: 0.3238 - val_loss: 2.3262 - val_categorical_accuracy: 0.3198\n",
      "Epoch 363/365\n",
      "10000/10000 [==============================] - 31s - loss: 2.3108 - categorical_accuracy: 0.3240 - val_loss: 2.3287 - val_categorical_accuracy: 0.3193\n",
      "Epoch 364/365\n",
      "10000/10000 [==============================] - 31s - loss: 2.3053 - categorical_accuracy: 0.3249 - val_loss: 2.3368 - val_categorical_accuracy: 0.3189\n",
      "Epoch 365/365\n",
      "10000/10000 [==============================] - 31s - loss: 2.3063 - categorical_accuracy: 0.3247 - val_loss: 2.3423 - val_categorical_accuracy: 0.3175\n",
      "62\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 366/370\n",
      "10000/10000 [==============================] - 31s - loss: 2.3238 - categorical_accuracy: 0.3212 - val_loss: 2.3264 - val_categorical_accuracy: 0.3210\n",
      "Epoch 367/370\n",
      "10000/10000 [==============================] - 31s - loss: 2.3134 - categorical_accuracy: 0.3236 - val_loss: 2.3299 - val_categorical_accuracy: 0.3199\n",
      "Epoch 368/370\n",
      "10000/10000 [==============================] - 31s - loss: 2.3060 - categorical_accuracy: 0.3252 - val_loss: 2.3287 - val_categorical_accuracy: 0.3214\n",
      "Epoch 369/370\n",
      "10000/10000 [==============================] - 31s - loss: 2.3022 - categorical_accuracy: 0.3260 - val_loss: 2.3267 - val_categorical_accuracy: 0.3216\n",
      "Epoch 370/370\n",
      "10000/10000 [==============================] - 31s - loss: 2.2997 - categorical_accuracy: 0.3267 - val_loss: 2.3270 - val_categorical_accuracy: 0.3210\n",
      "63\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 371/375\n",
      "10000/10000 [==============================] - 31s - loss: 2.3257 - categorical_accuracy: 0.3217 - val_loss: 2.3344 - val_categorical_accuracy: 0.3175\n",
      "Epoch 372/375\n",
      "10000/10000 [==============================] - 31s - loss: 2.3136 - categorical_accuracy: 0.3239 - val_loss: 2.3241 - val_categorical_accuracy: 0.3197\n",
      "Epoch 373/375\n",
      "10000/10000 [==============================] - 31s - loss: 2.3093 - categorical_accuracy: 0.3250 - val_loss: 2.3176 - val_categorical_accuracy: 0.3219\n",
      "Epoch 374/375\n",
      "10000/10000 [==============================] - 31s - loss: 2.3033 - categorical_accuracy: 0.3261 - val_loss: 2.3305 - val_categorical_accuracy: 0.3189\n",
      "Epoch 375/375\n",
      "10000/10000 [==============================] - 31s - loss: 2.3052 - categorical_accuracy: 0.3257 - val_loss: 2.3287 - val_categorical_accuracy: 0.3193\n",
      "64\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 376/380\n",
      "10000/10000 [==============================] - 31s - loss: 2.3251 - categorical_accuracy: 0.3213 - val_loss: 2.3370 - val_categorical_accuracy: 0.3191\n",
      "Epoch 377/380\n",
      "10000/10000 [==============================] - 31s - loss: 2.3121 - categorical_accuracy: 0.3238 - val_loss: 2.3196 - val_categorical_accuracy: 0.3229\n",
      "Epoch 378/380\n",
      "10000/10000 [==============================] - 31s - loss: 2.3089 - categorical_accuracy: 0.3244 - val_loss: 2.3333 - val_categorical_accuracy: 0.3202\n",
      "Epoch 379/380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 31s - loss: 2.3038 - categorical_accuracy: 0.3259 - val_loss: 2.3832 - val_categorical_accuracy: 0.3077\n",
      "Epoch 380/380\n",
      "10000/10000 [==============================] - 31s - loss: 2.3030 - categorical_accuracy: 0.3257 - val_loss: 2.3374 - val_categorical_accuracy: 0.3185\n",
      "65\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 381/385\n",
      "10000/10000 [==============================] - 31s - loss: 2.3206 - categorical_accuracy: 0.3223 - val_loss: 2.3230 - val_categorical_accuracy: 0.3222\n",
      "Epoch 382/385\n",
      "10000/10000 [==============================] - 31s - loss: 2.3086 - categorical_accuracy: 0.3251 - val_loss: 2.3652 - val_categorical_accuracy: 0.3116\n",
      "Epoch 383/385\n",
      "10000/10000 [==============================] - 31s - loss: 2.3043 - categorical_accuracy: 0.3257 - val_loss: 2.3315 - val_categorical_accuracy: 0.3196\n",
      "Epoch 384/385\n",
      "10000/10000 [==============================] - 31s - loss: 2.3018 - categorical_accuracy: 0.3262 - val_loss: 2.3289 - val_categorical_accuracy: 0.3203\n",
      "Epoch 385/385\n",
      "10000/10000 [==============================] - 31s - loss: 2.2949 - categorical_accuracy: 0.3280 - val_loss: 2.3274 - val_categorical_accuracy: 0.3206\n",
      "66\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 386/390\n",
      "10000/10000 [==============================] - 31s - loss: 2.3192 - categorical_accuracy: 0.3229 - val_loss: 2.3209 - val_categorical_accuracy: 0.3224\n",
      "Epoch 387/390\n",
      "10000/10000 [==============================] - 31s - loss: 2.3054 - categorical_accuracy: 0.3258 - val_loss: 2.3341 - val_categorical_accuracy: 0.3187\n",
      "Epoch 388/390\n",
      "10000/10000 [==============================] - 31s - loss: 2.3065 - categorical_accuracy: 0.3257 - val_loss: 2.3257 - val_categorical_accuracy: 0.3210\n",
      "Epoch 389/390\n",
      "10000/10000 [==============================] - 31s - loss: 2.2966 - categorical_accuracy: 0.3282 - val_loss: 2.3280 - val_categorical_accuracy: 0.3198\n",
      "Epoch 390/390\n",
      "10000/10000 [==============================] - 31s - loss: 2.2987 - categorical_accuracy: 0.3274 - val_loss: 2.3244 - val_categorical_accuracy: 0.3223\n",
      "67\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 391/395\n",
      "10000/10000 [==============================] - 31s - loss: 2.3183 - categorical_accuracy: 0.3228 - val_loss: 2.3283 - val_categorical_accuracy: 0.3210\n",
      "Epoch 392/395\n",
      "10000/10000 [==============================] - 31s - loss: 2.3046 - categorical_accuracy: 0.3258 - val_loss: 2.3309 - val_categorical_accuracy: 0.3191\n",
      "Epoch 393/395\n",
      "10000/10000 [==============================] - 31s - loss: 2.2969 - categorical_accuracy: 0.3276 - val_loss: 2.3284 - val_categorical_accuracy: 0.3199\n",
      "Epoch 394/395\n",
      "10000/10000 [==============================] - 31s - loss: 2.2950 - categorical_accuracy: 0.3279 - val_loss: 2.3381 - val_categorical_accuracy: 0.3177\n",
      "Epoch 395/395\n",
      "10000/10000 [==============================] - 31s - loss: 2.2937 - categorical_accuracy: 0.3280 - val_loss: 2.3426 - val_categorical_accuracy: 0.3168\n",
      "68\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 396/400\n",
      "10000/10000 [==============================] - 31s - loss: 2.3219 - categorical_accuracy: 0.3223 - val_loss: 2.3397 - val_categorical_accuracy: 0.3167\n",
      "Epoch 397/400\n",
      "10000/10000 [==============================] - 31s - loss: 2.3071 - categorical_accuracy: 0.3251 - val_loss: 2.3218 - val_categorical_accuracy: 0.3212\n",
      "Epoch 398/400\n",
      "10000/10000 [==============================] - 31s - loss: 2.3011 - categorical_accuracy: 0.3267 - val_loss: 2.3236 - val_categorical_accuracy: 0.3220\n",
      "Epoch 399/400\n",
      "10000/10000 [==============================] - 31s - loss: 2.2987 - categorical_accuracy: 0.3272 - val_loss: 2.3257 - val_categorical_accuracy: 0.3210\n",
      "Epoch 400/400\n",
      "10000/10000 [==============================] - 31s - loss: 2.2946 - categorical_accuracy: 0.3284 - val_loss: 2.3306 - val_categorical_accuracy: 0.3196\n",
      "69\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 401/405\n",
      "10000/10000 [==============================] - 31s - loss: 2.3158 - categorical_accuracy: 0.3230 - val_loss: 2.3294 - val_categorical_accuracy: 0.3208\n",
      "Epoch 402/405\n",
      "10000/10000 [==============================] - 32s - loss: 2.3034 - categorical_accuracy: 0.3258 - val_loss: 2.3240 - val_categorical_accuracy: 0.3211\n",
      "Epoch 403/405\n",
      "10000/10000 [==============================] - 32s - loss: 2.2973 - categorical_accuracy: 0.3273 - val_loss: 2.3332 - val_categorical_accuracy: 0.3190\n",
      "Epoch 404/405\n",
      "10000/10000 [==============================] - 32s - loss: 2.2943 - categorical_accuracy: 0.3279 - val_loss: 2.3304 - val_categorical_accuracy: 0.3200\n",
      "Epoch 405/405\n",
      "10000/10000 [==============================] - 32s - loss: 2.2926 - categorical_accuracy: 0.3284 - val_loss: 2.3446 - val_categorical_accuracy: 0.3173\n",
      "70\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 406/410\n",
      "10000/10000 [==============================] - 32s - loss: 2.3138 - categorical_accuracy: 0.3241 - val_loss: 2.3186 - val_categorical_accuracy: 0.3230\n",
      "Epoch 407/410\n",
      "10000/10000 [==============================] - 32s - loss: 2.2979 - categorical_accuracy: 0.3278 - val_loss: 2.3204 - val_categorical_accuracy: 0.3224\n",
      "Epoch 408/410\n",
      "10000/10000 [==============================] - 32s - loss: 2.2931 - categorical_accuracy: 0.3287 - val_loss: 2.3143 - val_categorical_accuracy: 0.3246\n",
      "Epoch 409/410\n",
      "10000/10000 [==============================] - 32s - loss: 2.2921 - categorical_accuracy: 0.3290 - val_loss: 2.3339 - val_categorical_accuracy: 0.3195\n",
      "Epoch 410/410\n",
      "10000/10000 [==============================] - 32s - loss: 2.2883 - categorical_accuracy: 0.3298 - val_loss: 2.3034 - val_categorical_accuracy: 0.3260\n",
      "71\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 411/415\n",
      "10000/10000 [==============================] - 33s - loss: 2.3141 - categorical_accuracy: 0.3241 - val_loss: 2.3175 - val_categorical_accuracy: 0.3223\n",
      "Epoch 412/415\n",
      "10000/10000 [==============================] - 32s - loss: 2.3029 - categorical_accuracy: 0.3261 - val_loss: 2.3229 - val_categorical_accuracy: 0.3199\n",
      "Epoch 413/415\n",
      "10000/10000 [==============================] - 32s - loss: 2.2956 - categorical_accuracy: 0.3282 - val_loss: 2.3439 - val_categorical_accuracy: 0.3153\n",
      "Epoch 414/415\n",
      "10000/10000 [==============================] - 32s - loss: 2.2941 - categorical_accuracy: 0.3284 - val_loss: 2.3113 - val_categorical_accuracy: 0.3239\n",
      "Epoch 415/415\n",
      "10000/10000 [==============================] - 32s - loss: 2.2899 - categorical_accuracy: 0.3296 - val_loss: 2.3174 - val_categorical_accuracy: 0.3220\n",
      "72\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 416/420\n",
      "10000/10000 [==============================] - 32s - loss: 2.3107 - categorical_accuracy: 0.3249 - val_loss: 2.3223 - val_categorical_accuracy: 0.3213\n",
      "Epoch 417/420\n",
      "10000/10000 [==============================] - 32s - loss: 2.2969 - categorical_accuracy: 0.3281 - val_loss: 2.3164 - val_categorical_accuracy: 0.3239\n",
      "Epoch 418/420\n",
      "10000/10000 [==============================] - 32s - loss: 2.2951 - categorical_accuracy: 0.3283 - val_loss: 2.3217 - val_categorical_accuracy: 0.3226\n",
      "Epoch 419/420\n",
      "10000/10000 [==============================] - 32s - loss: 2.2902 - categorical_accuracy: 0.3293 - val_loss: 2.3151 - val_categorical_accuracy: 0.3244\n",
      "Epoch 420/420\n",
      "10000/10000 [==============================] - 32s - loss: 2.2839 - categorical_accuracy: 0.3310 - val_loss: 2.3162 - val_categorical_accuracy: 0.3231\n",
      "73\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 421/425\n",
      "10000/10000 [==============================] - 32s - loss: 2.3144 - categorical_accuracy: 0.3243 - val_loss: 2.3189 - val_categorical_accuracy: 0.3230\n",
      "Epoch 422/425\n",
      "10000/10000 [==============================] - 32s - loss: 2.2987 - categorical_accuracy: 0.3277 - val_loss: 2.3200 - val_categorical_accuracy: 0.3234\n",
      "Epoch 423/425\n",
      "10000/10000 [==============================] - 32s - loss: 2.2947 - categorical_accuracy: 0.3284 - val_loss: 2.3113 - val_categorical_accuracy: 0.3256\n",
      "Epoch 424/425\n",
      "10000/10000 [==============================] - 32s - loss: 2.2914 - categorical_accuracy: 0.3294 - val_loss: 2.3148 - val_categorical_accuracy: 0.3239\n",
      "Epoch 425/425\n",
      "10000/10000 [==============================] - 32s - loss: 2.2880 - categorical_accuracy: 0.3301 - val_loss: 2.3096 - val_categorical_accuracy: 0.3254\n",
      "74\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 426/430\n",
      "10000/10000 [==============================] - 31s - loss: 2.3071 - categorical_accuracy: 0.3257 - val_loss: 2.3148 - val_categorical_accuracy: 0.3240\n",
      "Epoch 427/430\n",
      "10000/10000 [==============================] - 31s - loss: 2.2949 - categorical_accuracy: 0.3285 - val_loss: 2.3140 - val_categorical_accuracy: 0.3246\n",
      "Epoch 428/430\n",
      "10000/10000 [==============================] - 31s - loss: 2.2885 - categorical_accuracy: 0.3299 - val_loss: 2.3253 - val_categorical_accuracy: 0.3226\n",
      "Epoch 429/430\n",
      "10000/10000 [==============================] - 31s - loss: 2.2877 - categorical_accuracy: 0.3301 - val_loss: 2.3180 - val_categorical_accuracy: 0.3230\n",
      "Epoch 430/430\n",
      "10000/10000 [==============================] - 31s - loss: 2.2831 - categorical_accuracy: 0.3310 - val_loss: 2.3277 - val_categorical_accuracy: 0.3212\n",
      "75\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 431/435\n",
      "10000/10000 [==============================] - 31s - loss: 2.3070 - categorical_accuracy: 0.3258 - val_loss: 2.3120 - val_categorical_accuracy: 0.3255\n",
      "Epoch 432/435\n",
      "10000/10000 [==============================] - 31s - loss: 2.2967 - categorical_accuracy: 0.3281 - val_loss: 2.3197 - val_categorical_accuracy: 0.3220\n",
      "Epoch 433/435\n",
      "10000/10000 [==============================] - 31s - loss: 2.2899 - categorical_accuracy: 0.3296 - val_loss: 2.3154 - val_categorical_accuracy: 0.3234\n",
      "Epoch 434/435\n",
      "10000/10000 [==============================] - 31s - loss: 2.2872 - categorical_accuracy: 0.3300 - val_loss: 2.3185 - val_categorical_accuracy: 0.3230\n",
      "Epoch 435/435\n",
      "10000/10000 [==============================] - 31s - loss: 2.2847 - categorical_accuracy: 0.3308 - val_loss: 2.3116 - val_categorical_accuracy: 0.3249\n",
      "76\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 436/440\n",
      "10000/10000 [==============================] - 31s - loss: 2.3057 - categorical_accuracy: 0.3263 - val_loss: 2.3075 - val_categorical_accuracy: 0.3249\n",
      "Epoch 437/440\n",
      "10000/10000 [==============================] - 31s - loss: 2.2920 - categorical_accuracy: 0.3289 - val_loss: 2.3032 - val_categorical_accuracy: 0.3269\n",
      "Epoch 438/440\n",
      "10000/10000 [==============================] - 31s - loss: 2.2848 - categorical_accuracy: 0.3307 - val_loss: 2.3064 - val_categorical_accuracy: 0.3248\n",
      "Epoch 439/440\n",
      "10000/10000 [==============================] - 31s - loss: 2.2820 - categorical_accuracy: 0.3313 - val_loss: 2.3076 - val_categorical_accuracy: 0.3250\n",
      "Epoch 440/440\n",
      "10000/10000 [==============================] - 31s - loss: 2.2794 - categorical_accuracy: 0.3316 - val_loss: 2.3109 - val_categorical_accuracy: 0.3247\n",
      "77\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 441/445\n",
      "10000/10000 [==============================] - 31s - loss: 2.3058 - categorical_accuracy: 0.3262 - val_loss: 2.2989 - val_categorical_accuracy: 0.3276\n",
      "Epoch 442/445\n",
      "10000/10000 [==============================] - 31s - loss: 2.2931 - categorical_accuracy: 0.3288 - val_loss: 2.3049 - val_categorical_accuracy: 0.3260\n",
      "Epoch 443/445\n",
      "10000/10000 [==============================] - 31s - loss: 2.2868 - categorical_accuracy: 0.3302 - val_loss: 2.3017 - val_categorical_accuracy: 0.3269\n",
      "Epoch 444/445\n",
      "10000/10000 [==============================] - 31s - loss: 2.2819 - categorical_accuracy: 0.3314 - val_loss: 2.3123 - val_categorical_accuracy: 0.3241\n",
      "Epoch 445/445\n",
      "10000/10000 [==============================] - 31s - loss: 2.2852 - categorical_accuracy: 0.3302 - val_loss: 2.3055 - val_categorical_accuracy: 0.3252\n",
      "78\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 446/450\n",
      "10000/10000 [==============================] - 31s - loss: 2.3033 - categorical_accuracy: 0.3263 - val_loss: 2.3142 - val_categorical_accuracy: 0.3229\n",
      "Epoch 447/450\n",
      "10000/10000 [==============================] - 31s - loss: 2.2948 - categorical_accuracy: 0.3282 - val_loss: 2.2970 - val_categorical_accuracy: 0.3280\n",
      "Epoch 448/450\n",
      "10000/10000 [==============================] - 31s - loss: 2.2859 - categorical_accuracy: 0.3304 - val_loss: 2.3147 - val_categorical_accuracy: 0.3228\n",
      "Epoch 449/450\n",
      "10000/10000 [==============================] - 31s - loss: 2.2837 - categorical_accuracy: 0.3307 - val_loss: 2.3072 - val_categorical_accuracy: 0.3246\n",
      "Epoch 450/450\n",
      "10000/10000 [==============================] - 31s - loss: 2.2805 - categorical_accuracy: 0.3315 - val_loss: 2.3159 - val_categorical_accuracy: 0.3238\n",
      "79\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 451/455\n",
      "10000/10000 [==============================] - 31s - loss: 2.2979 - categorical_accuracy: 0.3284 - val_loss: 2.3265 - val_categorical_accuracy: 0.3209\n",
      "Epoch 452/455\n",
      "10000/10000 [==============================] - 31s - loss: 2.2875 - categorical_accuracy: 0.3306 - val_loss: 2.3217 - val_categorical_accuracy: 0.3213\n",
      "Epoch 453/455\n",
      "10000/10000 [==============================] - 31s - loss: 2.2838 - categorical_accuracy: 0.3314 - val_loss: 2.3038 - val_categorical_accuracy: 0.3254\n",
      "Epoch 454/455\n",
      "10000/10000 [==============================] - 31s - loss: 2.2789 - categorical_accuracy: 0.3323 - val_loss: 2.3072 - val_categorical_accuracy: 0.3246\n",
      "Epoch 455/455\n",
      "10000/10000 [==============================] - 31s - loss: 2.2808 - categorical_accuracy: 0.3319 - val_loss: 2.3225 - val_categorical_accuracy: 0.3209\n"
     ]
    }
   ],
   "source": [
    "for i in range(80):\n",
    "    print(i)\n",
    "    history = training_round(256, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(80):\n",
    "    print(i)\n",
    "    history = training_round(256, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oss of St. George, awarded to soldiers for bravery in\\naction, and in the company of well-known, elderly, and respected\\nracing men was training a trotter of his own for a race. He knew a\\nlady on one of the boulevards whom he visited of an evening. He led\\nth',\n",
       " ' he frowned at his wife, the officers\\ngrew still merrier, and some of them could not refrain from\\nlaughter, for which they hurriedly sought plausible pretexts. When\\nhe had gone, taking his wife with him, and had settled down with her\\nin their covered cart,',\n",
       " 'im that would explain to\\nher what had happened and to which she could find no answer.\\n\\n\"Natalie, just a word, only one!\" he kept repeating, evidently not\\nknowing what to say and he repeated it till Helene came up to them.\\n\\nHelene returned with Natasha to t',\n",
       " \"was growing lighter and lighter. That curly\\ngrass which always grows by country roadsides became clearly\\nvisible, still wet with the night's rain; the drooping branches of the\\nbirches, also wet, swayed in the wind and flung down bright drops of\\nwater to on\"]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.text[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['      iee.                                         he\\nsoee                 ee        ee \" er                       tes\\naee e                                            e eies. Ie  e     \\n                                                                     ',\n",
       " '                 hhh           ee ies\\nto  ee                          hheeeeeeeee              oe\\naer e         ttthhhhhe                                eeiis. The  eeee                                                          e\\n\\n\\n\\n\\n\\ne                     ',\n",
       " '                     ind\\nhh                  ll nn    thhhhh                    tiee.\\n\\n\"Io                          ie.                               he\\n\\naeaae                                                                                                 ',\n",
       " '                            eee. Hhe  eeeeee                                                          he\\npere                 ttthhhh                                       iee\\nan                                                             e\\n\\n\\n\\n\\n\\n          ']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytelevel.prediction2str(model256.predict(test.x[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ee seen.. Ae  ee  eeeeeed oo ceatiies aoe seeaeed oe\\nceneie, and on the rereent an tee,-aniees an eeee, and sereen ee\\ncotiee aot ane cartinee of eereld ao his ane  os ahtie.. Pe  een e\\n\\na  eee                                                               ',\n",
       " 'the eeeeees an his aaie, the serteee,\\nten  eeate ceeteee, and aone of the  aeite wad cettinn thnt\\nhane iee, fan whith  het has aeite seeiet so seenee coreeens. I\\nn  ee wod thaed aating his see                                    e e                         ',\n",
       " 'et theh shaed aereaee to\\nhos waed aod eeteeeed the ie whinh the woted heey oo  oteee.\\n\\n\"Ie teeed aaed a saeed haed hoe?\" he want aereeteee, ah eeeted woe\\nhen  en that ie wat  otthe serieted ao                                                                ',\n",
       " 'iee sheeing hos aa  an  tet eee. The eeeen,\\nthaed whatd an iee aeeae to ce eiee te eeeeed cerele ao thee\\nceseete, aeeet wos waon the wighere feiee the setining te eeee, an eed\\nwe thire aoee to                                                eeeeeee         ']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytelevel.prediction2str(model256.predict(test.x[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model256.save('../models/model256.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
