{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyper_params import *\n",
    "import text_encoder as te\n",
    "import text_decoder as td\n",
    "from data_set import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bowizer\n",
    "import tfidf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_policy_random.pkl', 'rb') as f:\n",
    "    gd = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n                    ________  ________  __    __  ________        \\n                   |        \\\\|        \\\\|  \\\\  |  \\\\|        \\\\       \\n                    \\\\$$$$$$$$| $$$$$$$$| $$  | $$ \\\\$$$$$$$$       \\n                      | $$   | $$__     \\\\$$\\\\/  $$   | $$          \\n                      | $$   | $$  \\\\     >$$  $$    | $$          \\n                      | $$   | $$$$$    /  $$$$\\\\    | $$          \\n                      | $$   | $$_____ |  $$ \\\\$$\\\\   | $$          \\n                      | $$   | $$     \\\\| $$  | $$   | $$          \\n                       \\\\$$    \\\\$$$$$$$$ \\\\$$   \\\\$$    \\\\$$          \\n              __       __   ______   _______   __        _______  \\n             |  \\\\  _  |  \\\\ /      \\\\ |       \\\\ |  \\\\      |       \\\\ \\n             | $$ / \\\\ | $$|  $$$$$$\\\\| $$$$$$$\\\\| $$      | $$$$$$$\\\\\\n             | $$/  $\\\\| $$| $$  | $$| $$__| $$| $$      | $$  | $$\\n             | $$  $$$\\\\ $$| $$  | $$| $$    $$| $$      | $$  | $$\\n             | $$ $$\\\\$$\\\\$$| $$  | $$| $$$$$$$\\\\| $$      | $$  | $$\\n             | $$$$  \\\\$$$$| $$__/ $$| $$  | $$| $$_____ | $$__/ $$\\n             | $$$    \\\\$$$ \\\\$$    $$| $$  | $$| $$     \\\\| $$    $$\\n              \\\\$$      \\\\$$  \\\\$$$$$$  \\\\$$   \\\\$$ \\\\$$$$$$$$ \\\\$$$$$$$ \\n\\nIt\\'s time to explore the amazing world of TextWorld! Make it so the safe inside the cellar is locked.\\n\\n-= Cellar =-\\nYou find yourself in a cellar. A typical one. You try to gain information on your surroundings by using a technique you call \"looking.\"\\n\\nA closed safe, which looks typical, is in the corner.\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob ='\\n\\n\\n                    ________  ________  __    __  ________        \\n                   |        \\\\|        \\\\|  \\\\  |  \\\\|        \\\\       \\n                    \\\\$$$$$$$$| $$$$$$$$| $$  | $$ \\\\$$$$$$$$       \\n                      | $$   | $$__     \\\\$$\\\\/  $$   | $$          \\n                      | $$   | $$  \\\\     >$$  $$    | $$          \\n                      | $$   | $$$$$    /  $$$$\\\\    | $$          \\n                      | $$   | $$_____ |  $$ \\\\$$\\\\   | $$          \\n                      | $$   | $$     \\\\| $$  | $$   | $$          \\n                       \\\\$$    \\\\$$$$$$$$ \\\\$$   \\\\$$    \\\\$$          \\n              __       __   ______   _______   __        _______  \\n             |  \\\\  _  |  \\\\ /      \\\\ |       \\\\ |  \\\\      |       \\\\ \\n             | $$ / \\\\ | $$|  $$$$$$\\\\| $$$$$$$\\\\| $$      | $$$$$$$\\\\\\n             | $$/  $\\\\| $$| $$  | $$| $$__| $$| $$      | $$  | $$\\n             | $$  $$$\\\\ $$| $$  | $$| $$    $$| $$      | $$  | $$\\n             | $$ $$\\\\$$\\\\$$| $$  | $$| $$$$$$$\\\\| $$      | $$  | $$\\n             | $$$$  \\\\$$$$| $$__/ $$| $$  | $$| $$_____ | $$__/ $$\\n             | $$$    \\\\$$$ \\\\$$    $$| $$  | $$| $$     \\\\| $$    $$\\n              \\\\$$      \\\\$$  \\\\$$$$$$  \\\\$$   \\\\$$ \\\\$$$$$$$$ \\\\$$$$$$$ \\n\\n'\n",
    "bloblen = len(blob)\n",
    "\n",
    "gd[0] = [x.replace(blob, \"\") for x in gd[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n-= Workshop =-\\nYou've entered a workshop. You begin to take stock of what's in the room.\\n\\n\\n\\nThere is an exit to the north. Don't worry, it is unguarded. There is an exit to the west. Don't worry, it is unblocked.\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_data = len(gd[0])\n",
    "\n",
    "vocab_size = 3000\n",
    "training_split = 0.7\n",
    "\n",
    "traininglen = int(len_data * training_split)\n",
    "\n",
    "# traininglen = 2000\n",
    "training_set = gd[0][:traininglen]\n",
    "test_set = gd[0][traininglen:]\n",
    "test_set[0]\n",
    "\n",
    "\n",
    "#tm = bowizer.TokenMaker(corpus=gd[0], vocab_size= vocab_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('norvig_tm_3000.pkl', 'rb') as f:\n",
    "    tm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_h = EmbeddingHyper(tm.vocab_size + 1, 256)\n",
    "conv_h = ConvHyper(256, 6, 4)\n",
    "rnn_h = RnnHyper(512, is_lstm=False, is_bidirectional=True, return_sequences=False)\n",
    "encoder_h = te.Hyper(embed_h, [conv_h, rnn_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dernn_h = RnnHyper(512, is_lstm=False, is_bidirectional=False, return_sequences=True, unroll=True)\n",
    "dec_h = DeconvHyper(256, 6, 4)\n",
    "decoder_h = td.Hyper(tm.vocab_size + 1, [dernn_h, dec_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder_h.make_layer()\n",
    "decoder = decoder_h.make_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(training_set).shape\n",
    "\n",
    "ml = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(max_len):\n",
    "    x = Input(shape=(max_len,), name='text_input')\n",
    "    h = encoder(x)\n",
    "    h = decoder(h, max_len)\n",
    "    model = Model(x, h)\n",
    "    model.compile(optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['categorical_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel = make_model(ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.load_weights('../models/wl_model64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_round(history=None):\n",
    "    if history is None:\n",
    "        initial_epoch = 0\n",
    "    else:\n",
    "        initial_epoch = len(history['loss'])\n",
    "    train = bowizer.SlicedWordData(lines=r.choice(training_set, size=2000, replace=False), maxlen=ml,tokenmaker=tm)\n",
    "    test = bowizer.SlicedWordData(lines=r.choice(test_set, size=400, replace=False), maxlen=ml,tokenmaker=tm)\n",
    "    newhistory = testmodel.fit(x=train.x, y=train.y,\n",
    "                            epochs=initial_epoch+5, batch_size=32,\n",
    "                            validation_data=(test.x, test.y),\n",
    "                            initial_epoch=initial_epoch)\n",
    "    if history is None:\n",
    "        history = newhistory.history\n",
    "    else:\n",
    "        history = {key:history[key] + newhistory.history[key] for key in history.keys()}\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 44s - loss: 1.4378 - categorical_accuracy: 0.6869 - val_loss: 1.5296 - val_categorical_accuracy: 0.6629\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 43s - loss: 1.3764 - categorical_accuracy: 0.6920 - val_loss: 1.4511 - val_categorical_accuracy: 0.6741\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 43s - loss: 1.3099 - categorical_accuracy: 0.7008 - val_loss: 1.3845 - val_categorical_accuracy: 0.6846\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 43s - loss: 1.2866 - categorical_accuracy: 0.7049 - val_loss: 1.3736 - val_categorical_accuracy: 0.6872\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 43s - loss: 1.2631 - categorical_accuracy: 0.7068 - val_loss: 1.3212 - val_categorical_accuracy: 0.6992\n",
      "1\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 44s - loss: 1.2552 - categorical_accuracy: 0.7121 - val_loss: 1.2427 - val_categorical_accuracy: 0.7116\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 43s - loss: 1.1865 - categorical_accuracy: 0.7252 - val_loss: 1.1899 - val_categorical_accuracy: 0.7301\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 44s - loss: 1.1700 - categorical_accuracy: 0.7258 - val_loss: 1.1711 - val_categorical_accuracy: 0.7342\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 43s - loss: 1.1267 - categorical_accuracy: 0.7347 - val_loss: 1.2024 - val_categorical_accuracy: 0.7248\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 43s - loss: 1.1273 - categorical_accuracy: 0.7301 - val_loss: 1.1197 - val_categorical_accuracy: 0.7417\n",
      "2\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 11/15\n",
      "2000/2000 [==============================] - 44s - loss: 1.0696 - categorical_accuracy: 0.7482 - val_loss: 1.0594 - val_categorical_accuracy: 0.7522\n",
      "Epoch 12/15\n",
      "2000/2000 [==============================] - 44s - loss: 1.0384 - categorical_accuracy: 0.7522 - val_loss: 1.0612 - val_categorical_accuracy: 0.7511\n",
      "Epoch 13/15\n",
      "2000/2000 [==============================] - 44s - loss: 1.0163 - categorical_accuracy: 0.7555 - val_loss: 1.0119 - val_categorical_accuracy: 0.7635\n",
      "Epoch 14/15\n",
      "2000/2000 [==============================] - 43s - loss: 0.9624 - categorical_accuracy: 0.7672 - val_loss: 1.1318 - val_categorical_accuracy: 0.7278\n",
      "Epoch 15/15\n",
      "2000/2000 [==============================] - 43s - loss: 0.9877 - categorical_accuracy: 0.7589 - val_loss: 1.0208 - val_categorical_accuracy: 0.7582\n",
      "3\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 44s - loss: 1.0355 - categorical_accuracy: 0.7539 - val_loss: 1.1087 - val_categorical_accuracy: 0.7367\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 44s - loss: 1.0750 - categorical_accuracy: 0.7380 - val_loss: 1.1136 - val_categorical_accuracy: 0.7317\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 43s - loss: 0.9826 - categorical_accuracy: 0.7611 - val_loss: 1.1368 - val_categorical_accuracy: 0.7267\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 44s - loss: 0.9549 - categorical_accuracy: 0.7666 - val_loss: 1.0592 - val_categorical_accuracy: 0.7456\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 44s - loss: 0.9300 - categorical_accuracy: 0.7704 - val_loss: 1.0587 - val_categorical_accuracy: 0.7436\n",
      "4\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 21/25\n",
      "2000/2000 [==============================] - 45s - loss: 0.9956 - categorical_accuracy: 0.7580 - val_loss: 1.0412 - val_categorical_accuracy: 0.7536\n",
      "Epoch 22/25\n",
      "2000/2000 [==============================] - 44s - loss: 0.9990 - categorical_accuracy: 0.7524 - val_loss: 1.0817 - val_categorical_accuracy: 0.7463\n",
      "Epoch 23/25\n",
      "2000/2000 [==============================] - 43s - loss: 0.9322 - categorical_accuracy: 0.7690 - val_loss: 1.0094 - val_categorical_accuracy: 0.7576\n",
      "Epoch 24/25\n",
      "2000/2000 [==============================] - 44s - loss: 0.8910 - categorical_accuracy: 0.7753 - val_loss: 1.0018 - val_categorical_accuracy: 0.7596\n",
      "Epoch 25/25\n",
      "2000/2000 [==============================] - 44s - loss: 0.8699 - categorical_accuracy: 0.7782 - val_loss: 0.9980 - val_categorical_accuracy: 0.7594\n",
      "5\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 44s - loss: 0.9078 - categorical_accuracy: 0.7727 - val_loss: 0.9348 - val_categorical_accuracy: 0.7686\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 43s - loss: 0.9510 - categorical_accuracy: 0.7590 - val_loss: 0.9475 - val_categorical_accuracy: 0.7673\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 43s - loss: 0.8683 - categorical_accuracy: 0.7777 - val_loss: 0.9197 - val_categorical_accuracy: 0.7728\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 40s - loss: 0.8448 - categorical_accuracy: 0.7816 - val_loss: 0.9213 - val_categorical_accuracy: 0.7742\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 40s - loss: 0.8212 - categorical_accuracy: 0.7860 - val_loss: 0.9058 - val_categorical_accuracy: 0.7757\n",
      "6\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 31/35\n",
      "2000/2000 [==============================] - 41s - loss: 0.9596 - categorical_accuracy: 0.7569 - val_loss: 1.0325 - val_categorical_accuracy: 0.7393\n",
      "Epoch 32/35\n",
      "2000/2000 [==============================] - 40s - loss: 0.8933 - categorical_accuracy: 0.7715 - val_loss: 0.8746 - val_categorical_accuracy: 0.7806\n",
      "Epoch 33/35\n",
      "2000/2000 [==============================] - 40s - loss: 0.8327 - categorical_accuracy: 0.7839 - val_loss: 0.8597 - val_categorical_accuracy: 0.7839\n",
      "Epoch 34/35\n",
      "2000/2000 [==============================] - 40s - loss: 0.8009 - categorical_accuracy: 0.7899 - val_loss: 0.8462 - val_categorical_accuracy: 0.7856\n",
      "Epoch 35/35\n",
      "2000/2000 [==============================] - 40s - loss: 0.7892 - categorical_accuracy: 0.7914 - val_loss: 0.8490 - val_categorical_accuracy: 0.7870\n",
      "7\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 36/40\n",
      "2000/2000 [==============================] - 42s - loss: 0.8363 - categorical_accuracy: 0.7840 - val_loss: 0.9026 - val_categorical_accuracy: 0.7702\n",
      "Epoch 37/40\n",
      "2000/2000 [==============================] - 39s - loss: 0.8833 - categorical_accuracy: 0.7698 - val_loss: 0.9380 - val_categorical_accuracy: 0.7617\n",
      "Epoch 38/40\n",
      "2000/2000 [==============================] - 39s - loss: 0.8172 - categorical_accuracy: 0.7845 - val_loss: 0.8988 - val_categorical_accuracy: 0.7724\n",
      "Epoch 39/40\n",
      "2000/2000 [==============================] - 39s - loss: 0.7845 - categorical_accuracy: 0.7904 - val_loss: 0.9862 - val_categorical_accuracy: 0.7494\n",
      "Epoch 40/40\n",
      "2000/2000 [==============================] - 39s - loss: 0.7841 - categorical_accuracy: 0.7895 - val_loss: 0.8857 - val_categorical_accuracy: 0.7732\n",
      "8\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 41/45\n",
      "2000/2000 [==============================] - 40s - loss: 0.8037 - categorical_accuracy: 0.7884 - val_loss: 0.8330 - val_categorical_accuracy: 0.7835\n",
      "Epoch 42/45\n",
      "2000/2000 [==============================] - 39s - loss: 0.7644 - categorical_accuracy: 0.7944 - val_loss: 0.8263 - val_categorical_accuracy: 0.7851\n",
      "Epoch 43/45\n",
      "2000/2000 [==============================] - 39s - loss: 0.7448 - categorical_accuracy: 0.7978 - val_loss: 0.8230 - val_categorical_accuracy: 0.7862\n",
      "Epoch 44/45\n",
      "2000/2000 [==============================] - 39s - loss: 0.7331 - categorical_accuracy: 0.8006 - val_loss: 0.8508 - val_categorical_accuracy: 0.7823\n",
      "Epoch 45/45\n",
      "2000/2000 [==============================] - 39s - loss: 0.8191 - categorical_accuracy: 0.7783 - val_loss: 0.9810 - val_categorical_accuracy: 0.7379\n",
      "9\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 40s - loss: 0.7972 - categorical_accuracy: 0.7891 - val_loss: 0.8683 - val_categorical_accuracy: 0.7763\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 39s - loss: 0.7223 - categorical_accuracy: 0.8038 - val_loss: 0.8570 - val_categorical_accuracy: 0.7800\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 39s - loss: 0.6901 - categorical_accuracy: 0.8103 - val_loss: 0.8512 - val_categorical_accuracy: 0.7811\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 39s - loss: 0.6661 - categorical_accuracy: 0.8147 - val_loss: 0.8568 - val_categorical_accuracy: 0.7799\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 39s - loss: 0.6548 - categorical_accuracy: 0.8169 - val_loss: 0.8767 - val_categorical_accuracy: 0.7755\n",
      "10\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 51/55\n",
      "2000/2000 [==============================] - 40s - loss: 0.7432 - categorical_accuracy: 0.7996 - val_loss: 0.8383 - val_categorical_accuracy: 0.7772\n",
      "Epoch 52/55\n",
      "2000/2000 [==============================] - 39s - loss: 0.7575 - categorical_accuracy: 0.7943 - val_loss: 0.8250 - val_categorical_accuracy: 0.7822\n",
      "Epoch 53/55\n",
      "2000/2000 [==============================] - 39s - loss: 0.6851 - categorical_accuracy: 0.8100 - val_loss: 0.8387 - val_categorical_accuracy: 0.7744\n",
      "Epoch 54/55\n",
      "2000/2000 [==============================] - 39s - loss: 0.6564 - categorical_accuracy: 0.8155 - val_loss: 0.7993 - val_categorical_accuracy: 0.7872\n",
      "Epoch 55/55\n",
      "2000/2000 [==============================] - 39s - loss: 0.6344 - categorical_accuracy: 0.8205 - val_loss: 0.8046 - val_categorical_accuracy: 0.7856\n",
      "11\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 56/60\n",
      "2000/2000 [==============================] - 40s - loss: 0.7179 - categorical_accuracy: 0.8052 - val_loss: 0.7801 - val_categorical_accuracy: 0.7918\n",
      "Epoch 57/60\n",
      "2000/2000 [==============================] - 39s - loss: 0.6755 - categorical_accuracy: 0.8129 - val_loss: 0.7836 - val_categorical_accuracy: 0.7927\n",
      "Epoch 58/60\n",
      "2000/2000 [==============================] - 39s - loss: 0.6515 - categorical_accuracy: 0.8176 - val_loss: 0.7787 - val_categorical_accuracy: 0.7928\n",
      "Epoch 59/60\n",
      "2000/2000 [==============================] - 39s - loss: 0.6291 - categorical_accuracy: 0.8225 - val_loss: 0.7833 - val_categorical_accuracy: 0.7939\n",
      "Epoch 60/60\n",
      "2000/2000 [==============================] - 39s - loss: 0.7211 - categorical_accuracy: 0.7996 - val_loss: 0.8065 - val_categorical_accuracy: 0.7888\n",
      "12\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 61/65\n",
      "2000/2000 [==============================] - 40s - loss: 0.7006 - categorical_accuracy: 0.8081 - val_loss: 0.8383 - val_categorical_accuracy: 0.7793\n",
      "Epoch 62/65\n",
      "2000/2000 [==============================] - 39s - loss: 0.6598 - categorical_accuracy: 0.8155 - val_loss: 0.8297 - val_categorical_accuracy: 0.7837\n",
      "Epoch 63/65\n",
      "2000/2000 [==============================] - 39s - loss: 0.6197 - categorical_accuracy: 0.8252 - val_loss: 0.8280 - val_categorical_accuracy: 0.7842\n",
      "Epoch 64/65\n",
      "2000/2000 [==============================] - 39s - loss: 0.6038 - categorical_accuracy: 0.8282 - val_loss: 0.8321 - val_categorical_accuracy: 0.7843\n",
      "Epoch 65/65\n",
      "2000/2000 [==============================] - 39s - loss: 0.5913 - categorical_accuracy: 0.8308 - val_loss: 0.8330 - val_categorical_accuracy: 0.7850\n",
      "13\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 66/70\n",
      "2000/2000 [==============================] - 40s - loss: 0.6632 - categorical_accuracy: 0.8159 - val_loss: 0.6989 - val_categorical_accuracy: 0.8118\n",
      "Epoch 67/70\n",
      "2000/2000 [==============================] - 39s - loss: 0.6205 - categorical_accuracy: 0.8243 - val_loss: 0.6894 - val_categorical_accuracy: 0.8143\n",
      "Epoch 68/70\n",
      "2000/2000 [==============================] - 39s - loss: 0.5906 - categorical_accuracy: 0.8319 - val_loss: 0.7013 - val_categorical_accuracy: 0.8108\n",
      "Epoch 69/70\n",
      "2000/2000 [==============================] - 39s - loss: 0.5609 - categorical_accuracy: 0.8385 - val_loss: 0.6887 - val_categorical_accuracy: 0.8176\n",
      "Epoch 70/70\n",
      "2000/2000 [==============================] - 39s - loss: 0.5378 - categorical_accuracy: 0.8438 - val_loss: 0.6867 - val_categorical_accuracy: 0.8175\n",
      "14\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 71/75\n",
      "2000/2000 [==============================] - 40s - loss: 0.6343 - categorical_accuracy: 0.8225 - val_loss: 0.7074 - val_categorical_accuracy: 0.8097\n",
      "Epoch 72/75\n",
      "2000/2000 [==============================] - 39s - loss: 0.5862 - categorical_accuracy: 0.8319 - val_loss: 0.7218 - val_categorical_accuracy: 0.8086\n",
      "Epoch 73/75\n",
      "2000/2000 [==============================] - 39s - loss: 0.7241 - categorical_accuracy: 0.7959 - val_loss: 0.8057 - val_categorical_accuracy: 0.7871\n",
      "Epoch 74/75\n",
      "2000/2000 [==============================] - 39s - loss: 0.6119 - categorical_accuracy: 0.8241 - val_loss: 0.7269 - val_categorical_accuracy: 0.8088\n",
      "Epoch 75/75\n",
      "2000/2000 [==============================] - 39s - loss: 0.5457 - categorical_accuracy: 0.8414 - val_loss: 0.7195 - val_categorical_accuracy: 0.8102\n",
      "15\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 76/80\n",
      "2000/2000 [==============================] - 40s - loss: 0.6307 - categorical_accuracy: 0.8238 - val_loss: 0.7272 - val_categorical_accuracy: 0.8043\n",
      "Epoch 77/80\n",
      "2000/2000 [==============================] - 39s - loss: 0.5732 - categorical_accuracy: 0.8356 - val_loss: 0.7251 - val_categorical_accuracy: 0.8059\n",
      "Epoch 78/80\n",
      "2000/2000 [==============================] - 39s - loss: 0.5456 - categorical_accuracy: 0.8421 - val_loss: 0.7235 - val_categorical_accuracy: 0.8075\n",
      "Epoch 79/80\n",
      "2000/2000 [==============================] - 39s - loss: 0.5263 - categorical_accuracy: 0.8467 - val_loss: 0.7244 - val_categorical_accuracy: 0.8090\n",
      "Epoch 80/80\n",
      "2000/2000 [==============================] - 39s - loss: 0.5131 - categorical_accuracy: 0.8496 - val_loss: 0.7330 - val_categorical_accuracy: 0.8079\n",
      "16\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 81/85\n",
      "2000/2000 [==============================] - 40s - loss: 0.6077 - categorical_accuracy: 0.8274 - val_loss: 0.7454 - val_categorical_accuracy: 0.8023\n",
      "Epoch 82/85\n",
      "2000/2000 [==============================] - 39s - loss: 0.5809 - categorical_accuracy: 0.8317 - val_loss: 0.7093 - val_categorical_accuracy: 0.8119\n",
      "Epoch 83/85\n",
      "2000/2000 [==============================] - 39s - loss: 0.6615 - categorical_accuracy: 0.8116 - val_loss: 0.7538 - val_categorical_accuracy: 0.8004\n",
      "Epoch 84/85\n",
      "2000/2000 [==============================] - 39s - loss: 0.5616 - categorical_accuracy: 0.8363 - val_loss: 0.6970 - val_categorical_accuracy: 0.8160\n",
      "Epoch 85/85\n",
      "2000/2000 [==============================] - 39s - loss: 0.5100 - categorical_accuracy: 0.8495 - val_loss: 0.6930 - val_categorical_accuracy: 0.8195\n",
      "17\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 86/90\n",
      "2000/2000 [==============================] - 40s - loss: 0.5697 - categorical_accuracy: 0.8383 - val_loss: 0.6559 - val_categorical_accuracy: 0.8211\n",
      "Epoch 87/90\n",
      "2000/2000 [==============================] - 39s - loss: 0.5148 - categorical_accuracy: 0.8503 - val_loss: 0.6543 - val_categorical_accuracy: 0.8247\n",
      "Epoch 88/90\n",
      "2000/2000 [==============================] - 39s - loss: 0.4808 - categorical_accuracy: 0.8587 - val_loss: 0.6589 - val_categorical_accuracy: 0.8252\n",
      "Epoch 89/90\n",
      "2000/2000 [==============================] - 39s - loss: 0.4687 - categorical_accuracy: 0.8612 - val_loss: 0.6720 - val_categorical_accuracy: 0.8240\n",
      "Epoch 90/90\n",
      "2000/2000 [==============================] - 39s - loss: 0.4734 - categorical_accuracy: 0.8597 - val_loss: 0.6932 - val_categorical_accuracy: 0.8177\n",
      "18\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 91/95\n",
      "2000/2000 [==============================] - 40s - loss: 0.5588 - categorical_accuracy: 0.8408 - val_loss: 0.6733 - val_categorical_accuracy: 0.8195\n",
      "Epoch 92/95\n",
      "2000/2000 [==============================] - 39s - loss: 0.5737 - categorical_accuracy: 0.8394 - val_loss: 1.1943 - val_categorical_accuracy: 0.6968\n",
      "Epoch 93/95\n",
      "2000/2000 [==============================] - 39s - loss: 0.6659 - categorical_accuracy: 0.8070 - val_loss: 0.7252 - val_categorical_accuracy: 0.8057\n",
      "Epoch 94/95\n",
      "2000/2000 [==============================] - 39s - loss: 0.5104 - categorical_accuracy: 0.8489 - val_loss: 0.6973 - val_categorical_accuracy: 0.8171\n",
      "Epoch 95/95\n",
      "2000/2000 [==============================] - 39s - loss: 0.4909 - categorical_accuracy: 0.8543 - val_loss: 0.6935 - val_categorical_accuracy: 0.8200\n",
      "19\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 40s - loss: 0.5373 - categorical_accuracy: 0.8457 - val_loss: 0.6396 - val_categorical_accuracy: 0.8252\n",
      "Epoch 97/100\n",
      "2000/2000 [==============================] - 39s - loss: 0.4787 - categorical_accuracy: 0.8599 - val_loss: 0.6473 - val_categorical_accuracy: 0.8256\n",
      "Epoch 98/100\n",
      "2000/2000 [==============================] - 39s - loss: 0.4517 - categorical_accuracy: 0.8668 - val_loss: 0.6400 - val_categorical_accuracy: 0.8271\n",
      "Epoch 99/100\n",
      "2000/2000 [==============================] - 39s - loss: 0.4278 - categorical_accuracy: 0.8730 - val_loss: 0.6535 - val_categorical_accuracy: 0.8259\n",
      "Epoch 100/100\n",
      "2000/2000 [==============================] - 39s - loss: 0.4187 - categorical_accuracy: 0.8747 - val_loss: 0.6598 - val_categorical_accuracy: 0.8261\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(i)\n",
    "    history = training_round(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 101/105\n",
      "2000/2000 [==============================] - 41s - loss: 0.5193 - categorical_accuracy: 0.8504 - val_loss: 0.6059 - val_categorical_accuracy: 0.8377\n",
      "Epoch 102/105\n",
      "2000/2000 [==============================] - 40s - loss: 0.4622 - categorical_accuracy: 0.8640 - val_loss: 0.6090 - val_categorical_accuracy: 0.8384\n",
      "Epoch 103/105\n",
      "2000/2000 [==============================] - 40s - loss: 0.4714 - categorical_accuracy: 0.8602 - val_loss: 0.6713 - val_categorical_accuracy: 0.8227\n",
      "Epoch 104/105\n",
      "2000/2000 [==============================] - 40s - loss: 0.4871 - categorical_accuracy: 0.8561 - val_loss: 0.6631 - val_categorical_accuracy: 0.8232\n",
      "Epoch 105/105\n",
      "2000/2000 [==============================] - 40s - loss: 0.4593 - categorical_accuracy: 0.8634 - val_loss: 0.6509 - val_categorical_accuracy: 0.8299\n",
      "1\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 106/110\n",
      "2000/2000 [==============================] - 41s - loss: 0.5034 - categorical_accuracy: 0.8540 - val_loss: 0.6128 - val_categorical_accuracy: 0.8360\n",
      "Epoch 107/110\n",
      "2000/2000 [==============================] - 40s - loss: 0.4451 - categorical_accuracy: 0.8680 - val_loss: 0.6291 - val_categorical_accuracy: 0.8352\n",
      "Epoch 108/110\n",
      "2000/2000 [==============================] - 40s - loss: 0.4179 - categorical_accuracy: 0.8755 - val_loss: 0.6109 - val_categorical_accuracy: 0.8407\n",
      "Epoch 109/110\n",
      "2000/2000 [==============================] - 40s - loss: 0.3885 - categorical_accuracy: 0.8835 - val_loss: 0.6147 - val_categorical_accuracy: 0.8413\n",
      "Epoch 110/110\n",
      "2000/2000 [==============================] - 40s - loss: 0.3736 - categorical_accuracy: 0.8876 - val_loss: 0.6543 - val_categorical_accuracy: 0.8336\n",
      "2\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 111/115\n",
      "2000/2000 [==============================] - 41s - loss: 0.5052 - categorical_accuracy: 0.8537 - val_loss: 0.5817 - val_categorical_accuracy: 0.8432\n",
      "Epoch 112/115\n",
      "2000/2000 [==============================] - 40s - loss: 0.4472 - categorical_accuracy: 0.8675 - val_loss: 0.5746 - val_categorical_accuracy: 0.8456\n",
      "Epoch 113/115\n",
      "2000/2000 [==============================] - 40s - loss: 0.4109 - categorical_accuracy: 0.8771 - val_loss: 0.5801 - val_categorical_accuracy: 0.8473\n",
      "Epoch 114/115\n",
      "2000/2000 [==============================] - 40s - loss: 0.4378 - categorical_accuracy: 0.8731 - val_loss: 0.6358 - val_categorical_accuracy: 0.8367\n",
      "Epoch 115/115\n",
      "2000/2000 [==============================] - 40s - loss: 0.4315 - categorical_accuracy: 0.8707 - val_loss: 0.8153 - val_categorical_accuracy: 0.7994\n",
      "3\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 116/120\n",
      "2000/2000 [==============================] - 41s - loss: 0.6367 - categorical_accuracy: 0.8205 - val_loss: 0.6290 - val_categorical_accuracy: 0.8339\n",
      "Epoch 117/120\n",
      "2000/2000 [==============================] - 40s - loss: 0.4735 - categorical_accuracy: 0.8610 - val_loss: 0.6128 - val_categorical_accuracy: 0.8393\n",
      "Epoch 118/120\n",
      "2000/2000 [==============================] - 40s - loss: 0.4089 - categorical_accuracy: 0.8781 - val_loss: 0.6005 - val_categorical_accuracy: 0.8427\n",
      "Epoch 119/120\n",
      "2000/2000 [==============================] - 40s - loss: 0.3763 - categorical_accuracy: 0.8870 - val_loss: 0.6217 - val_categorical_accuracy: 0.8417\n",
      "Epoch 120/120\n",
      "2000/2000 [==============================] - 40s - loss: 0.3552 - categorical_accuracy: 0.8932 - val_loss: 0.6271 - val_categorical_accuracy: 0.8418\n",
      "4\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 121/125\n",
      "2000/2000 [==============================] - 42s - loss: 0.4496 - categorical_accuracy: 0.8693 - val_loss: 0.6169 - val_categorical_accuracy: 0.8370\n",
      "Epoch 122/125\n",
      "2000/2000 [==============================] - 40s - loss: 0.3930 - categorical_accuracy: 0.8831 - val_loss: 0.6261 - val_categorical_accuracy: 0.8388\n",
      "Epoch 123/125\n",
      "2000/2000 [==============================] - 40s - loss: 0.3636 - categorical_accuracy: 0.8904 - val_loss: 0.6357 - val_categorical_accuracy: 0.8371\n",
      "Epoch 124/125\n",
      "2000/2000 [==============================] - 40s - loss: 0.3449 - categorical_accuracy: 0.8953 - val_loss: 0.6732 - val_categorical_accuracy: 0.8340\n",
      "Epoch 125/125\n",
      "2000/2000 [==============================] - 40s - loss: 0.3424 - categorical_accuracy: 0.8961 - val_loss: 0.6711 - val_categorical_accuracy: 0.8330\n",
      "5\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 126/130\n",
      "2000/2000 [==============================] - 40s - loss: 0.4459 - categorical_accuracy: 0.8700 - val_loss: 0.6258 - val_categorical_accuracy: 0.8339\n",
      "Epoch 127/130\n",
      "2000/2000 [==============================] - 39s - loss: 0.3900 - categorical_accuracy: 0.8834 - val_loss: 0.6209 - val_categorical_accuracy: 0.8382\n",
      "Epoch 128/130\n",
      "2000/2000 [==============================] - 39s - loss: 0.3545 - categorical_accuracy: 0.8935 - val_loss: 0.6385 - val_categorical_accuracy: 0.8357\n",
      "Epoch 129/130\n",
      "2000/2000 [==============================] - 39s - loss: 0.3761 - categorical_accuracy: 0.8885 - val_loss: 0.6667 - val_categorical_accuracy: 0.8287\n",
      "Epoch 130/130\n",
      "2000/2000 [==============================] - 39s - loss: 0.4401 - categorical_accuracy: 0.8696 - val_loss: 0.6937 - val_categorical_accuracy: 0.8191\n",
      "6\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 131/135\n",
      "2000/2000 [==============================] - 40s - loss: 0.4439 - categorical_accuracy: 0.8699 - val_loss: 0.6013 - val_categorical_accuracy: 0.8404\n",
      "Epoch 132/135\n",
      "2000/2000 [==============================] - 39s - loss: 0.3721 - categorical_accuracy: 0.8889 - val_loss: 0.5889 - val_categorical_accuracy: 0.8451\n",
      "Epoch 133/135\n",
      "2000/2000 [==============================] - 39s - loss: 0.3267 - categorical_accuracy: 0.9011 - val_loss: 0.6059 - val_categorical_accuracy: 0.8445\n",
      "Epoch 134/135\n",
      "2000/2000 [==============================] - 39s - loss: 0.2990 - categorical_accuracy: 0.9095 - val_loss: 0.6214 - val_categorical_accuracy: 0.8438\n",
      "Epoch 135/135\n",
      "2000/2000 [==============================] - 39s - loss: 0.2897 - categorical_accuracy: 0.9113 - val_loss: 0.6456 - val_categorical_accuracy: 0.8397\n",
      "7\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 136/140\n",
      "2000/2000 [==============================] - 40s - loss: 0.3956 - categorical_accuracy: 0.8838 - val_loss: 0.6055 - val_categorical_accuracy: 0.8408\n",
      "Epoch 137/140\n",
      "2000/2000 [==============================] - 39s - loss: 0.3393 - categorical_accuracy: 0.8977 - val_loss: 0.6214 - val_categorical_accuracy: 0.8399\n",
      "Epoch 138/140\n",
      "2000/2000 [==============================] - 39s - loss: 0.3367 - categorical_accuracy: 0.8980 - val_loss: 0.6361 - val_categorical_accuracy: 0.8359\n",
      "Epoch 139/140\n",
      "2000/2000 [==============================] - 39s - loss: 0.4767 - categorical_accuracy: 0.8636 - val_loss: 0.7176 - val_categorical_accuracy: 0.8142\n",
      "Epoch 140/140\n",
      "2000/2000 [==============================] - 39s - loss: 0.3731 - categorical_accuracy: 0.8875 - val_loss: 0.6391 - val_categorical_accuracy: 0.8350\n",
      "8\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 141/145\n",
      "2000/2000 [==============================] - 40s - loss: 0.4158 - categorical_accuracy: 0.8771 - val_loss: 0.5494 - val_categorical_accuracy: 0.8503\n",
      "Epoch 142/145\n",
      "2000/2000 [==============================] - 39s - loss: 0.3398 - categorical_accuracy: 0.8981 - val_loss: 0.5582 - val_categorical_accuracy: 0.8515\n",
      "Epoch 143/145\n",
      "2000/2000 [==============================] - 39s - loss: 0.3059 - categorical_accuracy: 0.9076 - val_loss: 0.5646 - val_categorical_accuracy: 0.8528\n",
      "Epoch 144/145\n",
      "2000/2000 [==============================] - 39s - loss: 0.2837 - categorical_accuracy: 0.9136 - val_loss: 0.5812 - val_categorical_accuracy: 0.8515\n",
      "Epoch 145/145\n",
      "2000/2000 [==============================] - 39s - loss: 0.2721 - categorical_accuracy: 0.9169 - val_loss: 0.6182 - val_categorical_accuracy: 0.8474\n",
      "9\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 146/150\n",
      "2000/2000 [==============================] - 40s - loss: 0.3897 - categorical_accuracy: 0.8853 - val_loss: 0.6053 - val_categorical_accuracy: 0.8426\n",
      "Epoch 147/150\n",
      "2000/2000 [==============================] - 39s - loss: 0.3267 - categorical_accuracy: 0.9013 - val_loss: 0.6199 - val_categorical_accuracy: 0.8426\n",
      "Epoch 148/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 39s - loss: 0.3016 - categorical_accuracy: 0.9083 - val_loss: 0.6395 - val_categorical_accuracy: 0.8392\n",
      "Epoch 149/150\n",
      "2000/2000 [==============================] - 39s - loss: 0.4114 - categorical_accuracy: 0.8787 - val_loss: 0.7303 - val_categorical_accuracy: 0.8093\n",
      "Epoch 150/150\n",
      "2000/2000 [==============================] - 39s - loss: 0.3738 - categorical_accuracy: 0.8870 - val_loss: 0.6335 - val_categorical_accuracy: 0.8389\n",
      "10\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 151/155\n",
      "2000/2000 [==============================] - 40s - loss: 0.4012 - categorical_accuracy: 0.8810 - val_loss: 0.5543 - val_categorical_accuracy: 0.8552\n",
      "Epoch 152/155\n",
      "2000/2000 [==============================] - 39s - loss: 0.3267 - categorical_accuracy: 0.9013 - val_loss: 0.5659 - val_categorical_accuracy: 0.8565\n",
      "Epoch 153/155\n",
      "2000/2000 [==============================] - 39s - loss: 0.2858 - categorical_accuracy: 0.9127 - val_loss: 0.5747 - val_categorical_accuracy: 0.8580\n",
      "Epoch 154/155\n",
      "2000/2000 [==============================] - 39s - loss: 0.2654 - categorical_accuracy: 0.9188 - val_loss: 0.5993 - val_categorical_accuracy: 0.8567\n",
      "Epoch 155/155\n",
      "2000/2000 [==============================] - 39s - loss: 0.2589 - categorical_accuracy: 0.9207 - val_loss: 0.6176 - val_categorical_accuracy: 0.8523\n",
      "11\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 156/160\n",
      "2000/2000 [==============================] - 40s - loss: 0.3707 - categorical_accuracy: 0.8916 - val_loss: 0.5360 - val_categorical_accuracy: 0.8600\n",
      "Epoch 157/160\n",
      "2000/2000 [==============================] - 39s - loss: 0.3025 - categorical_accuracy: 0.9085 - val_loss: 0.5411 - val_categorical_accuracy: 0.8629\n",
      "Epoch 158/160\n",
      "2000/2000 [==============================] - 39s - loss: 0.2674 - categorical_accuracy: 0.9185 - val_loss: 0.5600 - val_categorical_accuracy: 0.8599\n",
      "Epoch 159/160\n",
      "2000/2000 [==============================] - 39s - loss: 0.2525 - categorical_accuracy: 0.9227 - val_loss: 0.5685 - val_categorical_accuracy: 0.8606\n",
      "Epoch 160/160\n",
      "2000/2000 [==============================] - 39s - loss: 0.2553 - categorical_accuracy: 0.9224 - val_loss: 0.6227 - val_categorical_accuracy: 0.8487\n",
      "12\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 161/165\n",
      "2000/2000 [==============================] - 40s - loss: 0.3476 - categorical_accuracy: 0.8966 - val_loss: 0.5922 - val_categorical_accuracy: 0.8501\n",
      "Epoch 162/165\n",
      "2000/2000 [==============================] - 39s - loss: 0.2818 - categorical_accuracy: 0.9145 - val_loss: 0.5984 - val_categorical_accuracy: 0.8497\n",
      "Epoch 163/165\n",
      "2000/2000 [==============================] - 39s - loss: 0.2505 - categorical_accuracy: 0.9237 - val_loss: 0.6067 - val_categorical_accuracy: 0.8499\n",
      "Epoch 164/165\n",
      "2000/2000 [==============================] - 39s - loss: 0.2330 - categorical_accuracy: 0.9290 - val_loss: 0.6150 - val_categorical_accuracy: 0.8502\n",
      "Epoch 165/165\n",
      "2000/2000 [==============================] - 39s - loss: 0.2173 - categorical_accuracy: 0.9333 - val_loss: 0.6508 - val_categorical_accuracy: 0.8462\n",
      "13\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 166/170\n",
      "2000/2000 [==============================] - 40s - loss: 0.3386 - categorical_accuracy: 0.9003 - val_loss: 0.5358 - val_categorical_accuracy: 0.8620\n",
      "Epoch 167/170\n",
      "2000/2000 [==============================] - 39s - loss: 0.2879 - categorical_accuracy: 0.9127 - val_loss: 0.5356 - val_categorical_accuracy: 0.8609\n",
      "Epoch 168/170\n",
      "2000/2000 [==============================] - 39s - loss: 0.2838 - categorical_accuracy: 0.9133 - val_loss: 0.5717 - val_categorical_accuracy: 0.8574\n",
      "Epoch 169/170\n",
      "2000/2000 [==============================] - 39s - loss: 0.2704 - categorical_accuracy: 0.9185 - val_loss: 0.5573 - val_categorical_accuracy: 0.8583\n",
      "Epoch 170/170\n",
      "2000/2000 [==============================] - 39s - loss: 0.2442 - categorical_accuracy: 0.9260 - val_loss: 0.5550 - val_categorical_accuracy: 0.8622\n",
      "14\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 171/175\n",
      "2000/2000 [==============================] - 40s - loss: 0.3748 - categorical_accuracy: 0.8893 - val_loss: 0.4825 - val_categorical_accuracy: 0.8720\n",
      "Epoch 172/175\n",
      "2000/2000 [==============================] - 39s - loss: 0.2994 - categorical_accuracy: 0.9098 - val_loss: 0.4806 - val_categorical_accuracy: 0.8740\n",
      "Epoch 173/175\n",
      "2000/2000 [==============================] - 39s - loss: 0.2731 - categorical_accuracy: 0.9161 - val_loss: 0.5188 - val_categorical_accuracy: 0.8706\n",
      "Epoch 174/175\n",
      "2000/2000 [==============================] - 39s - loss: 0.4982 - categorical_accuracy: 0.8605 - val_loss: 0.5743 - val_categorical_accuracy: 0.8541\n",
      "Epoch 175/175\n",
      "2000/2000 [==============================] - 39s - loss: 0.3246 - categorical_accuracy: 0.9009 - val_loss: 0.5057 - val_categorical_accuracy: 0.8694\n",
      "15\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 176/180\n",
      "2000/2000 [==============================] - 40s - loss: 0.3281 - categorical_accuracy: 0.9019 - val_loss: 0.5083 - val_categorical_accuracy: 0.8680\n",
      "Epoch 177/180\n",
      "2000/2000 [==============================] - 39s - loss: 0.2521 - categorical_accuracy: 0.9236 - val_loss: 0.5155 - val_categorical_accuracy: 0.8689\n",
      "Epoch 178/180\n",
      "2000/2000 [==============================] - 39s - loss: 0.2149 - categorical_accuracy: 0.9347 - val_loss: 0.5394 - val_categorical_accuracy: 0.8680\n",
      "Epoch 179/180\n",
      "2000/2000 [==============================] - 39s - loss: 0.1878 - categorical_accuracy: 0.9433 - val_loss: 0.5529 - val_categorical_accuracy: 0.8686\n",
      "Epoch 180/180\n",
      "2000/2000 [==============================] - 39s - loss: 0.1722 - categorical_accuracy: 0.9477 - val_loss: 0.5830 - val_categorical_accuracy: 0.8646\n",
      "16\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 181/185\n",
      "2000/2000 [==============================] - 40s - loss: 0.3147 - categorical_accuracy: 0.9067 - val_loss: 0.5432 - val_categorical_accuracy: 0.8610\n",
      "Epoch 182/185\n",
      "2000/2000 [==============================] - 39s - loss: 0.2461 - categorical_accuracy: 0.9247 - val_loss: 0.5557 - val_categorical_accuracy: 0.8627\n",
      "Epoch 183/185\n",
      "2000/2000 [==============================] - 39s - loss: 0.2197 - categorical_accuracy: 0.9329 - val_loss: 0.5846 - val_categorical_accuracy: 0.8596\n",
      "Epoch 184/185\n",
      "2000/2000 [==============================] - 39s - loss: 0.2052 - categorical_accuracy: 0.9365 - val_loss: 0.5950 - val_categorical_accuracy: 0.8607\n",
      "Epoch 185/185\n",
      "2000/2000 [==============================] - 39s - loss: 0.2039 - categorical_accuracy: 0.9380 - val_loss: 0.6211 - val_categorical_accuracy: 0.8548\n",
      "17\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 186/190\n",
      "2000/2000 [==============================] - 40s - loss: 0.3104 - categorical_accuracy: 0.9076 - val_loss: 0.5380 - val_categorical_accuracy: 0.8627\n",
      "Epoch 187/190\n",
      "2000/2000 [==============================] - 39s - loss: 0.2477 - categorical_accuracy: 0.9238 - val_loss: 0.5443 - val_categorical_accuracy: 0.8674\n",
      "Epoch 188/190\n",
      "2000/2000 [==============================] - 39s - loss: 0.2286 - categorical_accuracy: 0.9302 - val_loss: 0.5957 - val_categorical_accuracy: 0.8580\n",
      "Epoch 189/190\n",
      "2000/2000 [==============================] - 39s - loss: 0.2390 - categorical_accuracy: 0.9279 - val_loss: 0.5655 - val_categorical_accuracy: 0.8648\n",
      "Epoch 190/190\n",
      "2000/2000 [==============================] - 39s - loss: 0.2113 - categorical_accuracy: 0.9366 - val_loss: 0.5756 - val_categorical_accuracy: 0.8639\n",
      "18\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 191/195\n",
      "2000/2000 [==============================] - 40s - loss: 0.2941 - categorical_accuracy: 0.9125 - val_loss: 0.5940 - val_categorical_accuracy: 0.8494\n",
      "Epoch 192/195\n",
      "2000/2000 [==============================] - 39s - loss: 0.2385 - categorical_accuracy: 0.9273 - val_loss: 0.6016 - val_categorical_accuracy: 0.8533\n",
      "Epoch 193/195\n",
      "2000/2000 [==============================] - 39s - loss: 0.2424 - categorical_accuracy: 0.9257 - val_loss: 0.6295 - val_categorical_accuracy: 0.8499\n",
      "Epoch 194/195\n",
      "2000/2000 [==============================] - 39s - loss: 0.2671 - categorical_accuracy: 0.9199 - val_loss: 0.6433 - val_categorical_accuracy: 0.8465\n",
      "Epoch 195/195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 39s - loss: 0.2259 - categorical_accuracy: 0.9310 - val_loss: 0.6147 - val_categorical_accuracy: 0.8504\n",
      "19\n",
      "Train on 2000 samples, validate on 400 samples\n",
      "Epoch 196/200\n",
      "2000/2000 [==============================] - 40s - loss: 0.2982 - categorical_accuracy: 0.9107 - val_loss: 0.4953 - val_categorical_accuracy: 0.8739\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 39s - loss: 0.2158 - categorical_accuracy: 0.9334 - val_loss: 0.5030 - val_categorical_accuracy: 0.8748\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 39s - loss: 0.1801 - categorical_accuracy: 0.9451 - val_loss: 0.5226 - val_categorical_accuracy: 0.8755\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 39s - loss: 0.1576 - categorical_accuracy: 0.9514 - val_loss: 0.5345 - val_categorical_accuracy: 0.8739\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 39s - loss: 0.1436 - categorical_accuracy: 0.9560 - val_loss: 0.5623 - val_categorical_accuracy: 0.8737\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(i)\n",
    "    history = training_round(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.save('../models/gamestate_ae128.hp5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
